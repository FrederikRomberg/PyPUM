{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Demand for Cars with the IPDL model\n",
    "\n",
    "In this notebook, we will explore the dataset used in\n",
    "Goldberg & Verboven (2005). We will estimate the IPDL Model\n",
    "model given the available data using the functions defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from numpy import linalg as la\n",
    "from scipy import optimize\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools as iter\n",
    "from numba import jit\n",
    "\n",
    "# Files\n",
    "import Logit_file as logit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "====\n",
    "\n",
    "The dataset consists of approximately 110 vehicle makes per year in the period 1970-1999 in five european markets (Belgium, France, Germany, Italy, and the United Kingdom). Furthermore, the data contains information on various characteristics of the makes such as sales, prices, horse power, weight and other physical car characteristics. Also these characteristics may vary across markets. \n",
    "\n",
    "A observation in our analysis will be a market in a given year such that e.g. the French car market in 1995 counts as a single observation. If $Y = 30$ is the number of years, and $M = 5$ is the number of country-level markets, we thus have $T=Y\\cdot M = 150$ markets and observations. In addition, since the available vehicle makes vary across time and place, let $\\mathcal{J}_t$ denote the set of available makes in each market $t=1,\\ldots,T$, and let $\\mathcal{J} := \\bigcup_{t=1}^T \\mathcal{J}_t$ be the set of all makes which were available in some market. Then $J:=\\#\\mathcal{J}$ is the number of makes which were available at some point of time in the period in at least one country-level market. In our dataset there are $J = 356$ unique vehicle makes. Note also however that characteristics of vehicle makes vary across markets.\n",
    "\n",
    "Our dataset includes 47 variables in total. The first three columns are market and product codes for the year, country, and make. Another variable is quantity sold (No. of new registrations) which will be used in computing observed market shares. The remaining 43 variables are potential explanatory variables. We will only consider the subset of these which describes car characteristics such as brand, after-tax price, horse power, etc. which adds up to $K=20$ characteristics. The remaining 23 variables are mainly macroeconomic variables such as e.g. GDP per capita which have been used to construct estimates of e.g. the average wage income and purchasing power. Since we are only interested in utility-shifting variables, we will not consider the latter columns. \n",
    "\n",
    "Reading in the dataset `eurocars.csv` we thus have a dataframe of $\\sum_{t=1}^T \\#\\mathcal{J}_t = 11459$ rows and $47$ columns. The `ye` column runs through $y=70,\\ldots,99$, the `ma` column runs through $m=1,\\ldots,M$, and the ``co`` column takes values $j\\in \\mathcal{J}$. \n",
    "\n",
    "Because we consider a country-year pair as the level of observation, we construct a `market` column taking values $t=1,\\ldots,T$. We also construct a `market_share` variable giving us the market share of any product $j$ in any market $t$; this will obviously take values in $[0,1]$. To deal with the fact that choice sets $\\mathcal{J}_t$ vary across markets, we expand the dataframe so that every car $j\\in \\mathcal{J}$ which was observed in some market $t$ is in the choice set of all other markets as well, i.e. we impose $\\mathcal{J}_t = \\mathcal{J}$ for all markets $t$. We then impute a market share of $q_{jt}=0$ for any car $j$ which in reality was not available in market $t$. To this end we first construct an outside option $j=0$ in each market $t$  of not buying a car by letting the 'sales' of $j=0$ being determined as \n",
    "\n",
    "$$\\mathrm{sales}_{0t} = \\mathrm{pop}_t - \\sum_{j=1}^J \\mathrm{sales}_{jt}$$\n",
    "\n",
    "where $\\mathrm{pop}_t$ is the total population in market $t$.\n",
    "\n",
    "We also read in the variable description of the dataset contained in `eurocars.dta`. We will use the list `x_vars` throughout to work with our explanatory variables.\n",
    "\n",
    "Lastly, we access the underlying 3-dimensional numpy array of the explonatory variables `x` by sorting on `market` and then `co`, and subsequently resizing the explanatory variables as\n",
    "\n",
    "> `x = dat[x_vars].values.resize((T,J,K))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and variable names\n",
    "os.chdir('../GREENCAR_notebooks/')\n",
    "input_path = os.getcwd() # Assigns input path as current working directory (cwd)\n",
    "descr = (pd.read_stata('eurocars.dta', iterator = True)).variable_labels()\n",
    "dat = pd.read_csv(os.path.join(input_path, 'eurocars.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable names</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ye</td>\n",
       "      <td>year (=first dimension of panel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ma</td>\n",
       "      <td>market (=second dimension of panel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>co</td>\n",
       "      <td>model code (=third dimension of panel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zcode</td>\n",
       "      <td>alternative model code (predecessors and succe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brd</td>\n",
       "      <td>brand code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type</td>\n",
       "      <td>name of brand and model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brand</td>\n",
       "      <td>name of brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model</td>\n",
       "      <td>name of model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>org</td>\n",
       "      <td>origin code (demand side, country with which c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loc</td>\n",
       "      <td>location code (production side, country where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cla</td>\n",
       "      <td>class or segment code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home</td>\n",
       "      <td>domestic car dummy (appropriate interaction of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>frm</td>\n",
       "      <td>firm code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qu</td>\n",
       "      <td>sales (number of new car registrations)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cy</td>\n",
       "      <td>cylinder volume or displacement (in cc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hp</td>\n",
       "      <td>horsepower (in kW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>we</td>\n",
       "      <td>weight (in kg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pl</td>\n",
       "      <td>places (number, not reliable variable)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>do</td>\n",
       "      <td>doors (number, not reliable variable)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>le</td>\n",
       "      <td>length (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wi</td>\n",
       "      <td>width (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>he</td>\n",
       "      <td>height (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>li1</td>\n",
       "      <td>measure 1 for fuel efficiency (liter per km, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>li2</td>\n",
       "      <td>measure 2 for fuel efficiency (liter per km, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>li3</td>\n",
       "      <td>measure 3 for fuel efficiency (liter per km, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>li</td>\n",
       "      <td>average of li1, li2, li3 (used in papers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sp</td>\n",
       "      <td>maximum speed (km/hour)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ac</td>\n",
       "      <td>time to acceleration (in seconds from 0 to 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pr</td>\n",
       "      <td>price (in destination currency including V.A.T.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>princ</td>\n",
       "      <td>=pr/(ngdp/pop): price relative to per capita i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>eurpr</td>\n",
       "      <td>=pr/avdexr: price in common currency (in SDR t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>exppr</td>\n",
       "      <td>=pr/avexr: price in exporter currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>avexr</td>\n",
       "      <td>av. exchange rate of exporter country (exporte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>avdexr</td>\n",
       "      <td>av. exchange rate of destination country (dest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>avcpr</td>\n",
       "      <td>av. consumer price index of exporter country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>avppr</td>\n",
       "      <td>av. producer price index of exporter country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>avdcpr</td>\n",
       "      <td>av. consumer price index of destination country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>avdppr</td>\n",
       "      <td>av. producer price index of destination country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xexr</td>\n",
       "      <td>avdexr/avexr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tax</td>\n",
       "      <td>percentage VAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pop</td>\n",
       "      <td>population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ngdp</td>\n",
       "      <td>nominal gross domestic product of destination ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rgdp</td>\n",
       "      <td>real gross domestic product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>engdp</td>\n",
       "      <td>=ngdp/avdexr: nominal gdp in common currency (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ergdp</td>\n",
       "      <td>=rgdp/avexr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>engdpc</td>\n",
       "      <td>=engdp/pop: nominal gdp per capita in common c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ergdpc</td>\n",
       "      <td>=ergdp/pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable names                                        description\n",
       "0              ye                   year (=first dimension of panel)\n",
       "1              ma                market (=second dimension of panel)\n",
       "2              co             model code (=third dimension of panel)\n",
       "3           zcode  alternative model code (predecessors and succe...\n",
       "4             brd                                         brand code\n",
       "5            type                            name of brand and model\n",
       "6           brand                                      name of brand\n",
       "7           model                                      name of model\n",
       "8             org  origin code (demand side, country with which c...\n",
       "9             loc  location code (production side, country where ...\n",
       "10            cla                              class or segment code\n",
       "11           home  domestic car dummy (appropriate interaction of...\n",
       "12            frm                                          firm code\n",
       "13             qu            sales (number of new car registrations)\n",
       "14             cy            cylinder volume or displacement (in cc)\n",
       "15             hp                                 horsepower (in kW)\n",
       "16             we                                     weight (in kg)\n",
       "17             pl             places (number, not reliable variable)\n",
       "18             do              doors (number, not reliable variable)\n",
       "19             le                                     length (in cm)\n",
       "20             wi                                      width (in cm)\n",
       "21             he                                     height (in cm)\n",
       "22            li1  measure 1 for fuel efficiency (liter per km, a...\n",
       "23            li2  measure 2 for fuel efficiency (liter per km, a...\n",
       "24            li3  measure 3 for fuel efficiency (liter per km, a...\n",
       "25             li          average of li1, li2, li3 (used in papers)\n",
       "26             sp                            maximum speed (km/hour)\n",
       "27             ac  time to acceleration (in seconds from 0 to 100...\n",
       "28             pr   price (in destination currency including V.A.T.)\n",
       "29          princ  =pr/(ngdp/pop): price relative to per capita i...\n",
       "30          eurpr  =pr/avdexr: price in common currency (in SDR t...\n",
       "31          exppr              =pr/avexr: price in exporter currency\n",
       "32          avexr  av. exchange rate of exporter country (exporte...\n",
       "33         avdexr  av. exchange rate of destination country (dest...\n",
       "34          avcpr       av. consumer price index of exporter country\n",
       "35          avppr       av. producer price index of exporter country\n",
       "36         avdcpr    av. consumer price index of destination country\n",
       "37         avdppr    av. producer price index of destination country\n",
       "38           xexr                                       avdexr/avexr\n",
       "39            tax                                     percentage VAT\n",
       "40            pop                                         population\n",
       "41           ngdp  nominal gross domestic product of destination ...\n",
       "42           rgdp                        real gross domestic product\n",
       "43          engdp  =ngdp/avdexr: nominal gdp in common currency (...\n",
       "44          ergdp                                        =rgdp/avexr\n",
       "45         engdpc  =engdp/pop: nominal gdp per capita in common c...\n",
       "46         ergdpc                                         =ergdp/pop"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(descr, index=['description']).transpose().reset_index().rename(columns={'index' : 'variable names'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now clean the data to fit our setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we create the 'market' column \n",
    "\n",
    "dat = dat.sort_values(by = ['ye', 'ma'], ascending = True)\n",
    "market_vals = [*iter.product(dat['ye'].unique(), dat['ma'].unique())]\n",
    "market_vals = pd.DataFrame({'year' : [val[0] for val in market_vals], 'country' : [val[1] for val in market_vals]})\n",
    "market_vals = market_vals.reset_index().rename(columns={'index' : 'market'})\n",
    "dat = dat.merge(market_vals, left_on=['ye', 'ma'], right_on=['year', 'country'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second we construct an outside option for each market t\n",
    "\n",
    "outside_shares = dat.groupby('market', as_index=False)['qu'].sum()\n",
    "outside_shares = outside_shares.merge(dat[['market', 'pop']], on = 'market', how='left').dropna().drop_duplicates(subset = 'market', keep = 'first')\n",
    "outside_shares['qu'] = outside_shares['pop'] - outside_shares['qu']\n",
    "outside_shares['co'] = 0\n",
    "dat = pd.concat([dat, outside_shares])\n",
    "\n",
    "# Potentially set characteristics equal to 0 for outside option. However consider different data types!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Third we compute market shares for each product j in each market t \n",
    "\n",
    "dat['ms'] = dat.groupby('market')['qu'].transform(lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine explanatory variables and find variable description as 'x_lab'\n",
    "x_vars =  [dat.keys()[k] for k in [*range(6,13), *range(14,22), *range(25,29)]]\n",
    "nest_vars = [var for var in x_vars if (var != 'type')&(var != 'model')&(var != 'pr')] # we will nest on variables which are not price, brand, model.\n",
    "nest_cont_vars = ['cy', 'hp', 'we', 'le', 'wi', 'he', 'li', 'sp', 'ac']\n",
    "x_lab = (pd.DataFrame(descr, index=['description'])[x_vars].transpose().reset_index().rename(columns={'index' : 'variable names'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable names</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>brand</td>\n",
       "      <td>name of brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model</td>\n",
       "      <td>name of model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>org</td>\n",
       "      <td>origin code (demand side, country with which c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>loc</td>\n",
       "      <td>location code (production side, country where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cla</td>\n",
       "      <td>class or segment code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>home</td>\n",
       "      <td>domestic car dummy (appropriate interaction of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>frm</td>\n",
       "      <td>firm code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cy</td>\n",
       "      <td>cylinder volume or displacement (in cc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>hp</td>\n",
       "      <td>horsepower (in kW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>we</td>\n",
       "      <td>weight (in kg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>pl</td>\n",
       "      <td>places (number, not reliable variable)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>do</td>\n",
       "      <td>doors (number, not reliable variable)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>le</td>\n",
       "      <td>length (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>wi</td>\n",
       "      <td>width (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>he</td>\n",
       "      <td>height (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>li</td>\n",
       "      <td>average of li1, li2, li3 (used in papers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sp</td>\n",
       "      <td>maximum speed (km/hour)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ac</td>\n",
       "      <td>time to acceleration (in seconds from 0 to 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pr</td>\n",
       "      <td>price (in destination currency including V.A.T.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable names                                        description\n",
       "0           brand                                      name of brand\n",
       "1           model                                      name of model\n",
       "2             org  origin code (demand side, country with which c...\n",
       "3             loc  location code (production side, country where ...\n",
       "4             cla                              class or segment code\n",
       "5            home  domestic car dummy (appropriate interaction of...\n",
       "6             frm                                          firm code\n",
       "7              cy            cylinder volume or displacement (in cc)\n",
       "8              hp                                 horsepower (in kW)\n",
       "9              we                                     weight (in kg)\n",
       "10             pl             places (number, not reliable variable)\n",
       "11             do              doors (number, not reliable variable)\n",
       "12             le                                     length (in cm)\n",
       "13             wi                                      width (in cm)\n",
       "14             he                                     height (in cm)\n",
       "15             li          average of li1, li2, li3 (used in papers)\n",
       "16             sp                            maximum speed (km/hour)\n",
       "17             ac  time to acceleration (in seconds from 0 to 100...\n",
       "18             pr   price (in destination currency including V.A.T.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dimensions of Data\n",
    "T = dat['market'].nunique()\n",
    "J = np.array([dat[dat['market'] == t]['co'].nunique() for t in np.arange(T)])\n",
    "K = len(x_vars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also convert our discrete explanatory variables to numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_columns = dat.select_dtypes(['object'])\n",
    "for col in obj_columns:\n",
    "    dat[col] = dat[col].astype('category').cat.codes.astype('float64') # Possibly a problem with Nan's being mapped to -1 ?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally we fill Nan values with '$-1$' in remaining columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.fillna(-1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also scale values such that they lie in the interval $[-1,1]$. This has various numerical benefits. Also, this will not affect elasticities or diversion ratios, but semielasticities will be affected by the scaling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[x_vars] = dat[x_vars] / dat[x_vars].abs().max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will primarily use numpy data types and numpy functions in this notebook. Hence we store our response variable 'y' and our explanatory variables 'x' as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy arrays of response and explanatory variables\n",
    "dat = dat.sort_values(by = ['market', 'co']) # Sort data so that reshape is successfull\n",
    "x = {t: dat[dat['market'] == t][x_vars].values.reshape((J[t],K)) for t in np.arange(T)}\n",
    "y = {t: dat[dat['market'] == t]['ms'].to_numpy().reshape((J[t])) for t in np.arange(T)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logit - for comparison\n",
    "Estimating a Logit model via maximum likelihood with an initial guess of parameters $\\hat \\beta^0 = 0$ yields estimated parameters $\\hat \\beta^{\\text{logit}}$ given as..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "einstein sum subscripts string contains too many subscripts for operand 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\IPDL_book3.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m beta_0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((K,))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# Estimate the model\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m res_logit \u001b[39m=\u001b[39m logit\u001b[39m.\u001b[39;49mestimate_logit(logit\u001b[39m.\u001b[39;49mq_logit, beta_0, y, x, is_dict \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\Logit_file.py:291\u001b[0m, in \u001b[0;36mestimate_logit\u001b[1;34m(q, Beta0, y, x, is_dict, Analytic_jac, options, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m     Grad \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39m# call optimizer\u001b[39;00m\n\u001b[1;32m--> 291\u001b[0m result \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39mminimize(Q, Beta0\u001b[39m.\u001b[39mtolist(), options\u001b[39m=\u001b[39moptions, jac \u001b[39m=\u001b[39m Grad, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    292\u001b[0m pars \u001b[39m=\u001b[39m result\u001b[39m.\u001b[39mx\n\u001b[0;32m    293\u001b[0m t,p \u001b[39m=\u001b[39m logit_t_p(pars, y, x, is_dict)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:618\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_cg(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    617\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbfgs\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 618\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_bfgs(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    619\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    620\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    621\u001b[0m                               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1201\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1198\u001b[0m \u001b[39mif\u001b[39;00m maxiter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1199\u001b[0m     maxiter \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x0) \u001b[39m*\u001b[39m \u001b[39m200\u001b[39m\n\u001b[1;32m-> 1201\u001b[0m sf \u001b[39m=\u001b[39m _prepare_scalar_function(fun, x0, jac, args\u001b[39m=\u001b[39;49margs, epsilon\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m   1202\u001b[0m                               finite_diff_rel_step\u001b[39m=\u001b[39;49mfinite_diff_rel_step)\n\u001b[0;32m   1204\u001b[0m f \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39mfun\n\u001b[0;32m   1205\u001b[0m myfprime \u001b[39m=\u001b[39m sf\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:261\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    257\u001b[0m     bounds \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39minf, np\u001b[39m.\u001b[39minf)\n\u001b[0;32m    259\u001b[0m \u001b[39m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[39m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 261\u001b[0m sf \u001b[39m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m    262\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[39m=\u001b[39;49mepsilon)\n\u001b[0;32m    264\u001b[0m \u001b[39mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:140\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx)\n\u001b[0;32m    139\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_fun_impl \u001b[39m=\u001b[39m update_fun\n\u001b[1;32m--> 140\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    142\u001b[0m \u001b[39m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[39mif\u001b[39;00m callable(grad):\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> 233\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\Logit_file.py:283\u001b[0m, in \u001b[0;36mestimate_logit.<locals>.<lambda>\u001b[1;34m(Theta)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[39m''' \u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39mTakes a function and returns the minimum, given start values and \u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39mvariables to calculate the residuals.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39m    res: Returns a dictionary with results from the estimation.\u001b[39;00m\n\u001b[0;32m    278\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    280\u001b[0m \u001b[39m# The objective function is the average of q(), \u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[39m# but Q is only a function of one variable, theta, \u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[39m# which is what minimize() will expect\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m Q \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m Theta: np\u001b[39m.\u001b[39mmean(q(Theta, y, x, is_dict))\n\u001b[0;32m    285\u001b[0m \u001b[39mif\u001b[39;00m Analytic_jac \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     Grad \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m Theta: np\u001b[39m.\u001b[39mmean(q_logit_score(Theta, y, x, is_dict), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m# Finds the Jacobian of Q. Takes mean of criterion q derivatives along axis=0, i.e. the mean across individuals.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\Logit_file.py:254\u001b[0m, in \u001b[0;36mq_logit\u001b[1;34m(Beta, y, x, is_dict)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mq_logit\u001b[39m(Beta, y, x, is_dict \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    251\u001b[0m     \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[39m    q: Criterion function, passed to estimate_logit().\u001b[39;00m\n\u001b[0;32m    253\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m--> 254\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m-\u001b[39mlogit_loglikehood(Beta, y, x, is_dict)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\Logit_file.py:153\u001b[0m, in \u001b[0;36mlogit_loglikehood\u001b[1;34m(Beta, y, x, MAXRESCALE, is_dict)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[39mThis function calculates the likelihood contributions of a Logit model\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[39m    ll_i: (N,) vector of loglikelihood contributions for a Logit\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    152\u001b[0m \u001b[39m# deterministic utility \u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m v \u001b[39m=\u001b[39m util(Beta, x, is_dict)\n\u001b[0;32m    155\u001b[0m \u001b[39mif\u001b[39;00m is_dict \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     \u001b[39mif\u001b[39;00m MAXRESCALE: \n\u001b[0;32m    157\u001b[0m         \u001b[39m# subtract the row-max from each observation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\Logit_file.py:129\u001b[0m, in \u001b[0;36mutil\u001b[1;34m(Beta, x, is_dict)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[39mThis function finds the deterministic utilities u = X*Beta.\u001b[39;00m\n\u001b[0;32m    119\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[39m    u: (N,J) matrix of deterministic utilities\u001b[39;00m\n\u001b[0;32m    126\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39mif\u001b[39;00m is_dict \u001b[39m==\u001b[39m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m--> 129\u001b[0m     u \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49meinsum(\u001b[39m'\u001b[39;49m\u001b[39mnjk,k->nj\u001b[39;49m\u001b[39m'\u001b[39;49m, x, Beta) \u001b[39m# is the same as x @ Beta\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    131\u001b[0m     T \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mkeys())\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\numpy\\core\\einsumfunc.py:1359\u001b[0m, in \u001b[0;36meinsum\u001b[1;34m(out, optimize, *operands, **kwargs)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[39mif\u001b[39;00m specified_out:\n\u001b[0;32m   1358\u001b[0m         kwargs[\u001b[39m'\u001b[39m\u001b[39mout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m out\n\u001b[1;32m-> 1359\u001b[0m     \u001b[39mreturn\u001b[39;00m c_einsum(\u001b[39m*\u001b[39moperands, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1361\u001b[0m \u001b[39m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[39;00m\n\u001b[0;32m   1362\u001b[0m \u001b[39m# repeat default values here\u001b[39;00m\n\u001b[0;32m   1363\u001b[0m valid_einsum_kwargs \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39morder\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcasting\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: einstein sum subscripts string contains too many subscripts for operand 0"
     ]
    }
   ],
   "source": [
    "beta_0 = np.zeros((K,))\n",
    "\n",
    "# Estimate the model\n",
    "res_logit = logit.estimate_logit(logit.q_logit, beta_0, y, x, is_dict = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_beta, logit_se = res_logit['beta'], res_logit['se']\n",
    "pd.DataFrame({'parameters': logit_beta, 'se' : logit_se}) # Our estimates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the corresponding Logit choice probabilities. STILL FIX THIS PART IN LOGIT BOOK!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_q = logit.logit_ccp(logit_beta, x, is_dict = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also find the elasticities and diversion ratios implied by the logit model as follows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_logit = logit.logit_elasticity(logit_q, logit_beta, 0) # Elasticities wrt. the price-to-log-income characteristic\n",
    "DR_logit_hat = logit.logit_diversion_ratio(logit_q, logit_beta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The IPDL model - Nesting structure\n",
    "\n",
    "The IPDL model is a generalization of the nested logit model where each alternative may belong to more than one nest. Before fully introducing the model, we construct the nesting structure.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing nests\n",
    "\n",
    "Let $\\Delta=\\left\\{q\\in \\mathbb{R}^J_+: \\sum_{j=1}^J q_j=1\\right\\}$ denote the probability simplex. For each group of nests $g=1,\\ldots, G$, nest membership is denoted by the matrix $\\Psi^g\\in \\mathbb R^{C_g\\times J}$: $\\Psi^g_{cj}=1$ if product $j$ belongs to nest $c$ and zero otherwise, and each product can only belong to one nest within each group, meaning that $\\sum_{c=1}^{C_g}\\Psi^g_{cj}=1$ for all $j$ and all $g$. The matrix-vector product $\\Psi^gq$ is then\n",
    "$$\n",
    "\\Psi^g q=\\sum_j \\Psi^{g}_{cj}q_j=\\left(\\begin{array}{c}\n",
    "\\sum_{j:\\Psi^g_{1j}=1} q_j \\\\\n",
    "\\vdots \\\\\n",
    "\\sum_{j: \\Psi^g_{C_gj}=1}q_j\n",
    "\\end{array}\\right),\n",
    "$$\n",
    "and the vector $\\Psi^gq$ is a vector of nest-specific choice probabilities, i.e. the sum of the probabilities within each nest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The perturbation function $\\Omega$\n",
    "\n",
    "In the following, a vector $z\\in \\mathbb R^d$ is always a column vector. We now construct the IPDL perturbation function which has the form (where for a vector $z$, the logarithm is applied elementwise and $z'$ denote the transpose)\n",
    "$$\n",
    "\\Omega(q|\\lambda)= (1-\\sum_{g=1}^G \\lambda_g) q'\\ln q +\\sum_{g=1}^{G} \\lambda_g \\left(\\Psi^g q \\right)'\\ln \\left(\\Psi^g q\\right).\n",
    "$$\n",
    "Note that since $\\Psi^g q$ denotes a probability distribution over the nests, the term $(\\Psi^gq)'\\ln (\\Psi^gq)$ is the (negative) entropy of the probability distribution $\\Psi^g q$. Similarly, $q'\\ln q$ is the negative entropy of q. Note also that as each nest has at least one member, and $q$ is strictly positive, $\\Psi^gq$ is also strictly positive. When the parameters $\\lambda_g$ satisfy $\\lambda_g>0$ and\n",
    "$$\n",
    "\\sum_g \\lambda_g<1,\n",
    "$$\n",
    "the function $\\Omega(\\cdot|\\lambda)$ is a strictly convex function of $q$, and the utility maximization problem has a unique interior (meaning strictly positive choice probabilities) solution. If $\\lambda_g = 0$ for all groupings $g$, we immediately see that the  IPDL becomes the standard multinomial Logit model for the choice probabilities $q$. When there is only one group of nests, $G=1$, then $\\Omega$ induces the nested logit choice probabilities (note though that the nested logit model is often parameterized in terms of the nesting parameter $\\mu=1-\\lambda$ instead!). \n",
    "\n",
    "It will be convenient to define a choice probability function for a given vector of payoffs $u$ as\n",
    "$$\n",
    "P(u|\\lambda)=\\arg \\max_{q\\in \\Delta}\\left\\{q'u-\\Omega(q|\\lambda)\\right\\}\n",
    "$$\n",
    "Letting $\\theta$ denote the full vector of parameters, $\\theta=(\\beta',\\lambda')'$, the individual choice probabilities is a function of the matrix $\\mathbf{X}_i$ and the parameters $\\theta$, as\n",
    "$$\n",
    "p(\\mathbf{X}_i,\\theta)=\\arg\\max_{q\\in \\Delta}\\left\\{q'\\mathbf{X}_i \\beta-(1-\\sum_{g=1}^G\\lambda_g)q'\\ln q-\\sum_{g=1}^G\\lambda_g \\left(\\Psi^g q \\right)'\\ln \\left(\\Psi^g q\\right)\\right\\}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-rescaling for numerical stability\n",
    "\n",
    "Let $\\alpha$ be a scalar, and let $\\iota$ be the all-ones vector in $\\mathbb R^J$. Note that $q'(u+\\alpha\\iota)=q'u+(q'\\iota)\\alpha=q'u+\\alpha$, since $q$ sums to one. For this reason, $\\alpha$ does not enter into the utility maximization when calculating $P(u+\\alpha\\iota|\\lambda)$, and we have $P(u+\\alpha\\iota|\\lambda)=P(u|\\lambda)$.\n",
    "\n",
    "This allows us to re-scale the utilities just as in the logit model, since $P(u-(\\max_{j}u_j)\\iota|\\lambda)=P(u|\\lambda)$. The numerical benefits of this approach carry over to the IPDL model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient and Hessian\n",
    "\n",
    "For purposes of computing the gradient and Hessian of $\\Omega$, it is convenient to define\n",
    "$$\n",
    "\\Gamma=\\left(\\begin{array}{c}\n",
    "(1-\\sum_g \\lambda_g)I_J\\\\\n",
    "\\lambda_1 \\Psi^1\\\\\n",
    "\\vdots\\\\\n",
    "\\lambda_G \\Psi^G\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "where $I_J$ is the identity matrix in $\\mathbb R^J$. The matrix $\\Gamma$ is a block matrix with $J+\\sum_g C_g$ rows and $J$ columns. Note that \n",
    "\n",
    "$$\n",
    "\\Gamma q=\\left(\\begin{array}{c}\n",
    "(1-\\sum_g\\lambda_g)q \\\\\n",
    "\\lambda_1\\Psi^g q\\\\\n",
    "\\vdots \\\\\n",
    "\\lambda_G \\Psi^Gq\n",
    "\\end{array}\\right)>0\n",
    "$$\n",
    "if $q>0$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $\\Gamma$, we can show that\n",
    "$$\n",
    "\\Omega(q|\\lambda)=(\\Gamma q)'\\ln (\\Gamma q)+c\\\\\n",
    "\\nabla_q \\Omega(q|\\lambda)=\\Gamma'\\ln (\\Gamma q)+\\iota\\\\\n",
    "\\nabla^2_{qq}\\Omega(q|\\lambda)=\\Gamma'\\mathrm{diag}(\\Gamma q)^{-1}\\Gamma,\n",
    "$$\n",
    "where $c$ is a scalar that depends on $\\lambda$ but not on $q$ and therefore does not affect the utility maximization problem, $\\iota=(1,\\ldots,1)'\\in \\mathbb R^J$ is the all-ones vector and $\\mathrm{diag}(z)$ is a diagonal matrix with the elements of the vector $z$ on the diagonal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we impose on all nests on all markets. We deal with this by setting $\\psi_{tcj} = 0$ for all products $j$ if the nest $c$ was not in fact observed in market $t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_nests(data, markets_id, products_id, columns, cont_var = None, cont_var_bins = None):\n",
    "    '''\n",
    "    This function creates the nest matrices \\Psi^g from any specified columns in data\n",
    "\n",
    "    Args.\n",
    "        data: a pandas DataFrame\n",
    "        markets_id: a string denoting the column of 'data' containing an enumeration t=0,1,...,T-1 of markets\n",
    "        products_id: a string denoting the column of 'data' containing product code which uniquely identifies products\n",
    "        columns: a list containing the column names of columns in 'data' from which nest groupings g=0,1,...,G-1 for each market t are to be generated\n",
    "        cont_var: a list of the continuous variables in 'columns'\n",
    "        caont_var_bins: a list containing the number of bins to make for each continuous variable in 'columns'\n",
    "\n",
    "    Returns\n",
    "        Psi_dict: a dictionary of dictionaries of the Psi_g matrices for each market t and each gropuing g\n",
    "        nest_dict: a dictionary of dictionaries of pandas dataframes describing the structure of each nest for each market t and each grouping g \n",
    "    '''\n",
    "\n",
    "    T = data[markets_id].nunique()\n",
    "    J = np.array([data[data[markets_id] == t][products_id].nunique() for t in np.arange(T)])\n",
    "    G = len(columns)\n",
    "\n",
    "    dat = data.sort_values(by = [markets_id, products_id]) # This is good :)\n",
    "    \n",
    "    Psi_dict = {}\n",
    "    Psi_stack = {}\n",
    "    nest_dict = {}\n",
    "    nest_counts = {}\n",
    "\n",
    "    ### Bin continuous variables\n",
    "\n",
    "    if cont_var == None:\n",
    "        None\n",
    "    else:\n",
    "        for var,n_bins in zip(cont_var,cont_var_bins):\n",
    "            dat[var] = pd.cut(dat[var], bins=n_bins, labels=[str(i) for i in range(1,n_bins +1)], include_lowest=True)\n",
    "\n",
    "    # Assign nests for products in each market t\n",
    "    for t in np.arange(T):\n",
    "        data_t = dat[dat[markets_id] == t]\n",
    "        Psi_dict_t = {}\n",
    "        nest_dict_t = {}\n",
    "        nest_counts_t = np.empty(G)\n",
    "\n",
    "        for g in np.arange(G):\n",
    "            col = columns[g]\n",
    "            vals = pd.DataFrame({'nests' : data_t[col].sort_values().unique()}).reset_index().rename(columns={'index' :'nest_index'})\n",
    "            descr = vals.rename_axis(col, axis='columns')\n",
    "            nest_dict_t[g] = descr\n",
    "            nest_counts_t[g] = len(vals['nests'])\n",
    "            product_enumeration = pd.DataFrame({products_id : data_t[products_id].sort_values().unique(), 'product_enumeration' : np.arange(J[t])})\n",
    "            C_g = data_t[col].nunique()\n",
    "\n",
    "            frame = data_t[[products_id, col]].merge(vals, left_on = col, right_on = 'nests')\n",
    "            allocation = frame[[products_id, 'nest_index']].merge(product_enumeration, on=products_id, how='left')\n",
    "\n",
    "            mat = np.zeros((int(C_g), J[t]))\n",
    "\n",
    "            for c,j in zip(allocation['nest_index'], allocation['product_enumeration']):\n",
    "                mat[c, j] = 1\n",
    "\n",
    "            Psi_dict_t[g] = mat\n",
    "\n",
    "        Psi_dict[t] = Psi_dict_t\n",
    "        nest_dict[t] = nest_dict_t\n",
    "        nest_counts[t] = nest_counts_t\n",
    "        Psi_stack[t] = np.concatenate([np.eye(J[t]) if g==0 else Psi_dict[t][g-1] for g in np.arange(G + 1)])\n",
    "        \n",
    "    return Psi_stack, Psi_dict, nest_dict, nest_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We bin all the continuous explanatory variables different from `pr` (i.e. the price) in 10 bins, and the grouping of `pr` includes 100 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi_stack, Psi_dict, Nest_descr, Nest_count = Create_nests(dat, 'market', 'co', nest_vars, nest_cont_vars, [*[np.int64(10) for i in range(len(nest_cont_vars))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Gamma(Lambda, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function \n",
    "    '''\n",
    "\n",
    "    T = len(psi_stack.keys())\n",
    "\n",
    "    Gamma = {}\n",
    "    lambda0 = 1 - sum(Lambda)\n",
    "    Lambda_full = [lambda0, *Lambda]\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        J = np.int64(psi_stack[t].shape[1])\n",
    "        C = np.int64(J + np.sum(nest_count[t]))\n",
    "        Lambda_long = np.empty((C))\n",
    "        indices = np.concatenate([np.array([J]),nest_count[t]]).cumsum().astype('int')\n",
    "\n",
    "        for i in np.arange(len(indices)):\n",
    "            if i == 0:\n",
    "                Lambda_long[0:(indices[i])] = Lambda_full[i]\n",
    "            else:\n",
    "                Lambda_long[indices[i-1]:indices[i]] = Lambda_full[i]\n",
    "    \n",
    "        Gamma[t] =  np.multiply(Lambda_long[:,None], psi_stack[t])\n",
    "\n",
    "    return Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = len(nest_vars)\n",
    "lambda0 = np.ones((G,))/(G+1)\n",
    "Gamma0 = Create_Gamma(lambda0, Psi_stack, Nest_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model solution\n",
    "\n",
    "While it is possible to solve for the choice probabilities explicitly by maximizing utility, Fosgerau and Nielsen (2021) suggest a contraction mapping approach which is conceptually simpler. Suppose we are evaluating the likelihood at some guess of the parameters $\\theta=(\\beta',\\lambda')$. Let $u_i=\\mathbf{X}_i\\beta$, and let $q_i^0$ denote some initial vector of choice probabilities e.g. $q^0_i=\\frac{e^{u_i}}{\\sum_{j'=1}^Je^{u_{ij'}}}$, we update the choice probabilities according to the formula\n",
    "$$\n",
    "v_i^{k} =u_i+\\ln q_i^{k-1}-\\Gamma'\\ln (\\Gamma q_i^{k-1})\\\\\n",
    "q_i^{k} = \\frac{e^{v_i^{k}}}{\\sum_{j=1}^J e^{v_{ij}^{k}}},\n",
    "$$\n",
    "they show that $\\lim_{k\\rightarrow \\infty}q_i^k=p(\\mathbf{X}_i,\\theta)$ for any starting value $q^0_i$ in the interior of $\\Delta$. For numerical stability, it can be a good idea to also do max-rescaling of $v^k_i$ at every iteration.\n",
    "\n",
    "Let $p$ denote the solution to the utility maximization problem. Formally, the Kullback-Leibler divergence $D_{KL}(p||q)=p'\\ln \\frac{p}{q}$ decays linearly with each iteration,\n",
    "$$\n",
    "D_{KL}(p||q^{k+1})\\leq \\left(1- \\sum_g \\lambda_g \\right)D_{KL}(p||q^k),\n",
    "$$\n",
    "Noting that $(1-\\sum_g \\lambda_g)\\in [0,1)$ by assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_ccp(Beta, x, Gamma, tol = 1.0e-15, maximum_iterations = 1000, MAXRESCALE:bool = True):\n",
    "    ''' \n",
    "    '''\n",
    "\n",
    "    T = len(x)\n",
    "\n",
    "    u = {t: np.dot(x[t], Beta) for t in np.arange(T)}\n",
    "    q = {t: np.exp(u[t]) / np.exp(u[t]).sum() for t in np.arange(T)} # Find logit choice probabilities\n",
    "    q0 = q\n",
    "    \n",
    "    Epsilon = 1.0e-8\n",
    "\n",
    "    for k in range(maximum_iterations):\n",
    "        q1 = {}\n",
    "        for t in np.arange(T):\n",
    "            # Calculate v\n",
    "            gamma_q = np.dot(Gamma[t], q0[t])\n",
    "            log_gammaq = np.log(gamma_q)\n",
    "            gamma_log_prod = np.dot(np.transpose(Gamma[t]), log_gammaq) # Maybe multiply with active_mat???\n",
    "            v = u[t] - gamma_log_prod\n",
    "\n",
    "            # Calculate iterated ccp q^k\n",
    "            denom = np.dot(q0[t], np.exp(v))\n",
    "            inv_denom = np.divide(1, denom)\n",
    "            numerator = np.multiply(q0[t],np.exp(v))\n",
    "            q1[t] = np.multiply(numerator, inv_denom) \n",
    "\n",
    "        # Check convergence in an appropriate distance function\n",
    "        dist = np.max(np.array([np.sum((q1[t]-q0[t])**2/q[t]) for t in np.arange(T)])) # Uses logit weights. This avoids precision issues when q1~q0~0.\n",
    "\n",
    "        if dist<tol:\n",
    "            break\n",
    "        elif k==maximum_iterations:\n",
    "            break\n",
    "        else:\n",
    "            None\n",
    "            \n",
    "        # Iteration step\n",
    "        q0 = q1\n",
    "\n",
    "    return q1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Markets</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Products</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.987011e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.282687e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.803934e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.568958e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.920573e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>5.040531e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3.367840e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.862955e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4.164191e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>9.309149e-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Markets              0\n",
       "Products              \n",
       "0         9.987011e-01\n",
       "1         3.282687e-10\n",
       "2         4.803934e-05\n",
       "3         1.568958e-08\n",
       "4         6.920573e-07\n",
       "...                ...\n",
       "61        5.040531e-11\n",
       "62        3.367840e-06\n",
       "63        6.862955e-07\n",
       "64        4.164191e-09\n",
       "65        9.309149e-06\n",
       "\n",
       "[66 rows x 1 columns]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta0 = -np.ones(K)\n",
    "theta0 = np.append(beta0, lambda0)\n",
    "\n",
    "q0_hat = IPDL_ccp(beta0, x, Gamma0)\n",
    "pd.DataFrame(q0_hat[0]).rename_axis(index='Products', columns='Markets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0[K-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array([np.sum(q0_hat[t]) for t in np.arange(T)]).all() == 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand derivatives and price Elasticity\n",
    "\n",
    "While the demand derivatives in the IPDL model are not quite as simple as in the logit model, they are still easy to compute. \n",
    "Let $q=P(u|\\lambda)$, then\n",
    "$$\n",
    "\\nabla_u P(u|\\lambda)=\\left(\\nabla^2_{qq}\\Omega(q|\\lambda)\\right)^{-1}-qq'\n",
    "$$\n",
    "where the $()^{-1}$ denotes the matrix inverse. The derivatives with respect to any $x_{ij\\ell}$ can now easily be computed by the chain rule,\n",
    "$$\n",
    "    \\frac{\\partial P_j(u_i|\\lambda)}{\\partial x_{ik\\ell}}=\\frac{\\partial P_j(u_i|\\lambda)}{\\partial u_{ik}}\\frac{\\partial u_{ik}}{\\partial x_{ik\\ell}}=\\frac{\\partial P_j(u_i|\\lambda)}{\\partial u_{ik}}\\beta_\\ell,\n",
    "$$\n",
    "\n",
    "Finally, moving to price elasticity is the same as in the logit model, if $x_{ik\\ell}$ is the log price of product $k$ for individual $i$, then\n",
    "$$\n",
    "    \\mathcal{E}_{jk}= \\frac{\\partial P_j(u_i|\\lambda)}{\\partial x_{ik\\ell}}\\frac{1}{P_j(u_i|\\lambda)}=\\frac{\\partial P_j(u_i|\\lambda)}{\\partial u_{ik}}\\frac{1}{P_j(u_i|\\lambda)}\\beta_\\ell=\\frac{\\partial \\ln P_j(u_i|\\lambda)}{\\partial u_{ik}}\\beta_\\ell$$\n",
    "we can also write this compactly as\n",
    "$$\n",
    "\\nabla_u \\ln P(u|\\lambda)=\\mathrm{diag}(P(u|\\lambda))^{-1}\\nabla_u P(u|\\lambda).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pertubation_hessian(q, x, Theta, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calucates the hessian of the pertubation function \\Omega\n",
    "\n",
    "    Args.\n",
    "        q: a (N,J) numpy array of choice probabilities\n",
    "        Lambda: a (G,) numpy array of nesting parameters\n",
    "        Psi: a dictionary of the \\Psi^g matrices as columns as outputted 'Create_incidence_matrix'\n",
    "    \n",
    "    Returns\n",
    "        Hess: a (N,J,J) numpy array of second partial derivatives of the pertubation function \\Omega\n",
    "    '''\n",
    "    \n",
    "    T = len(x.keys())\n",
    "    K = x[0].shape[1]\n",
    "\n",
    "    Gamma = Create_Gamma(Theta[K:], psi_stack, nest_count)\n",
    "    Hess = {}\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        gamma_q = np.dot(Gamma[t], q[t])\n",
    "        inv_gamma_q = la.inv(np.diag(gamma_q))\n",
    "        Hess[t] = np.dot(np.transpose(Gamma[t]), np.dot(inv_gamma_q, Gamma[t]))\n",
    "\n",
    "    return Hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccp_gradient(q, x, Theta, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calucates the gradient of the choice proabilities wrt. characteristics\n",
    "\n",
    "    Args.\n",
    "        q: a (N,J) numpy array of choice probabilities\n",
    "        x: a (N,J,K) numpy array of covariates\n",
    "        Lambda: a (G,) numpy array of nesting parameters\n",
    "        Psi: a dictionary of the \\Psi^g matrices as columns as outputted 'Create_incidence_matrix'\n",
    "    \n",
    "    Returns\n",
    "        Grad: a (N,J,K) numpy array of partial derivatives of the choice proabilities wrt. characteristics\n",
    "    '''\n",
    "\n",
    "    T = len(x.keys())\n",
    "    Grad = {}\n",
    "    Hess = compute_pertubation_hessian(q, x, Theta, psi_stack, nest_count)\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        inv_omega_hess = la.inv(Hess[t]) # (N,J,J) # For each i=1,...,N , computes the inverse of the J*J Hessian\n",
    "        qqT = np.outer(q[t], q[t]) # (N,J,J) outerproduct\n",
    "        Grad[t] = inv_omega_hess - qqT\n",
    "\n",
    "    return Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_u_grad_Log_ccp(q, x, Theta, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calucates the gradient of the log choice proabilities wrt. characteristics\n",
    "\n",
    "    Args.\n",
    "        q: a (N,J) numpy array of choice probabilities\n",
    "        x: a (N,J,J) numpy array of covariates\n",
    "        Theta: a (K+G,) numpy array of IPDL parameters\n",
    "        Psi: a dictionary of the \\Psi^g matrices as columns as outputted 'Create_incidence_matrix'\n",
    "    \n",
    "    Returns\n",
    "        Epsilon: a (N,J,K) numpy array of partial derivatives of the log choice proabilities wrt. characteristics\n",
    "    '''\n",
    "\n",
    "    T = len(x.keys())\n",
    "    Epsilon = {}\n",
    "    Grad = ccp_gradient(q, x, Theta, psi_stack, nest_count)\n",
    "    \n",
    "    for t in np.arange(T):\n",
    "        ccp_grad = Grad[t]\n",
    "        inv_q = np.divide(1, q[t])\n",
    "        Epsilon[t] = np.multiply(inv_q, ccp_grad) # Is equivalent to (1./q)[:,:,None]*ccp_grad an elementwise product. Einsum merely divides through by the nj'th elemnt of q in k'th row of ccp_grad.\n",
    "\n",
    "    return Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_elasticity(q, x, Theta, psi_stack, nest_count, char_number = K-1):\n",
    "    ''' \n",
    "    This function calculates the elasticity of choice probabilities wrt. any characteristic or nest grouping of products\n",
    "\n",
    "    Args.\n",
    "        q: a (N,J) numpy array of choice probabilities\n",
    "        x: a (N,J,K) numpy array of covariates\n",
    "        Theta: a (K+G,) numpy array of IPDL parameters\n",
    "        Psi: a dictionary of the \\Psi^g matrices as columns as outputted 'Create_incidence_matrix'\n",
    "        char_number: an integer which is an index of the parameter in theta wrt. which we wish calculate the elasticity \n",
    "\n",
    "    Returns\n",
    "        an (N,J,J) array of choice probability elasticities\n",
    "    '''\n",
    "    T = len(x.keys())\n",
    "    Epsilon = {}\n",
    "    Grad = IPDL_u_grad_Log_ccp(q, x, Theta, psi_stack, nest_count)\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        Epsilon[t] = np.multiply(Grad[t], Theta[char_number])\n",
    "\n",
    "    return Epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using guess parameters $\\hat \\theta^0$ we calculate price-to-log-income elasticities for individual $i=0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.384880e-03</td>\n",
       "      <td>0.350378</td>\n",
       "      <td>1.109680e+00</td>\n",
       "      <td>1.283409</td>\n",
       "      <td>1.268592</td>\n",
       "      <td>1.880527</td>\n",
       "      <td>0.949445</td>\n",
       "      <td>8.072344e-01</td>\n",
       "      <td>1.565182</td>\n",
       "      <td>1.201342</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855228</td>\n",
       "      <td>0.532607</td>\n",
       "      <td>0.528588</td>\n",
       "      <td>1.037248</td>\n",
       "      <td>1.182221</td>\n",
       "      <td>1.344070</td>\n",
       "      <td>1.148631</td>\n",
       "      <td>0.704435</td>\n",
       "      <td>1.118530</td>\n",
       "      <td>9.347855e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.151676e-10</td>\n",
       "      <td>-17.998314</td>\n",
       "      <td>-3.857470e-08</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>-0.000047</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-4.743218e-05</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000904</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>-0.000088</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>1.550187e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.337763e-05</td>\n",
       "      <td>-0.005645</td>\n",
       "      <td>-2.775001e+00</td>\n",
       "      <td>11.297734</td>\n",
       "      <td>1.068710</td>\n",
       "      <td>-0.361041</td>\n",
       "      <td>-0.230908</td>\n",
       "      <td>-1.737439e-02</td>\n",
       "      <td>-0.216165</td>\n",
       "      <td>0.352210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196368</td>\n",
       "      <td>-0.702731</td>\n",
       "      <td>-0.231749</td>\n",
       "      <td>0.184774</td>\n",
       "      <td>0.403710</td>\n",
       "      <td>0.160491</td>\n",
       "      <td>-0.123999</td>\n",
       "      <td>0.043092</td>\n",
       "      <td>0.054415</td>\n",
       "      <td>-7.546134e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.016234e-08</td>\n",
       "      <td>-0.009472</td>\n",
       "      <td>3.689823e-03</td>\n",
       "      <td>-17.935786</td>\n",
       "      <td>0.001279</td>\n",
       "      <td>0.011631</td>\n",
       "      <td>-0.001379</td>\n",
       "      <td>1.251776e-04</td>\n",
       "      <td>0.012712</td>\n",
       "      <td>-0.002478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0.012403</td>\n",
       "      <td>-0.002294</td>\n",
       "      <td>-0.000931</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>-0.014073</td>\n",
       "      <td>-0.003097</td>\n",
       "      <td>1.070188e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.790798e-07</td>\n",
       "      <td>-0.098853</td>\n",
       "      <td>1.539589e-02</td>\n",
       "      <td>0.056404</td>\n",
       "      <td>-17.202433</td>\n",
       "      <td>-0.027551</td>\n",
       "      <td>0.087942</td>\n",
       "      <td>-1.480753e-02</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>-0.097263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031446</td>\n",
       "      <td>0.018487</td>\n",
       "      <td>0.027712</td>\n",
       "      <td>0.023426</td>\n",
       "      <td>-0.031243</td>\n",
       "      <td>-0.059713</td>\n",
       "      <td>-0.010222</td>\n",
       "      <td>-0.051050</td>\n",
       "      <td>-0.044372</td>\n",
       "      <td>6.224173e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>6.783638e-11</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>1.683958e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>4.787343e-07</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000286</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-8.999680</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-6.898360e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>3.873436e-06</td>\n",
       "      <td>2.368078</td>\n",
       "      <td>-8.693034e-03</td>\n",
       "      <td>3.842040</td>\n",
       "      <td>-0.049746</td>\n",
       "      <td>-3.107066</td>\n",
       "      <td>0.301009</td>\n",
       "      <td>-3.933851e-02</td>\n",
       "      <td>-3.290233</td>\n",
       "      <td>0.706424</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002703</td>\n",
       "      <td>-0.074549</td>\n",
       "      <td>-3.474251</td>\n",
       "      <td>0.626684</td>\n",
       "      <td>0.320281</td>\n",
       "      <td>-0.088501</td>\n",
       "      <td>-4.656054</td>\n",
       "      <td>3.632094</td>\n",
       "      <td>0.800942</td>\n",
       "      <td>-4.343108e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>4.840796e-07</td>\n",
       "      <td>-0.434214</td>\n",
       "      <td>6.156137e-04</td>\n",
       "      <td>-0.615568</td>\n",
       "      <td>-0.050625</td>\n",
       "      <td>7.133336</td>\n",
       "      <td>-0.037170</td>\n",
       "      <td>-1.647416e-02</td>\n",
       "      <td>7.303482</td>\n",
       "      <td>0.299185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007433</td>\n",
       "      <td>0.106391</td>\n",
       "      <td>6.674486</td>\n",
       "      <td>-0.558328</td>\n",
       "      <td>-0.061857</td>\n",
       "      <td>-0.107607</td>\n",
       "      <td>0.740145</td>\n",
       "      <td>-8.371262</td>\n",
       "      <td>0.101073</td>\n",
       "      <td>1.023461e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>4.663830e-09</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>4.716880e-06</td>\n",
       "      <td>-0.000822</td>\n",
       "      <td>-0.000267</td>\n",
       "      <td>-0.001058</td>\n",
       "      <td>-0.000262</td>\n",
       "      <td>3.879182e-03</td>\n",
       "      <td>-0.000667</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000079</td>\n",
       "      <td>0.009172</td>\n",
       "      <td>-0.000323</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000428</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000990</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>-5.937366</td>\n",
       "      <td>8.308803e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>8.713375e-06</td>\n",
       "      <td>4.396071</td>\n",
       "      <td>-1.462303e-02</td>\n",
       "      <td>0.063498</td>\n",
       "      <td>0.837239</td>\n",
       "      <td>1.029903</td>\n",
       "      <td>1.141414</td>\n",
       "      <td>3.408037e-01</td>\n",
       "      <td>-2.075546</td>\n",
       "      <td>6.391887</td>\n",
       "      <td>...</td>\n",
       "      <td>0.145888</td>\n",
       "      <td>-2.775051</td>\n",
       "      <td>-1.339459</td>\n",
       "      <td>0.275029</td>\n",
       "      <td>0.146878</td>\n",
       "      <td>-0.127403</td>\n",
       "      <td>-0.120049</td>\n",
       "      <td>1.388257</td>\n",
       "      <td>1.857453</td>\n",
       "      <td>-3.265905e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows  66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1             2          3          4         5   \\\n",
       "0  -1.384880e-03   0.350378  1.109680e+00   1.283409   1.268592  1.880527   \n",
       "1   1.151676e-10 -17.998314 -3.857470e-08  -0.000198  -0.000047  0.000091   \n",
       "2   5.337763e-05  -0.005645 -2.775001e+00  11.297734   1.068710 -0.361041   \n",
       "3   2.016234e-08  -0.009472  3.689823e-03 -17.935786   0.001279  0.011631   \n",
       "4   8.790798e-07  -0.098853  1.539589e-02   0.056404 -17.202433 -0.027551   \n",
       "..           ...        ...           ...        ...        ...       ...   \n",
       "61  6.783638e-11  -0.000014  1.683958e-07   0.000003  -0.000004 -0.000012   \n",
       "62  3.873436e-06   2.368078 -8.693034e-03   3.842040  -0.049746 -3.107066   \n",
       "63  4.840796e-07  -0.434214  6.156137e-04  -0.615568  -0.050625  7.133336   \n",
       "64  4.663830e-09   0.000822  4.716880e-06  -0.000822  -0.000267 -0.001058   \n",
       "65  8.713375e-06   4.396071 -1.462303e-02   0.063498   0.837239  1.029903   \n",
       "\n",
       "          6             7         8         9   ...        56        57  \\\n",
       "0   0.949445  8.072344e-01  1.565182  1.201342  ...  0.855228  0.532607   \n",
       "1  -0.000103 -4.743218e-05  0.000509  0.000904  ...  0.000036 -0.000222   \n",
       "2  -0.230908 -1.737439e-02 -0.216165  0.352210  ...  0.196368 -0.702731   \n",
       "3  -0.001379  1.251776e-04  0.012712 -0.002478  ...  0.000212 -0.000122   \n",
       "4   0.087942 -1.480753e-02  0.014633 -0.097263  ...  0.031446  0.018487   \n",
       "..       ...           ...       ...       ...  ...       ...       ...   \n",
       "61  0.000001  4.787343e-07 -0.000014 -0.000007  ...  0.000005  0.000015   \n",
       "62  0.301009 -3.933851e-02 -3.290233  0.706424  ... -0.002703 -0.074549   \n",
       "63 -0.037170 -1.647416e-02  7.303482  0.299185  ... -0.007433  0.106391   \n",
       "64 -0.000262  3.879182e-03 -0.000667  0.000940  ... -0.000079  0.009172   \n",
       "65  1.141414  3.408037e-01 -2.075546  6.391887  ...  0.145888 -2.775051   \n",
       "\n",
       "          58        59        60        61        62        63        64  \\\n",
       "0   0.528588  1.037248  1.182221  1.344070  1.148631  0.704435  1.118530   \n",
       "1  -0.000025  0.000130  0.000229 -0.000088  0.000231 -0.000208  0.000065   \n",
       "2  -0.231749  0.184774  0.403710  0.160491 -0.123999  0.043092  0.054415   \n",
       "3   0.012403 -0.002294 -0.000931  0.001022  0.017899 -0.014073 -0.003097   \n",
       "4   0.027712  0.023426 -0.031243 -0.059713 -0.010222 -0.051050 -0.044372   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "61  0.000286  0.000289 -0.000001 -8.999680 -0.000001 -0.000008  0.000001   \n",
       "62 -3.474251  0.626684  0.320281 -0.088501 -4.656054  3.632094  0.800942   \n",
       "63  6.674486 -0.558328 -0.061857 -0.107607  0.740145 -8.371262  0.101073   \n",
       "64 -0.000323 -0.000028 -0.000428  0.000088  0.000990  0.000613 -5.937366   \n",
       "65 -1.339459  0.275029  0.146878 -0.127403 -0.120049  1.388257  1.857453   \n",
       "\n",
       "              65  \n",
       "0   9.347855e-01  \n",
       "1   1.550187e-04  \n",
       "2  -7.546134e-02  \n",
       "3   1.070188e-04  \n",
       "4   6.224173e-02  \n",
       "..           ...  \n",
       "61 -6.898360e-07  \n",
       "62 -4.343108e-02  \n",
       "63  1.023461e-01  \n",
       "64  8.308803e-04  \n",
       "65 -3.265905e+00  \n",
       "\n",
       "[66 rows x 66 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(IPDL_elasticity(q0_hat, x, theta0, Psi_stack, Nest_count)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood estimation of IPDL\n",
    "\n",
    "The log-likelihood contribution is\n",
    "$$\n",
    "\\ell_t(\\theta)=y_t'\\ln p(\\mathbf{X}_t,\\theta),\n",
    "$$\n",
    "and an estimation routine must therefore have a function that - given $\\mathbf{X}_t$ and $\\theta$ - calculates $u_t=\\mathbf{X}_t\\beta$ and constructs $\\Gamma$, and then calls the fixed point routine described above. That routine will return $p(\\mathbf{X}_t,\\theta)$, and we can then evaluate $\\ell_t(\\theta)$. Using our above defined functions we now construct precisely such an estimation procedure.\n",
    "\n",
    "For maximizing the likelihood, we want the derivates at some $\\theta=(\\beta',\\lambda')$. Let $q_t=p(\\mathbf{X}_t,\\theta)$, then we have\n",
    "$$\n",
    "\\nabla_\\theta \\ln p(\\mathbf{X}_t,\\theta)=\\mathrm{diag}(q_t)^{-1}\\left(\\nabla_{qq}^2\\Omega(q_t|\\lambda)^{-1}-q_tq_t' \\right)\\left[\\mathbf{X}_t,-\\nabla_{q,\\lambda}^2 \\Omega(q_t|\\lambda)\\right]\n",
    "$$\n",
    "Note that the first two components is the elasticity $\\nabla_u \\ln P(u|\\lambda)$ and the last term is a block matrix of size $J\\times dim(\\theta)$. Note that the latter cross derivative $\\nabla_{q,\\lambda}^2 \\Omega(q_t|\\lambda)$ is given by $\\nabla_{q,\\lambda}^2 \\Omega(q_t|\\lambda)_g = \\ln(q) - \\Psi^g \\ln(\\Psi^g q)$ for each row $g=1,\\ldots,G$. The derivative of the log-likelihood function can be obtained from this as\n",
    "$$\n",
    "\\nabla_\\theta \\ell_t(\\theta)=\\nabla_\\theta \\ln p(\\mathbf{X}_t,\\theta)' y_t \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_loglikelihood(Theta, y, x, psi_stack, nest_count):\n",
    "    ''' \n",
    "    This function computes the loglikehood contribution for each individual i.\n",
    "    \n",
    "    Args.\n",
    "        Theta: a numpy array (K+G,) of parameters of (\\beta', \\lambda')',\n",
    "        y: a numpy array (N,J) of observed choices in onehot encoding,\n",
    "        x: a numpy matrix (N,J,K) of covariates,\n",
    "        Psi: a dictionary of the matrices \\psi^g as columns as outputted by 'Create_incidence_matrix'\n",
    "\n",
    "    Output\n",
    "        ll: a numpy array (N,) of IPDL loglikelihood contributions\n",
    "    '''\n",
    "\n",
    "    T = len(x.keys())\n",
    "    K = x[0].shape[1]\n",
    "    gamma = Create_Gamma(Theta[K:], psi_stack, nest_count)\n",
    "    ccp_hat = IPDL_ccp(Theta[:K], x, gamma)\n",
    "    ll = np.empty(T)\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        ll[t] = np.dot(y[t], np.log(ccp_hat[t]))\n",
    "\n",
    "    return ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_IPDL(Theta, y, x, psi_stack, nest_count):\n",
    "    ''' \n",
    "    '''\n",
    "    Q = -IPDL_loglikelihood(Theta, y, x, psi_stack, nest_count)\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement the derivative of the loglikehood wrt. parameters $\\nabla_\\theta \\ell_t(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_grad_pertubation(q, psi_stack, nest_count):\n",
    "    ''' \n",
    "    '''\n",
    "\n",
    "    T = len(q.keys())\n",
    "    log_q = {t: np.log(q[t]) for t in np.arange(T)}\n",
    "    Z = {}\n",
    "    \n",
    "    for t in np.arange(T):\n",
    "        G = len(nest_count[t])\n",
    "        indices = np.int64(np.cumsum(nest_count[t]))\n",
    "        J = np.int64(psi_stack[t].shape[0] - np.sum(nest_count[t]))\n",
    "        Z_t = np.empty((J,G))\n",
    "        for g in np.arange(G):\n",
    "\n",
    "            if g == 0:\n",
    "                Psi = psi_stack[t][J:J+indices[g],:]\n",
    "            else:\n",
    "                Psi = psi_stack[t][J+indices[g-1]:J+indices[g],:]\n",
    "\n",
    "            Psi_q = np.dot( Psi, q[t])\n",
    "            log_Psiq = np.log(Psi_q) # IS THIS THE RIGHT WAY TO HANDLE 0's ??? Should be set to 0 if input is 0 since no info is gained from the nest or car if they were not active in the market\n",
    "            Psi_logPsiq = np.dot(np.transpose(Psi), log_Psiq) # possibly hadamard multiply with active_mat ???\n",
    "\n",
    "            Z_t[:,g] = log_q[t] - Psi_logPsiq\n",
    "        \n",
    "        Z[t] = Z_t\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_theta_grad_log_ccp(Theta, x, psi_stack, nest_count):\n",
    "    ''' \n",
    "    '''\n",
    "\n",
    "    T = len(x.keys())\n",
    "    K = x[0].shape[1]\n",
    "\n",
    "    Gamma = Create_Gamma(Theta[K:], psi_stack, nest_count)\n",
    "    q = IPDL_ccp(Theta[:K], x, Gamma)\n",
    "\n",
    "    Z = cross_grad_pertubation(q, psi_stack, nest_count)\n",
    "    G = [np.concatenate((x[t], -Z[t]), axis=1) for t in np.arange(T)]\n",
    "\n",
    "    u_grad = IPDL_u_grad_Log_ccp(q, x, Theta, psi_stack, nest_count)\n",
    "\n",
    "    Grad = {t: np.dot(u_grad[t], G[t]) for t in np.arange(T)} # np.einsum('tjk,tkd->tjd', u_grad, G)\n",
    "\n",
    "    return Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_score(Theta, y, x, psi_stack, nest_count):\n",
    "    ''' \n",
    "    '''\n",
    "    T = len(x.keys())\n",
    "\n",
    "    log_ccp_grad = IPDL_theta_grad_log_ccp(Theta, x, psi_stack, nest_count)\n",
    "    D = log_ccp_grad[0].shape[1]\n",
    "    Score = np.empty((T,D))\n",
    "    \n",
    "    for t in np.arange(T):\n",
    "        Score[t,:] = np.dot(y[t], log_ccp_grad[t])\n",
    "\n",
    "    return Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_IPDL_score(Theta, y, x, psi_stack, nest_count):\n",
    "    ''' \n",
    "    '''\n",
    "\n",
    "    return -IPDL_score(Theta, y, x, psi_stack, nest_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard errors in Maximum Likelihood estimation\n",
    "\n",
    "As usual we may consistently estimate the Covariance Matrix  of the IPDL maximum likelihood estimator for some estimate $\\hat \\theta = (\\hat \\beta', \\hat \\lambda')'\\in \\mathbb{R}^{K+G}$ as:\n",
    "\n",
    "$$\n",
    "\\hat \\Sigma = \\left( \\sum_{i=1}^N \\nabla_\\theta \\ell_i (\\hat \\theta) \\nabla_\\theta \\ell_i (\\hat \\theta)' \\right)^{-1}\n",
    "$$\n",
    "\n",
    "Thereby we may find the estimated standard error of parameter $d$ as the squareroot of the d'th diagonal entry of $\\hat \\Sigma$:\n",
    "\n",
    "$$\n",
    "\\hat \\sigma_d = \\sqrt{\\hat \\Sigma_{dd}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_se(score):\n",
    "    ''' \n",
    "    '''\n",
    "\n",
    "    SE = np.sqrt(np.diag(la.inv(np.einsum('td,tm->dm', score, score))))\n",
    "\n",
    "    return SE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_IPDL(f, Theta0, y, x, psi_stack, nest_count, Analytic_jac:bool = True, options = {'disp': True}, **kwargs):\n",
    "    ''' \n",
    "    Takes a function and returns the minimum, given start values and \n",
    "    variables to calculate the residuals.\n",
    "\n",
    "    Args:\n",
    "    f: a function to minimize,\n",
    "    Theta0 : (K+G,) array of initial guess parameters,\n",
    "    y: a numpy array (N,J) of observed choices in onehot encoding,\n",
    "    x: array of observed explanatory variables (N,J,K),\n",
    "    Psi: dictionary of nesting distributions outputted by 'Create_incidence_matrix',\n",
    "    Analytic_jac: a boolean. Default value is 'True'. If 'True' the analytic jacobian of the IPDL loglikelihood function is used in estimation. Else the numerical jacobian is used.\n",
    "    options: dictionary with options for the optimizer (e.g. disp=True,\n",
    "        which tells it to display information at termination.)\n",
    "    \n",
    "    Returns:\n",
    "        res: a dictionary with results from the estimation.\n",
    "    '''\n",
    "\n",
    "    # The objective function is the average of q(), \n",
    "    # but Q is only a function of one variable, theta, \n",
    "    # which is what minimize() will expect\n",
    "    Q = lambda Theta: np.mean(f(Theta, y, x, psi_stack, nest_count))\n",
    "\n",
    "    if Analytic_jac == True:\n",
    "        Grad = lambda Theta: np.mean(q_IPDL_score(Theta, y, x, psi_stack, nest_count), axis=0) # Finds the Jacobian of Q. Takes mean of criterion q derivatives along axis=0, i.e. the mean across individuals.\n",
    "    else:\n",
    "        Grad = None\n",
    "\n",
    "    # call optimizer\n",
    "    result = optimize.minimize(Q, Theta0.tolist(), options=options, jac=Grad, **kwargs) # optimize.minimize takes a list of parameters Theta0 (not a numpy array) as initial guess.\n",
    "\n",
    "    # collect output in a dict \n",
    "    res = {\n",
    "        'theta': result.x,\n",
    "        'se': IPDL_se(IPDL_score(result.x, y, x, psi_stack, nest_count)),\n",
    "        'success':  result.success, # bool, whether convergence was succesful \n",
    "        'nit':      result.nit, # no. algorithm iterations \n",
    "        'nfev':     result.nfev, # no. function evaluations \n",
    "        'fun':      result.fun # function value at termination \n",
    "    }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_11928\\156226920.py:18: RuntimeWarning: invalid value encountered in log\n",
      "  log_gammaq = np.log(gamma_q) # THIS PROBABLY WILL NOT WORK\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\IPDL_book3.ipynb Cell 65\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m res_IPDL \u001b[39m=\u001b[39m estimate_IPDL(q_IPDL, theta0, y, x, Psi_stack, Nest_count)\n",
      "\u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\IPDL_book3.ipynb Cell 65\u001b[0m in \u001b[0;36mestimate_IPDL\u001b[1;34m(f, Theta0, y, x, psi_stack, nest_count, Analytic_jac, options, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m     Grad \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# call optimizer\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m result \u001b[39m=\u001b[39m optimize\u001b[39m.\u001b[39mminimize(Q, Theta0\u001b[39m.\u001b[39mtolist(), options\u001b[39m=\u001b[39moptions, jac\u001b[39m=\u001b[39mGrad, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m# optimize.minimize takes a list of parameters Theta0 (not a numpy array) as initial guess.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# collect output in a dict \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m res \u001b[39m=\u001b[39m {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtheta\u001b[39m\u001b[39m'\u001b[39m: result\u001b[39m.\u001b[39mx,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mse\u001b[39m\u001b[39m'\u001b[39m: IPDL_se(IPDL_score(result\u001b[39m.\u001b[39mx, y, x, psi_stack, nest_count)),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mfun\u001b[39m\u001b[39m'\u001b[39m:      result\u001b[39m.\u001b[39mfun \u001b[39m# function value at termination \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m }\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_minimize.py:618\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_cg(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    617\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbfgs\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 618\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_bfgs(fun, x0, args, jac, callback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[0;32m    619\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnewton-cg\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    620\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    621\u001b[0m                               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1235\u001b[0m, in \u001b[0;36m_minimize_bfgs\u001b[1;34m(fun, x0, args, jac, callback, gtol, norm, eps, maxiter, disp, return_all, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m   1232\u001b[0m pk \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mdot(Hk, gfk)\n\u001b[0;32m   1233\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1234\u001b[0m     alpha_k, fc, gc, old_fval, old_old_fval, gfkp1 \u001b[39m=\u001b[39m \\\n\u001b[1;32m-> 1235\u001b[0m              _line_search_wolfe12(f, myfprime, xk, pk, gfk,\n\u001b[0;32m   1236\u001b[0m                                   old_fval, old_old_fval, amin\u001b[39m=\u001b[39;49m\u001b[39m1e-100\u001b[39;49m, amax\u001b[39m=\u001b[39;49m\u001b[39m1e100\u001b[39;49m)\n\u001b[0;32m   1237\u001b[0m \u001b[39mexcept\u001b[39;00m _LineSearchError:\n\u001b[0;32m   1238\u001b[0m     \u001b[39m# Line search failed to find a better solution.\u001b[39;00m\n\u001b[0;32m   1239\u001b[0m     warnflag \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\optimize.py:1005\u001b[0m, in \u001b[0;36m_line_search_wolfe12\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, **kwargs)\u001b[0m\n\u001b[0;32m    991\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[39mSame as line_search_wolfe1, but fall back to line_search_wolfe2 if\u001b[39;00m\n\u001b[0;32m    993\u001b[0m \u001b[39msuitable step length is not found, and raise an exception if a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1000\u001b[0m \n\u001b[0;32m   1001\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1003\u001b[0m extra_condition \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m'\u001b[39m\u001b[39mextra_condition\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m-> 1005\u001b[0m ret \u001b[39m=\u001b[39m line_search_wolfe1(f, fprime, xk, pk, gfk,\n\u001b[0;32m   1006\u001b[0m                          old_fval, old_old_fval,\n\u001b[0;32m   1007\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1009\u001b[0m \u001b[39mif\u001b[39;00m ret[\u001b[39m0\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m extra_condition \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1010\u001b[0m     xp1 \u001b[39m=\u001b[39m xk \u001b[39m+\u001b[39m ret[\u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m pk\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:96\u001b[0m, in \u001b[0;36mline_search_wolfe1\u001b[1;34m(f, fprime, xk, pk, gfk, old_fval, old_old_fval, args, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mdot(gval[\u001b[39m0\u001b[39m], pk)\n\u001b[0;32m     94\u001b[0m derphi0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(gfk, pk)\n\u001b[1;32m---> 96\u001b[0m stp, fval, old_fval \u001b[39m=\u001b[39m scalar_search_wolfe1(\n\u001b[0;32m     97\u001b[0m         phi, derphi, old_fval, old_old_fval, derphi0,\n\u001b[0;32m     98\u001b[0m         c1\u001b[39m=\u001b[39;49mc1, c2\u001b[39m=\u001b[39;49mc2, amax\u001b[39m=\u001b[39;49mamax, amin\u001b[39m=\u001b[39;49mamin, xtol\u001b[39m=\u001b[39;49mxtol)\n\u001b[0;32m    100\u001b[0m \u001b[39mreturn\u001b[39;00m stp, fc[\u001b[39m0\u001b[39m], gc[\u001b[39m0\u001b[39m], fval, old_fval, gval[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:172\u001b[0m, in \u001b[0;36mscalar_search_wolfe1\u001b[1;34m(phi, derphi, phi0, old_phi0, derphi0, c1, c2, amax, amin, xtol)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m task[:\u001b[39m2\u001b[39m] \u001b[39m==\u001b[39m \u001b[39mb\u001b[39m\u001b[39m'\u001b[39m\u001b[39mFG\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    171\u001b[0m     alpha1 \u001b[39m=\u001b[39m stp\n\u001b[1;32m--> 172\u001b[0m     phi1 \u001b[39m=\u001b[39m phi(stp)\n\u001b[0;32m    173\u001b[0m     derphi1 \u001b[39m=\u001b[39m derphi(stp)\n\u001b[0;32m    174\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\linesearch.py:84\u001b[0m, in \u001b[0;36mline_search_wolfe1.<locals>.phi\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mphi\u001b[39m(s):\n\u001b[0;32m     83\u001b[0m     fc[\u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 84\u001b[0m     \u001b[39mreturn\u001b[39;00m f(xk \u001b[39m+\u001b[39;49m s\u001b[39m*\u001b[39;49mpk, \u001b[39m*\u001b[39;49margs)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:249\u001b[0m, in \u001b[0;36mScalarFunction.fun\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39marray_equal(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx):\n\u001b[0;32m    248\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 249\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun()\n\u001b[0;32m    250\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:233\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_update_fun\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    232\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated:\n\u001b[1;32m--> 233\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update_fun_impl()\n\u001b[0;32m    234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf_updated \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_fun\u001b[39m():\n\u001b[1;32m--> 137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf \u001b[39m=\u001b[39m fun_wrapped(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\n",
      "File \u001b[1;32mc:\\Users\\mgq977\\Anaconda3\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:134\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnfev \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[39m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[39m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m \u001b[39mreturn\u001b[39;00m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n",
      "\u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\IPDL_book3.ipynb Cell 65\u001b[0m in \u001b[0;36mestimate_IPDL.<locals>.<lambda>\u001b[1;34m(Theta)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m''' \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mTakes a function and returns the minimum, given start values and \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mvariables to calculate the residuals.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m    res: a dictionary with results from the estimation.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# The objective function is the average of q(), \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# but Q is only a function of one variable, theta, \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# which is what minimize() will expect\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m Q \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m Theta: np\u001b[39m.\u001b[39mmean(f(Theta, y, x, psi_stack, nest_count))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mif\u001b[39;00m Analytic_jac \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     Grad \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m Theta: np\u001b[39m.\u001b[39mmean(q_IPDL_score(Theta, y, x, psi_stack, nest_count), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m# Finds the Jacobian of Q. Takes mean of criterion q derivatives along axis=0, i.e. the mean across individuals.\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\IPDL_book3.ipynb Cell 65\u001b[0m in \u001b[0;36mq_IPDL\u001b[1;34m(Theta, y, x, psi_stack, nest_count)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mq_IPDL\u001b[39m(Theta, y, x, psi_stack, nest_count):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m''' \u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     Q \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mIPDL_loglikelihood(Theta, y, x, psi_stack, nest_count)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Q\n",
      "\u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\IPDL_book3.ipynb Cell 65\u001b[0m in \u001b[0;36mIPDL_loglikelihood\u001b[1;34m(Theta, y, x, psi_stack, nest_count)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m K \u001b[39m=\u001b[39m x[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m gamma \u001b[39m=\u001b[39m Create_Gamma(Theta[K:], psi_stack, nest_count)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ccp_hat \u001b[39m=\u001b[39m IPDL_ccp(Theta[:K], x, gamma)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m ll \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(T)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39marange(T):\n",
      "\u001b[1;32mc:\\Users\\mgq977\\OneDrive - University of Copenhagen\\Desktop\\Practice\\GREENCAR_notebooks\\IPDL_book3.ipynb Cell 65\u001b[0m in \u001b[0;36mIPDL_ccp\u001b[1;34m(Beta, x, Gamma, tol, maximum_iterations, MAXRESCALE)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m v \u001b[39m=\u001b[39m u[t] \u001b[39m-\u001b[39m gamma_log_prod\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# Calculate iterated ccp q^k\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m denom \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mdot(q0[t], np\u001b[39m.\u001b[39;49mexp(v))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m inv_denom \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdivide(\u001b[39m1\u001b[39m, denom)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/mgq977/OneDrive%20-%20University%20of%20Copenhagen/Desktop/Practice/GREENCAR_notebooks/IPDL_book3.ipynb#Y130sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m numerator \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmultiply(q0[t],np\u001b[39m.\u001b[39mexp(v))\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res_IPDL = estimate_IPDL(q_IPDL, theta0, y, x, Psi_stack, Nest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IPDL_theta = res_IPDL['theta']\n",
    "Theta_frame = pd.DataFrame({'theta' : IPDL_theta}, index = [*x_vars, *['group' + var for var in nest_vars]]).rename_axis(columns='variables')\n",
    "#Theta_frame.to_csv('IPDL2_Theta.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
