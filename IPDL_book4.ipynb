{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Demand for Cars with the IPDL model\n",
    "\n",
    "In this notebook, we will explore the dataset used in\n",
    "Goldberg & Verboven (2005). We will estimate the IPDL Model\n",
    "model given the available data using the functions defined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "from numpy import linalg as la\n",
    "from scipy import optimize\n",
    "import scipy.stats as scstat\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools as iter\n",
    "import numba as nb\n",
    "\n",
    "# Files\n",
    "import Logit_file as logit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data\n",
    "====\n",
    "\n",
    "The dataset consists of approximately 110 vehicle makes per year in the period 1970-1999 in five european markets (Belgium, France, Germany, Italy, and the United Kingdom). Furthermore, the data contains information on various characteristics of the makes such as sales, prices, horse power, weight and other physical car characteristics. Also these characteristics may vary across markets. \n",
    "\n",
    "A observation in our analysis will be a market in a given year such that e.g. the French car market in 1995 counts as a single observation. If $Y = 30$ is the number of years, and $M = 5$ is the number of country-level markets, we thus have $T=Y\\cdot M = 150$ markets and observations. In addition, since the available vehicle makes vary across time and place, let $\\mathcal{J}_t$ denote the set of available makes in each market $t=1,\\ldots,T$, and let $\\mathcal{J} := \\bigcup_{t=1}^T \\mathcal{J}_t$ be the set of all makes which were available in some market. Then $J:=\\#\\mathcal{J}$ is the number of makes which were available at some point of time in the period in at least one country-level market. In our dataset there are $J = 356$ unique vehicle makes. Note also however that characteristics of vehicle makes vary across markets.\n",
    "\n",
    "Our dataset includes 47 variables in total. The first three columns are market and product codes for the year, country, and make. Another variable is quantity sold (No. of new registrations) which will be used in computing observed market shares. The remaining 43 variables are potential explanatory variables. We will only consider the subset of these which describes car characteristics such as brand, after-tax price, horse power, etc. which adds up to $K=20$ characteristics. The remaining 23 variables are mainly macroeconomic variables such as e.g. GDP per capita which have been used to construct estimates of e.g. the average wage income and purchasing power. Since we are only interested in utility-shifting variables, we will not consider the latter columns. \n",
    "\n",
    "Reading in the dataset `eurocars.csv` we thus have a dataframe of $\\sum_{t=1}^T \\#\\mathcal{J}_t = 11459$ rows and $47$ columns. The `ye` column runs through $y=70,\\ldots,99$, the `ma` column runs through $m=1,\\ldots,M$, and the ``co`` column takes values $j\\in \\mathcal{J}$. \n",
    "\n",
    "Because we consider a country-year pair as the level of observation, we construct a `market` column taking values $t=1,\\ldots,T$. In python, this variable will take values $t=0,\\ldots,T-1$. We also construct a `market_share` variable giving us the market share of any product $j$ in any market $t$; this will obviously take values in $[0,1]$. To deal with the fact that choice sets $\\mathcal{J}_t$ vary across markets, we expand the dataframe so that every car $j\\in \\mathcal{J}$ which was observed in some market $t$ is in the choice set of all other markets as well, i.e. we impose $\\mathcal{J}_t = \\mathcal{J}$ for all markets $t$. We then impute a market share of $q_{jt}=0$ for any car $j$ which in reality was not available in market $t$. To this end we first construct an outside option $j=0$ in each market $t$  of not buying a car by letting the 'sales' of $j=0$ being determined as \n",
    "\n",
    "$$\\mathrm{sales}_{0t} = \\mathrm{pop}_t - \\sum_{j=1}^J \\mathrm{sales}_{jt}$$\n",
    "\n",
    "where $\\mathrm{pop}_t$ is the total population in market $t$.\n",
    "\n",
    "We also read in the variable description of the dataset contained in `eurocars.dta`. We will use the list `x_vars` throughout to work with our explanatory variables.\n",
    "\n",
    "Lastly, we access the underlying 3-dimensional numpy array of the explonatory variables `x` by sorting on `market` and then `co`, and subsequently resizing the explanatory variables as\n",
    "\n",
    "> `x = dat[x_vars].values.resize((T,J,K))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and variable names\n",
    "os.chdir('../GREENCAR_notebooks/')\n",
    "input_path = os.getcwd() # Assigns input path as current working directory (cwd)\n",
    "descr = (pd.read_stata('eurocars.dta', iterator = True)).variable_labels()\n",
    "dat = pd.read_csv(os.path.join(input_path, 'eurocars.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable names</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ye</td>\n",
       "      <td>year (=first dimension of panel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ma</td>\n",
       "      <td>market (=second dimension of panel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>co</td>\n",
       "      <td>model code (=third dimension of panel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zcode</td>\n",
       "      <td>alternative model code (predecessors and succe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>brd</td>\n",
       "      <td>brand code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>type</td>\n",
       "      <td>name of brand and model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>brand</td>\n",
       "      <td>name of brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>model</td>\n",
       "      <td>name of model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>org</td>\n",
       "      <td>origin code (demand side, country with which c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>loc</td>\n",
       "      <td>location code (production side, country where ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cla</td>\n",
       "      <td>class or segment code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home</td>\n",
       "      <td>domestic car dummy (appropriate interaction of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>frm</td>\n",
       "      <td>firm code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>qu</td>\n",
       "      <td>sales (number of new car registrations)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cy</td>\n",
       "      <td>cylinder volume or displacement (in cc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hp</td>\n",
       "      <td>horsepower (in kW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>we</td>\n",
       "      <td>weight (in kg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pl</td>\n",
       "      <td>places (number, not reliable variable)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>do</td>\n",
       "      <td>doors (number, not reliable variable)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>le</td>\n",
       "      <td>length (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>wi</td>\n",
       "      <td>width (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>he</td>\n",
       "      <td>height (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>li1</td>\n",
       "      <td>measure 1 for fuel efficiency (liter per km, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>li2</td>\n",
       "      <td>measure 2 for fuel efficiency (liter per km, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>li3</td>\n",
       "      <td>measure 3 for fuel efficiency (liter per km, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>li</td>\n",
       "      <td>average of li1, li2, li3 (used in papers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sp</td>\n",
       "      <td>maximum speed (km/hour)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ac</td>\n",
       "      <td>time to acceleration (in seconds from 0 to 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>pr</td>\n",
       "      <td>price (in destination currency including V.A.T.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>princ</td>\n",
       "      <td>=pr/(ngdp/pop): price relative to per capita i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>eurpr</td>\n",
       "      <td>=pr/avdexr: price in common currency (in SDR t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>exppr</td>\n",
       "      <td>=pr/avexr: price in exporter currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>avexr</td>\n",
       "      <td>av. exchange rate of exporter country (exporte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>avdexr</td>\n",
       "      <td>av. exchange rate of destination country (dest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>avcpr</td>\n",
       "      <td>av. consumer price index of exporter country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>avppr</td>\n",
       "      <td>av. producer price index of exporter country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>avdcpr</td>\n",
       "      <td>av. consumer price index of destination country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>avdppr</td>\n",
       "      <td>av. producer price index of destination country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>xexr</td>\n",
       "      <td>avdexr/avexr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>tax</td>\n",
       "      <td>percentage VAT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>pop</td>\n",
       "      <td>population</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ngdp</td>\n",
       "      <td>nominal gross domestic product of destination ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>rgdp</td>\n",
       "      <td>real gross domestic product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>engdp</td>\n",
       "      <td>=ngdp/avdexr: nominal gdp in common currency (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ergdp</td>\n",
       "      <td>=rgdp/avexr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>engdpc</td>\n",
       "      <td>=engdp/pop: nominal gdp per capita in common c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ergdpc</td>\n",
       "      <td>=ergdp/pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable names                                        description\n",
       "0              ye                   year (=first dimension of panel)\n",
       "1              ma                market (=second dimension of panel)\n",
       "2              co             model code (=third dimension of panel)\n",
       "3           zcode  alternative model code (predecessors and succe...\n",
       "4             brd                                         brand code\n",
       "5            type                            name of brand and model\n",
       "6           brand                                      name of brand\n",
       "7           model                                      name of model\n",
       "8             org  origin code (demand side, country with which c...\n",
       "9             loc  location code (production side, country where ...\n",
       "10            cla                              class or segment code\n",
       "11           home  domestic car dummy (appropriate interaction of...\n",
       "12            frm                                          firm code\n",
       "13             qu            sales (number of new car registrations)\n",
       "14             cy            cylinder volume or displacement (in cc)\n",
       "15             hp                                 horsepower (in kW)\n",
       "16             we                                     weight (in kg)\n",
       "17             pl             places (number, not reliable variable)\n",
       "18             do              doors (number, not reliable variable)\n",
       "19             le                                     length (in cm)\n",
       "20             wi                                      width (in cm)\n",
       "21             he                                     height (in cm)\n",
       "22            li1  measure 1 for fuel efficiency (liter per km, a...\n",
       "23            li2  measure 2 for fuel efficiency (liter per km, a...\n",
       "24            li3  measure 3 for fuel efficiency (liter per km, a...\n",
       "25             li          average of li1, li2, li3 (used in papers)\n",
       "26             sp                            maximum speed (km/hour)\n",
       "27             ac  time to acceleration (in seconds from 0 to 100...\n",
       "28             pr   price (in destination currency including V.A.T.)\n",
       "29          princ  =pr/(ngdp/pop): price relative to per capita i...\n",
       "30          eurpr  =pr/avdexr: price in common currency (in SDR t...\n",
       "31          exppr              =pr/avexr: price in exporter currency\n",
       "32          avexr  av. exchange rate of exporter country (exporte...\n",
       "33         avdexr  av. exchange rate of destination country (dest...\n",
       "34          avcpr       av. consumer price index of exporter country\n",
       "35          avppr       av. producer price index of exporter country\n",
       "36         avdcpr    av. consumer price index of destination country\n",
       "37         avdppr    av. producer price index of destination country\n",
       "38           xexr                                       avdexr/avexr\n",
       "39            tax                                     percentage VAT\n",
       "40            pop                                         population\n",
       "41           ngdp  nominal gross domestic product of destination ...\n",
       "42           rgdp                        real gross domestic product\n",
       "43          engdp  =ngdp/avdexr: nominal gdp in common currency (...\n",
       "44          ergdp                                        =rgdp/avexr\n",
       "45         engdpc  =engdp/pop: nominal gdp per capita in common c...\n",
       "46         ergdpc                                         =ergdp/pop"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(descr, index=['description']).transpose().reset_index().rename(columns={'index' : 'variable names'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11549 entries, 0 to 11548\n",
      "Data columns (total 47 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   ye      11549 non-null  int64  \n",
      " 1   ma      11549 non-null  int64  \n",
      " 2   co      11549 non-null  int64  \n",
      " 3   zcode   11549 non-null  int64  \n",
      " 4   brd     11549 non-null  int64  \n",
      " 5   type    11549 non-null  object \n",
      " 6   brand   11549 non-null  object \n",
      " 7   model   11521 non-null  object \n",
      " 8   org     11549 non-null  int64  \n",
      " 9   loc     11549 non-null  int64  \n",
      " 10  cla     11549 non-null  int64  \n",
      " 11  home    11549 non-null  int64  \n",
      " 12  frm     11549 non-null  int64  \n",
      " 13  qu      11549 non-null  int64  \n",
      " 14  cy      11549 non-null  object \n",
      " 15  hp      11549 non-null  object \n",
      " 16  we      11549 non-null  int64  \n",
      " 17  pl      11549 non-null  object \n",
      " 18  do      11547 non-null  object \n",
      " 19  le      11549 non-null  object \n",
      " 20  wi      11549 non-null  object \n",
      " 21  he      11549 non-null  object \n",
      " 22  li1     11549 non-null  object \n",
      " 23  li2     11549 non-null  object \n",
      " 24  li3     11549 non-null  object \n",
      " 25  li      11549 non-null  object \n",
      " 26  sp      11545 non-null  object \n",
      " 27  ac      9232 non-null   object \n",
      " 28  pr      11549 non-null  object \n",
      " 29  princ   11549 non-null  object \n",
      " 30  eurpr   11549 non-null  object \n",
      " 31  exppr   11549 non-null  object \n",
      " 32  avexr   11549 non-null  object \n",
      " 33  avdexr  11549 non-null  object \n",
      " 34  avcpr   11549 non-null  object \n",
      " 35  avppr   9836 non-null   object \n",
      " 36  avdcpr  11549 non-null  object \n",
      " 37  avdppr  9492 non-null   object \n",
      " 38  xexr    11549 non-null  object \n",
      " 39  tax     11549 non-null  object \n",
      " 40  pop     11549 non-null  int64  \n",
      " 41  ngdp    11549 non-null  object \n",
      " 42  rgdp    10999 non-null  object \n",
      " 43  engdp   11549 non-null  int64  \n",
      " 44  ergdp   10999 non-null  float64\n",
      " 45  engdpc  11549 non-null  object \n",
      " 46  ergdpc  10999 non-null  object \n",
      "dtypes: float64(1), int64(14), object(32)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "dat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable names</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cy</td>\n",
       "      <td>cylinder volume or displacement (in cc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hp</td>\n",
       "      <td>horsepower (in kW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we</td>\n",
       "      <td>weight (in kg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le</td>\n",
       "      <td>length (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wi</td>\n",
       "      <td>width (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he</td>\n",
       "      <td>height (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>li</td>\n",
       "      <td>average of li1, li2, li3 (used in papers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sp</td>\n",
       "      <td>maximum speed (km/hour)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ac</td>\n",
       "      <td>time to acceleration (in seconds from 0 to 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pr</td>\n",
       "      <td>price (in destination currency including V.A.T.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>home</td>\n",
       "      <td>domestic car dummy (appropriate interaction of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>brand</td>\n",
       "      <td>name of brand</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable names                                        description\n",
       "0              cy            cylinder volume or displacement (in cc)\n",
       "1              hp                                 horsepower (in kW)\n",
       "2              we                                     weight (in kg)\n",
       "3              le                                     length (in cm)\n",
       "4              wi                                      width (in cm)\n",
       "5              he                                     height (in cm)\n",
       "6              li          average of li1, li2, li3 (used in papers)\n",
       "7              sp                            maximum speed (km/hour)\n",
       "8              ac  time to acceleration (in seconds from 0 to 100...\n",
       "9              pr   price (in destination currency including V.A.T.)\n",
       "10           home  domestic car dummy (appropriate interaction of...\n",
       "11          brand                                      name of brand"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine explanatory variables and find variable description as 'x_lab'\n",
    "x_discretevars = ['home', 'brand'] # [ 'brand', 'home', 'cla']\n",
    "x_contvars = ['cy', 'hp', 'we', 'le', 'wi', 'he', 'li', 'sp', 'ac', 'pr']\n",
    "x_orgvars =  [*x_contvars, *x_discretevars]\n",
    "\n",
    "# Outisde is included if OO == True, and is not included else...\n",
    "OO = True\n",
    "\n",
    "# variable descriptions:\n",
    "x_lab = (pd.DataFrame(descr, index=['description'])[x_orgvars].transpose().reset_index().rename(columns={'index' : 'variable names'}))\n",
    "x_lab"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now clean the data to fit our setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we create the 'market' column \n",
    "\n",
    "dat = dat.sort_values(by = ['ye', 'ma'], ascending = True)\n",
    "Used_cols = [*dat.keys()[:28], 'pr', 'princ', 'pop', 'xexr', 'avexr'] \n",
    "dat = dat[Used_cols]\n",
    "market_vals = [*iter.product(dat['ye'].unique(), dat['ma'].unique())]\n",
    "market_vals = pd.DataFrame({'year' : [val[0] for val in market_vals], 'country' : [val[1] for val in market_vals]})\n",
    "market_vals = market_vals.reset_index().rename(columns={'index' : 'market'})\n",
    "dat = dat.merge(market_vals, left_on=['ye', 'ma'], right_on=['year', 'country'], how='left')\n",
    "dat_org = dat # Save the original data with the 'market'-column added as 'dat_org'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We also create an inside/outside-option column if the outside option is included\n",
    "if OO:\n",
    "    dat['in_out'] = 1\n",
    "else:\n",
    "    None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We drop rows which contain NaN values in any explanatory variable or in the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = dat.dropna()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also convert our discrete explanatory variables to integer valued variables and make sure our continuous variables are identified as floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].str.replace(',', '.').astype('float64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].str.replace(',', '.').astype('float64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].str.replace(',', '.').astype('float64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\3139264709.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].str.replace(',', '.').astype('float64')\n"
     ]
    }
   ],
   "source": [
    "obj_columns = dat.select_dtypes(['object'])\n",
    "for col in obj_columns:\n",
    "    if col in [*x_contvars, 'xexr', 'avexr']:\n",
    "        dat[col] = dat[col].str.replace(',', '.').astype('float64')\n",
    "    else:\n",
    "        dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mgq977\\AppData\\Local\\Temp\\ipykernel_2536\\708423628.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n"
     ]
    }
   ],
   "source": [
    "# We reencode all variables such that only the outside option takes the value 0\n",
    "x_0vars = [var for var in x_discretevars if len(dat[(dat['co'] != 0)&(dat[var].isin([0]))]) > 0]\n",
    "\n",
    "for col in x_0vars:\n",
    "    dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Second we construct an outside option for each market t\n",
    "if OO:\n",
    "    outside_shares = dat.groupby('market', as_index=False)['qu'].sum()\n",
    "    outside_shares = outside_shares.merge(dat[['market', 'pop']], on = 'market', how='left').dropna().drop_duplicates(subset = 'market', keep = 'first')\n",
    "    outside_shares['qu'] = outside_shares['pop'] - outside_shares['qu']\n",
    "    keys_add = [key for key in dat.keys() if (key!='market')&(key!='qu')&(key!='pop')]\n",
    "    for key in keys_add:\n",
    "        outside_shares[key] = 0\n",
    "\n",
    "    dat = pd.concat([dat, outside_shares])\n",
    "else:\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Third we compute market shares for each product j in each market t \n",
    "\n",
    "dat['ms'] = dat.groupby('market')['qu'].transform(lambda x: x/x.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the amount of markets and amount of alternatives for each market\n",
    "T = dat['market'].nunique()\n",
    "J = np.array([dat[dat['market'] == t]['co'].nunique() for t in np.arange(T)])\n",
    "\n",
    "# number of observations\n",
    "if OO:\n",
    "    N = np.array([dat[dat['market'] == t]['pop'].unique().sum() for t in np.arange(T)]).sum()\n",
    "else:\n",
    "    N = np.array([len(dat[dat['market'] == t]['co']) for t in np.arange(T)]).sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also scale values such that they lie in the interval $[-1,1]$. This has various numerical benefits. Also, this will not affect elasticities or diversion ratios, but semielasticities will be affected by the scaling.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat[x_contvars] = dat[x_contvars] / dat[x_contvars].abs().max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We encode the discete variables as onehot encoded variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_disc = pd.get_dummies(dat[x_discretevars], prefix = x_discretevars, columns=x_discretevars, drop_first=True) # Drop the outside option column when constructing dummies of discrete variables\n",
    "dat_disc = dat_disc[[var for var in dat_disc.keys() if not var.endswith('1')]] # Drops a second column from discrete columns to identify parameters\n",
    "x_disc_ohkeys = dat_disc.keys()\n",
    "dat = pd.concat([dat, dat_disc], axis = 1)\n",
    "\n",
    "if OO:\n",
    "    x_vars = ['in_out', *x_contvars, *x_disc_ohkeys]\n",
    "else:\n",
    "    x_vars = [*x_contvars, *x_disc_ohkeys]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find also the number of explanatory variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(x_vars)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will primarily use numpy data types and numpy functions in this notebook. Hence we store our response variable 'y' and our explanatory variables 'x' as numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create numpy arrays of response and explanatory variables\n",
    "dat = dat.reset_index(drop = True).sort_values(by = ['market', 'co']) # Sort data so that reshape is successfull\n",
    "\n",
    "x = {t: dat[dat['market'] == t][x_vars].values.reshape((J[t],K)) for t in np.arange(T)}\n",
    "y = {t: dat[dat['market'] == t]['ms'].to_numpy().reshape((J[t])) for t in np.arange(T)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OO:\n",
    "    nest_vars = [var for var in ['in_out', *x_orgvars] if (var != 'pr')]\n",
    "else:\n",
    "    nest_vars = [var for var in x_orgvars if (var != 'pr')] # ['cy', 'hp', 'we', 'le', 'wi', 'he', 'li', 'sp', 'ac']  we will nest on variables which are not price, brand, model.\n",
    "nest_cont_vars = ['cy', 'hp', 'we', 'le', 'wi', 'he', 'li', 'sp', 'ac']\n",
    "\n",
    "G = len(nest_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check if our specififcation of the model is operational, we stack the design matrices $X_t$ of markets $t$ on top of each other to get the $\\sum_t J_t$ by $K$ matrix $X^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_star = np.concatenate([x[t] for t in np.arange(T)], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.18172094e+04 1.51194245e+03 8.33480907e+02 6.63621704e+02\n",
      " 6.19596331e+02 5.73576387e+02 5.55397509e+02 5.05398845e+02\n",
      " 4.24525878e+02 3.84850081e+02 3.00287423e+02 3.02063419e+02\n",
      " 2.59006551e+02 2.45676682e+02 2.26642105e+02 2.16253594e+02\n",
      " 1.96773303e+02 1.86193568e+02 1.77215039e+02 1.59428915e+02\n",
      " 1.51168124e+02 1.08441640e+02 9.02903234e+01 7.80017834e+01\n",
      " 6.10956434e+01 5.50035617e+01 5.17804496e+01 4.85116902e+01\n",
      " 4.69232106e+01 4.48465462e+01 4.34297582e+01 3.49478996e+01\n",
      " 2.78010403e+01 2.39853311e+01 1.55948562e+01 1.11374929e+01\n",
      " 1.00237547e+01 6.43942208e+00 9.97646233e-01 1.52561673e+00\n",
      " 4.21540233e+00 2.64853391e+00 2.99504916e+00 2.86137167e+00]\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(x_star)\n",
    "\n",
    "XTX=x_star.T@x_star\n",
    "[e,v]=la.eig(XTX)\n",
    "print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.89380531e-01, 3.48082596e-01, 5.49738220e-01,\n",
       "        9.07114625e-01, 9.20212766e-01, 8.81987578e-01, 4.94444423e-01,\n",
       "        6.31578947e-01, 2.70000000e-01, 1.28470526e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.46902655e-01, 2.38938053e-01, 4.10994764e-01,\n",
       "        7.60869565e-01, 8.45744681e-01, 8.81987578e-01, 4.44444444e-01,\n",
       "        5.46558704e-01, 3.82000008e-01, 7.48964950e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.42920354e-01, 1.74041298e-01, 4.31937173e-01,\n",
       "        7.86561265e-01, 8.35106383e-01, 8.57142857e-01, 4.55555545e-01,\n",
       "        5.06072874e-01, 5.67999992e-01, 6.95390919e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.87168142e-01, 2.33038348e-01, 4.60732984e-01,\n",
       "        8.43873518e-01, 8.77659574e-01, 8.63354037e-01, 5.22222201e-01,\n",
       "        5.30364372e-01, 3.92000008e-01, 8.15932488e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 4.39823009e-01, 4.12979351e-01, 6.96335079e-01,\n",
       "        9.25889328e-01, 9.41489362e-01, 8.94409938e-01, 6.05555534e-01,\n",
       "        6.47773279e-01, 3.03999996e-01, 1.80008743e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.38495575e-01, 1.94690265e-01, 3.90052356e-01,\n",
       "        8.11264822e-01, 8.35106383e-01, 8.69565217e-01, 4.87037023e-01,\n",
       "        5.06072874e-01, 5.20000000e-01, 7.16820531e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.30088496e-01, 1.74041298e-01, 5.36649215e-01,\n",
       "        8.99209486e-01, 9.30851064e-01, 9.06832298e-01, 5.83333333e-01,\n",
       "        5.78947368e-01, 4.40000000e-01, 9.63261073e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 5.50884956e-01, 5.22123894e-01, 5.99476440e-01,\n",
       "        9.03162055e-01, 9.30851064e-01, 8.97515528e-01, 7.22222222e-01,\n",
       "        7.16599190e-01, 2.40000000e-01, 1.38863888e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.97345133e-01, 3.30383481e-01, 6.28272251e-01,\n",
       "        8.87351779e-01, 8.98936170e-01, 9.06832298e-01, 6.44444466e-01,\n",
       "        6.31578947e-01, 2.96000004e-01, 1.31149227e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.84955752e-01, 2.53687316e-01, 4.79057592e-01,\n",
       "        8.18181818e-01, 8.35106383e-01, 8.75776398e-01, 5.61111132e-01,\n",
       "        6.07287449e-01, 3.12000008e-01, 1.05112248e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.25221239e-01, 2.38938053e-01, 5.13089005e-01,\n",
       "        8.35968379e-01, 8.77659574e-01, 9.03726708e-01, 5.55555556e-01,\n",
       "        5.74898785e-01, 4.00000000e-01, 9.63261073e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.85176991e-01, 2.33038348e-01, 4.60732984e-01,\n",
       "        8.57707510e-01, 8.69680851e-01, 8.91304348e-01, 4.58333333e-01,\n",
       "        5.66801619e-01, 3.40000000e-01, 8.56113011e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 1.87610619e-01, 1.50442478e-01, 3.31937173e-01,\n",
       "        6.02766798e-01, 7.50000000e-01, 8.38509317e-01, 4.16666667e-01,\n",
       "        4.77732794e-01, 5.20000000e-01, 6.41816888e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        1.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.78097345e-01, 3.48082596e-01, 5.60209424e-01,\n",
       "        8.60671937e-01, 8.90957447e-01, 9.00621118e-01, 5.00000000e-01,\n",
       "        6.27530364e-01, 2.90000000e-01, 1.36613778e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.63716814e-01, 1.47492625e-01, 3.97905759e-01,\n",
       "        8.04347826e-01, 8.24468085e-01, 9.31677019e-01, 4.16666667e-01,\n",
       "        4.65587045e-01, 7.40000000e-01, 6.41816888e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 1.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.85398230e-01, 3.39233038e-01, 5.23560209e-01,\n",
       "        8.22134387e-01, 8.29787234e-01, 8.88198758e-01, 5.38888878e-01,\n",
       "        6.27530364e-01, 3.27999992e-01, 1.16737813e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 1.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.60398230e-01, 2.38938053e-01, 3.71727749e-01,\n",
       "        7.90513834e-01, 7.97872340e-01, 8.63354037e-01, 4.33333344e-01,\n",
       "        5.82995951e-01, 2.90000000e-01, 8.62541895e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 3.30973451e-01, 2.38938053e-01, 4.94764398e-01,\n",
       "        8.65612648e-01, 8.67021277e-01, 9.00621118e-01, 4.83333323e-01,\n",
       "        5.58704453e-01, 3.60000000e-01, 9.84690685e-04, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.00000000e+00, 2.20353982e-01, 1.74041298e-01, 3.45549738e-01,\n",
       "        7.49011858e-01, 7.92553191e-01, 8.44720497e-01, 4.33333344e-01,\n",
       "        5.26315789e-01, 4.00000000e-01, 1.18934348e-03, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 1.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_star[0:20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44, 44)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XTX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get each market's share of total population N\n",
    "pop_share = np.empty((T,))\n",
    "for t in np.arange(T):\n",
    "    pop_share[t] = dat[dat['market'] == t]['qu'].sum() / N"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multinomial Logit - for comparison\n",
    "Estimating a Logit model via maximum likelihood with an initial guess of parameters $\\hat \\beta^0 = 0$ yields estimated parameters $\\hat \\beta^{\\text{logit}}$ given as..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001546\n",
      "         Iterations: 24\n",
      "         Function evaluations: 35\n",
      "         Gradient evaluations: 35\n"
     ]
    }
   ],
   "source": [
    "beta_0 = np.ones((K,))\n",
    "\n",
    "# Estimate the model\n",
    "res_logit = logit.estimate_logit(logit.q_logit, beta_0, y, x, sample_share=pop_share, Analytic_jac=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parameters</th>\n",
       "      <th>se</th>\n",
       "      <th>t</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in_out</th>\n",
       "      <td>-2.435520</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>9.331757e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cy</th>\n",
       "      <td>-0.246269</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>1.399485e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hp</th>\n",
       "      <td>-0.383298</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>1.831138e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>-0.857401</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>5.347850e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>-1.827391</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>9.928522e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wi</th>\n",
       "      <td>-1.982906</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>8.367728e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>-1.995376</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>8.380812e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>li</th>\n",
       "      <td>-0.651964</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>6.701176e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp</th>\n",
       "      <td>-1.307546</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>6.105287e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac</th>\n",
       "      <td>-0.028687</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>3.546958e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr</th>\n",
       "      <td>0.853000</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>7.639898e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_2</th>\n",
       "      <td>1.748739</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.720742e+06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_2</th>\n",
       "      <td>0.994770</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>9.050312e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_3</th>\n",
       "      <td>0.982633</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>3.472632e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_4</th>\n",
       "      <td>0.822876</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.436044e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_5</th>\n",
       "      <td>0.785866</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.250364e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_6</th>\n",
       "      <td>0.676757</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.821371e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_7</th>\n",
       "      <td>0.957136</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>5.280731e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_8</th>\n",
       "      <td>0.964829</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>5.505948e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_9</th>\n",
       "      <td>0.902017</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.030605e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_10</th>\n",
       "      <td>0.718795</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.912909e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_12</th>\n",
       "      <td>0.869615</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>8.107208e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_13</th>\n",
       "      <td>0.928533</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>3.022436e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_14</th>\n",
       "      <td>0.938058</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>2.738807e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_15</th>\n",
       "      <td>0.960477</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>5.552782e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_16</th>\n",
       "      <td>0.663666</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.813020e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_17</th>\n",
       "      <td>0.835205</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>6.854635e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_18</th>\n",
       "      <td>0.897989</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>1.461451e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_19</th>\n",
       "      <td>0.898449</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>5.812611e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_20</th>\n",
       "      <td>0.893840</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>6.055550e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_22</th>\n",
       "      <td>0.786022</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.097351e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_23</th>\n",
       "      <td>0.941038</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.682740e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_24</th>\n",
       "      <td>0.499198</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.627773e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_25</th>\n",
       "      <td>0.862370</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>3.019440e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_26</th>\n",
       "      <td>0.788905</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>6.502043e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_27</th>\n",
       "      <td>0.998703</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>7.663771e+03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_28</th>\n",
       "      <td>0.964244</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>2.035033e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_29</th>\n",
       "      <td>0.988190</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>6.141674e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_30</th>\n",
       "      <td>0.941987</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.297757e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_32</th>\n",
       "      <td>0.957041</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>1.983136e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_33</th>\n",
       "      <td>0.997923</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.335403e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_34</th>\n",
       "      <td>0.874886</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>2.310989e+05</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_35</th>\n",
       "      <td>0.866875</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>6.407770e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_36</th>\n",
       "      <td>0.796791</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>5.749492e+04</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          parameters        se             t    p\n",
       "in_out     -2.435520  0.000026  9.331757e+04  0.0\n",
       "cy         -0.246269  0.000018  1.399485e+04  0.0\n",
       "hp         -0.383298  0.000021  1.831138e+04  0.0\n",
       "we         -0.857401  0.000016  5.347850e+04  0.0\n",
       "le         -1.827391  0.000018  9.928522e+04  0.0\n",
       "wi         -1.982906  0.000024  8.367728e+04  0.0\n",
       "he         -1.995376  0.000024  8.380812e+04  0.0\n",
       "li         -0.651964  0.000010  6.701176e+04  0.0\n",
       "sp         -1.307546  0.000021  6.105287e+04  0.0\n",
       "ac         -0.028687  0.000008  3.546958e+03  0.0\n",
       "pr          0.853000  0.000011  7.639898e+04  0.0\n",
       "home_2      1.748739  0.000001  1.720742e+06  0.0\n",
       "brand_2     0.994770  0.000011  9.050312e+04  0.0\n",
       "brand_3     0.982633  0.000003  3.472632e+05  0.0\n",
       "brand_4     0.822876  0.000006  1.436044e+05  0.0\n",
       "brand_5     0.785866  0.000002  3.250364e+05  0.0\n",
       "brand_6     0.676757  0.000004  1.821371e+05  0.0\n",
       "brand_7     0.957136  0.000018  5.280731e+04  0.0\n",
       "brand_8     0.964829  0.000018  5.505948e+04  0.0\n",
       "brand_9     0.902017  0.000009  1.030605e+05  0.0\n",
       "brand_10    0.718795  0.000004  1.912909e+05  0.0\n",
       "brand_12    0.869615  0.000011  8.107208e+04  0.0\n",
       "brand_13    0.928533  0.000031  3.022436e+04  0.0\n",
       "brand_14    0.938058  0.000003  2.738807e+05  0.0\n",
       "brand_15    0.960477  0.000017  5.552782e+04  0.0\n",
       "brand_16    0.663666  0.000004  1.813020e+05  0.0\n",
       "brand_17    0.835205  0.000012  6.854635e+04  0.0\n",
       "brand_18    0.897989  0.000006  1.461451e+05  0.0\n",
       "brand_19    0.898449  0.000015  5.812611e+04  0.0\n",
       "brand_20    0.893840  0.000015  6.055550e+04  0.0\n",
       "brand_22    0.786022  0.000004  2.097351e+05  0.0\n",
       "brand_23    0.941038  0.000004  2.682740e+05  0.0\n",
       "brand_24    0.499198  0.000003  1.627773e+05  0.0\n",
       "brand_25    0.862370  0.000029  3.019440e+04  0.0\n",
       "brand_26    0.788905  0.000012  6.502043e+04  0.0\n",
       "brand_27    0.998703  0.000130  7.663771e+03  0.0\n",
       "brand_28    0.964244  0.000047  2.035033e+04  0.0\n",
       "brand_29    0.988190  0.000016  6.141674e+04  0.0\n",
       "brand_30    0.941987  0.000007  1.297757e+05  0.0\n",
       "brand_32    0.957041  0.000005  1.983136e+05  0.0\n",
       "brand_33    0.997923  0.000007  1.335403e+05  0.0\n",
       "brand_34    0.874886  0.000004  2.310989e+05  0.0\n",
       "brand_35    0.866875  0.000014  6.407770e+04  0.0\n",
       "brand_36    0.796791  0.000014  5.749492e+04  0.0"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_beta = res_logit['beta']\n",
    "logit_score = logit.logit_score(logit_beta, y, x, pop_share) # maybe use 'logit.' functions from Logit_file instead of including e.g. standard errors in logit.estimate_logit function\n",
    "logit_se = logit.logit_se(logit_score, N)\n",
    "logit_t, logit_p = logit.logit_t_p(logit_beta, logit_score, N)\n",
    "pd.DataFrame({'parameters': logit_beta, 'se' : logit_se, 't': logit_t, 'p': logit_p}, index = x_vars) # Our estimates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute the corresponding Logit choice probabilities. STILL FIX THIS PART IN LOGIT BOOK!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_q = logit.logit_ccp(logit_beta, x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also find the elasticities and diversion ratios implied by the logit model as follows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_logit = logit.logit_elasticity(logit_q, logit_beta, K-1) # Elasticities wrt. the price characteristic\n",
    "DR_logit_hat = logit.logit_diversion_ratio(logit_q, logit_beta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The IPDL model - Nesting structure\n",
    "\n",
    "The IPDL model is a generalization of the nested logit model where each alternative may belong to more than one nest. Before fully introducing the model, we construct the nesting structure.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing nests\n",
    "\n",
    "Let $\\Delta=\\left\\{q\\in \\mathbb{R}^J_+: \\sum_{j=1}^J q_j=1\\right\\}$ denote the probability simplex. For each group of nests $g=1,\\ldots, G$, nest membership is denoted by the matrix $\\Psi^g\\in \\mathbb R^{C_g\\times J}$: $\\Psi^g_{cj}=1$ if product $j$ belongs to nest $c$ and zero otherwise, and each product can only belong to one nest within each group, meaning that $\\sum_{c=1}^{C_g}\\Psi^g_{cj}=1$ for all $j$ and all $g$. The matrix-vector product $\\Psi^gq$ is then\n",
    "$$\n",
    "\\Psi^g q=\\sum_j \\Psi^{g}_{cj}q_j=\\left(\\begin{array}{c}\n",
    "\\sum_{j:\\Psi^g_{1j}=1} q_j \\\\\n",
    "\\vdots \\\\\n",
    "\\sum_{j: \\Psi^g_{C_gj}=1}q_j\n",
    "\\end{array}\\right),\n",
    "$$\n",
    "and the vector $\\Psi^gq$ is a vector of nest-specific choice probabilities, i.e. the sum of the probabilities within each nest."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The perturbation function $\\Omega$\n",
    "\n",
    "In the following, a vector $z\\in \\mathbb R^d$ is always a column vector. We now construct the IPDL perturbation function which has the form (where for a vector $z$, the logarithm is applied elementwise and $z'$ denote the transpose)\n",
    "$$\n",
    "\\Omega(q|\\lambda)= (1-\\sum_{g=1}^G \\lambda_g) q'\\ln q +\\sum_{g=1}^{G} \\lambda_g \\left(\\Psi^g q \\right)'\\ln \\left(\\Psi^g q\\right).\n",
    "$$\n",
    "Note that since $\\Psi^g q$ denotes a probability distribution over the nests, the term $(\\Psi^gq)'\\ln (\\Psi^gq)$ is the (negative) entropy of the probability distribution $\\Psi^g q$. Similarly, $q'\\ln q$ is the negative entropy of q. Note also that as each nest has at least one member, and $q$ is strictly positive, $\\Psi^gq$ is also strictly positive. When the parameters $\\lambda_g$ satisfy $\\lambda_g>0$ and\n",
    "$$\n",
    "\\sum_g \\lambda_g<1,\n",
    "$$\n",
    "the function $\\Omega(\\cdot|\\lambda)$ is a strictly convex function of $q$, and the utility maximization problem has a unique interior (meaning strictly positive choice probabilities) solution. If $\\lambda_g = 0$ for all groupings $g$, we immediately see that the  IPDL becomes the standard multinomial Logit model for the choice probabilities $q$. When there is only one group of nests, $G=1$, then $\\Omega$ induces the nested logit choice probabilities (note though that the nested logit model is often parameterized in terms of the nesting parameter $\\mu=1-\\lambda$ instead!). \n",
    "\n",
    "It will be convenient to define a choice probability function for a given vector of payoffs $u$ as\n",
    "$$\n",
    "P(u|\\lambda)=\\arg \\max_{q\\in \\Delta}\\left\\{q'u-\\Omega(q|\\lambda)\\right\\}\n",
    "$$\n",
    "Letting $\\theta$ denote the full vector of parameters, $\\theta=(\\beta',\\lambda')'$, the individual choice probabilities is a function of the matrix $\\mathbf{X}_i$ and the parameters $\\theta$, as\n",
    "$$\n",
    "p(\\mathbf{X}_i,\\theta)=\\arg\\max_{q\\in \\Delta}\\left\\{q'\\mathbf{X}_i \\beta-(1-\\sum_{g=1}^G\\lambda_g)q'\\ln q-\\sum_{g=1}^G\\lambda_g \\left(\\Psi^g q \\right)'\\ln \\left(\\Psi^g q\\right)\\right\\}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-rescaling for numerical stability\n",
    "\n",
    "Let $\\alpha$ be a scalar, and let $\\iota$ be the all-ones vector in $\\mathbb R^J$. Note that $q'(u+\\alpha\\iota)=q'u+(q'\\iota)\\alpha=q'u+\\alpha$, since $q$ sums to one. For this reason, $\\alpha$ does not enter into the utility maximization when calculating $P(u+\\alpha\\iota|\\lambda)$, and we have $P(u+\\alpha\\iota|\\lambda)=P(u|\\lambda)$.\n",
    "\n",
    "This allows us to re-scale the utilities just as in the logit model, since $P(u-(\\max_{j}u_j)\\iota|\\lambda)=P(u|\\lambda)$. The numerical benefits of this approach carry over to the IPDL model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient and Hessian\n",
    "\n",
    "For purposes of computing the gradient and Hessian of $\\Omega$, it is convenient to define\n",
    "$$\n",
    "\\Gamma=\\left(\\begin{array}{c}\n",
    "(1-\\sum_g \\lambda_g)I_J\\\\\n",
    "\\lambda_1 \\Psi^1\\\\\n",
    "\\vdots\\\\\n",
    "\\lambda_G \\Psi^G\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "where $I_J$ is the identity matrix in $\\mathbb R^J$. The matrix $\\Gamma$ is a block matrix with $J+\\sum_g C_g$ rows and $J$ columns. Note that \n",
    "\n",
    "$$\n",
    "\\Gamma q=\\left(\\begin{array}{c}\n",
    "(1-\\sum_g\\lambda_g)q \\\\\n",
    "\\lambda_1\\Psi^g q\\\\\n",
    "\\vdots \\\\\n",
    "\\lambda_G \\Psi^Gq\n",
    "\\end{array}\\right)>0\n",
    "$$\n",
    "if $q>0$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using $\\Gamma$, we can show that\n",
    "$$\n",
    "\\Omega(q|\\lambda)=(\\Gamma q)'\\ln (\\Gamma q)+c\\\\\n",
    "\\nabla_q \\Omega(q|\\lambda)=\\Gamma'\\ln (\\Gamma q)+\\iota\\\\\n",
    "\\nabla^2_{qq}\\Omega(q|\\lambda)=\\Gamma'\\mathrm{diag}(\\Gamma q)^{-1}\\Gamma,\n",
    "$$\n",
    "where $c$ is a scalar that depends on $\\lambda$ but not on $q$ and therefore does not affect the utility maximization problem, $\\iota=(1,\\ldots,1)'\\in \\mathbb R^J$ is the all-ones vector and $\\mathrm{diag}(z)$ is a diagonal matrix with the elements of the vector $z$ on the diagonal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following we impose on all nests on all markets. We deal with this by setting $\\psi_{tcj} = 0$ for all products $j$ if the nest $c$ was not in fact observed in market $t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def Create_nests_old(data, markets_id, products_id, columns, cont_var = None, cont_var_bins = None, outside_option = True):\n",
    "    '''\n",
    "    This function creates the nest matrices \\Psi^g from any specified columns of the dataset\n",
    "\n",
    "    Args.\n",
    "        data: a pandas DataFrame\n",
    "        markets_id: a string denoting the column of 'data' containing an enumeration t=0,1,...,T-1 of markets\n",
    "        products_id: a string denoting the column of 'data' containing product codes which uniquely identifies products\n",
    "        columns: a list containing the column names of columns in 'data' from which nest groupings g=0,1,...,G-1 for each market t are to be generated\n",
    "        cont_var: a list of the continuous variables in 'columns'\n",
    "        cont_var_bins: a list containing the number of bins to make for each continuous variable in 'columns'\n",
    "        outside_option: a boolean indicating whether the model is estimated with or without an outside option. Default is set to 'True' i.e. with an outside option.\n",
    "\n",
    "    Returns\n",
    "        Psi_stack: a dictionary of length T of dictionaries of the Psi_g matrices for each market t and each gropuing g\n",
    "        nest_dict: a dictionary of length T of dictionaries of pandas dataframes describing the structure of each nest for each market t and each grouping g\n",
    "        nest_count: a dictionary of length T of (G,) numpy arrays containing the amount of nests in each category\n",
    "    '''\n",
    "\n",
    "    T = data[markets_id].nunique()\n",
    "    J = np.array([data[data[markets_id] == t][products_id].nunique() for t in np.arange(T)])\n",
    "    \n",
    "    # We nest on outside vs. inside options. The amount of categories varies if the outside option is included in the analysis.\n",
    "\n",
    "    if outside_option == True:\n",
    "        G = np.int64(len(columns) + 1)\n",
    "    else:\n",
    "        G = len(columns)\n",
    "\n",
    "    dat = data.sort_values(by = [markets_id, products_id]) # This is good :)\n",
    "    \n",
    "    Psi_dict = {}\n",
    "    Psi_stack = {}\n",
    "    nest_dict = {}\n",
    "    nest_counts = {}\n",
    "\n",
    "    ### Bin continuous variables according to quantiles of the variable\n",
    "\n",
    "    if cont_var == None:\n",
    "        None\n",
    "    else:\n",
    "        for var,n_bins in zip(cont_var,cont_var_bins):\n",
    "            if outside_option:\n",
    "                q_dat = np.quantile(dat[var].rank(method = 'first'), q = np.arange(1,n_bins + 1) / n_bins)\n",
    "                dat[var] = pd.cut(dat[var].rank(method = 'first'), bins = [0.99, 1, *q_dat], labels=False) # Quantiles are equally spaced with 'n_bins' quantiles for the variable. The outside option gets its own bin (0.99,1].\n",
    "            else:\n",
    "                dat[var] = pd.qcut(dat[var].rank(method = 'first'), q = n_bins, labels=False)\n",
    "\n",
    "    # Assign nests for products in each market t\n",
    "    for t in np.arange(T):\n",
    "        data_t = dat[dat[markets_id] == t] # Subset data on market t\n",
    "        Psi_dict_t = {}\n",
    "        nest_dict_t = {}\n",
    "        nest_counts_t = np.empty(G)\n",
    "\n",
    "        # For each category/group g we create a \\psi^g matrix plus related descriptions and the amount of nests in category g\n",
    "        for g in np.arange(G):\n",
    "            if (outside_option == True)&(g == 0): # If the outside option is included, we set the first category to be the outside/inside option nest.\n",
    "                mat = np.zeros((2, J[t]))\n",
    "                mat[0,0] = 1 # The outside option is set to one in the outside option nest\n",
    "                mat[1,1:] = 1 # All other products are set to one in the inside option nest\n",
    "\n",
    "                # Assign the matrix, nest descriptions, and nest count\n",
    "                Psi_dict_t[g] = mat\n",
    "                nest_dict_t[g] = pd.DataFrame({'nests': ['outside_option', 'inside_option']}).reset_index().rename(columns={'index' :'nest_index'}).rename_axis('outside/inside option', axis='columns') # Enumerate the two nests 'outside' and 'inside' by 0 and 1, and save the description of the category.\n",
    "                nest_counts_t[g] = 2\n",
    "\n",
    "            else:\n",
    "                if outside_option == True:\n",
    "                    col = columns[g-1] # If outside option is included, then the second category is the first variable in the specfied columns\n",
    "                else:\n",
    "                    col = columns[g] # If outside option is excluded, then the first category is the first variable in the specfied columns\n",
    "                    \n",
    "                vals = pd.DataFrame({'nests' : data_t[col].sort_values().unique()}).reset_index().rename(columns={'index' :'nest_index'}) # Enumerate the unique values of the variable 'col' by the integers 0,1,...,C_g-1\n",
    "                descr = vals.rename_axis(col, axis='columns') # Create a description of category g\n",
    "                \n",
    "                # Assign the description and counts\n",
    "                nest_dict_t[g] = descr\n",
    "                nest_counts_t[g] = len(vals['nests'])\n",
    "\n",
    "                # Constuct the \\psi^g matrix\n",
    "                product_enumeration = pd.DataFrame({products_id : data_t[products_id].sort_values().unique(), 'product_enumeration' : np.arange(J[t])}) # Enumerates products by j=0,...,J[t]-1\n",
    "                C_g = len(vals['nest_index']) # Find the amount of nests in category g\n",
    "\n",
    "                frame = data_t[[products_id, col]].merge(vals, left_on = col, right_on = 'nests') # Merge nest indices and nest enumerations onto the subsetted data for market t \n",
    "                allocation = frame[[products_id, 'nest_index']].merge(product_enumeration, on=products_id, how='left') # Merge the product enumeration onto frame\n",
    "\n",
    "                mat = np.zeros((C_g, J[t])) # Initialize zero matrix\n",
    "\n",
    "                for c,j in zip(allocation['nest_index'], allocation['product_enumeration']): \n",
    "                    mat[c, j] = 1 # Assigns a 1 to each pair of a nest index and a product index as specified by the eariler merges\n",
    "\n",
    "                Psi_dict_t[g] = mat # Assign the matrix\n",
    "\n",
    "        # For each market t assign the relevant information\n",
    "        Psi_dict[t] = Psi_dict_t\n",
    "        nest_dict[t] = nest_dict_t\n",
    "        nest_counts[t] = nest_counts_t\n",
    "        Psi_stack[t] = np.concatenate([np.eye(J[t]) if g==0 else Psi_dict[t][g-1] for g in np.arange(G + 1)]) # The top most block matrix is the J[t] by J[t] identity, and the next G block matrices are the \\psi^g matrices\n",
    "        \n",
    "    return Psi_stack, nest_dict, nest_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_nests(data, markets_id, products_id, columns, cont_var = None, cont_var_bins = None, outside_option = True):\n",
    "    '''\n",
    "    This function creates the nest matrices \\Psi^g from any specified columns of the dataset\n",
    "\n",
    "    Args.\n",
    "        data: a pandas DataFrame\n",
    "        markets_id: a string denoting the column of 'data' containing an enumeration t=0,1,...,T-1 of markets\n",
    "        products_id: a string denoting the column of 'data' containing product codes which uniquely identifies products\n",
    "        columns: a list containing the column names of columns in 'data' from which nest groupings g=0,1,...,G-1 for each market t are to be generated\n",
    "        cont_var: a list of the continuous variables in 'columns'\n",
    "        cont_var_bins: a list containing the number of bins to make for each continuous variable in 'columns'\n",
    "        outside_option: a boolean indicating whether the model is estimated with or without an outside option. Default is set to 'True' i.e. with an outside option.\n",
    "\n",
    "    Returns\n",
    "        Psi_stack: a dictionary of length T of the J[t] by J[t] identity stacked on top of the Psi_g matrices for each market t and each gropuing g\n",
    "        nest_dict: a dictionary of length T of pandas series describing the structure of each nest for each market t and each grouping g\n",
    "        nest_count: a dictionary of length T of (G,) numpy arrays containing the amount of nests in each category g\n",
    "    '''\n",
    "\n",
    "    T = data[markets_id].nunique()\n",
    "    J = np.array([data[data[markets_id] == t][products_id].nunique() for t in np.arange(T)])\n",
    "    \n",
    "    # We include nest on outside vs. inside options. The amount of categories varies if the outside option is included in the analysis.\n",
    "    dat = data.sort_values(by = [markets_id, products_id]) # We sort the data in ascending, first according to market and then according to the product id\n",
    "    \n",
    "    Psi_stack = {}\n",
    "    nest_dict = {}\n",
    "    nest_counts = {}\n",
    "\n",
    "    ### Bin continuous variables according to quantiles of the variable\n",
    "\n",
    "    if cont_var == None:\n",
    "        None\n",
    "    else:\n",
    "        for var,n_bins in zip(cont_var,cont_var_bins):\n",
    "            if outside_option:\n",
    "                q_dat = np.quantile(dat[var].rank(method = 'first'), q = np.arange(1,n_bins + 1) / n_bins) # Get the 'n_bins' equally spaced quantiles of each continuous variable given in the cont_var list\n",
    "                dat[var] = pd.cut(dat[var].rank(method = 'first'), bins = [0.99, 1, *q_dat], labels=False) # Quantiles are equally spaced with 'n_bins' quantiles for the variable. The outside option gets its own bin (0.99,1].\n",
    "            else:\n",
    "                dat[var] = pd.qcut(dat[var].rank(method = 'first'), q = n_bins, labels=False) # Bin the variable according to 'n_bins' equally spaced quantiles.\n",
    "\n",
    "    # Assign nests for products in each market t\n",
    "    for t in np.arange(T):\n",
    "        data_t = dat[dat[markets_id] == t] # Subset data on market t\n",
    "        nest_dict[t] = data_t[columns].apply(lambda col: list(np.unique(col))) # Get the unique values of each 'col' in columns\n",
    "        nest_counts[t] = data_t[columns].nunique().values # Find the number of unique values in each column in columns and output as a numpy array\n",
    "\n",
    "        sum_Cg = data_t[columns].nunique().sum() # Find the sum of nest counts C_g\n",
    "        nests = pd.get_dummies(data_t[columns], columns = columns).values.reshape((J[t], sum_Cg)).transpose() # Finds dummies for each category in columns, and converts these to numpy arrays of the appropiate size. Note that the data has been sorted according to market and then product.\n",
    "        Psi_t = np.concatenate([np.eye(J[t]), nests], axis = 0) # Stack a J[t] by J[t] identity on top of the stacked \\Psi^g matrices for each market t\n",
    "\n",
    "        Psi_stack[t] = Psi_t\n",
    "\n",
    "    return Psi_stack, nest_dict, nest_counts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We bin all the continuous explanatory variables different from `pr` (i.e. the price) in 10 bins, and the grouping of `pr` includes 100 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi_stack, Nest_descr, Nest_count = Create_nests(dat, 'market', 'co', nest_vars, nest_cont_vars, [*[np.int64(10) for i in range(len(nest_cont_vars))]], outside_option=OO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Gamma(Lambda, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function \n",
    "    '''\n",
    "\n",
    "    T = len(psi_stack)\n",
    "    \n",
    "    Gamma = {}\n",
    "    lambda0 = np.array([1 - sum(Lambda)])\n",
    "    Lambda_full = np.concatenate((lambda0, Lambda)) # create vector (1- sum(lambda), lambda_1, ..., lambda_G)\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        C,J = psi_stack[t].shape # The amount of alternatives in market t\n",
    "        Lambda_long = np.empty((C,)) # Initialize a row vector with as many rows as psi_stack\n",
    "        indices = np.concatenate((np.array([J]) , nest_count[t])).cumsum().astype('int64') # Get the indices of where the identity and the nests in psi_stack are located along the rows of psi_stack.\n",
    "\n",
    "        for i in np.arange(len(indices)):\n",
    "            if i == 0:\n",
    "                Lambda_long[0:(indices[i])] = Lambda_full[i] # Assign 1-sum(lambda) to the first J coordinates of Lambda_long\n",
    "            else:\n",
    "                Lambda_long[indices[i-1]:indices[i]] = Lambda_full[i] # Assign lambda_g to the coordinates of Lambda_long corresponding to the rows of psi_stack equal to the block matrix \\psi^g \n",
    "    \n",
    "        Gamma[t] =  np.einsum('c,cj->cj', Lambda_long, psi_stack[t]) # Compute hadamard product of lambda parameters and psi_stack\n",
    "\n",
    "    return Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda0 = np.ones((G,))/(2*(G+1))\n",
    "Gamma0 = Create_Gamma(lambda0, Psi_stack, Nest_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model solution\n",
    "\n",
    "While it is possible to solve for the choice probabilities explicitly by maximizing utility, Fosgerau and Nielsen (2021) suggest a contraction mapping approach which is conceptually simpler. Suppose we are evaluating the likelihood at some guess of the parameters $\\theta=(\\beta',\\lambda')$. Let $u_i=\\mathbf{X}_i\\beta$, and let $q_i^0$ denote some initial vector of choice probabilities e.g. $q^0_i=\\frac{e^{u_i}}{\\sum_{j'=1}^Je^{u_{ij'}}}$, we update the choice probabilities according to the formula\n",
    "$$\n",
    "v_i^{k} =u_i+\\ln q_i^{k-1}-\\Gamma'\\ln (\\Gamma q_i^{k-1})\\\\\n",
    "q_i^{k} = \\frac{e^{v_i^{k}}}{\\sum_{j=1}^J e^{v_{ij}^{k}}},\n",
    "$$\n",
    "they show that $\\lim_{k\\rightarrow \\infty}q_i^k=p(\\mathbf{X}_i,\\theta)$ for any starting value $q^0_i$ in the interior of $\\Delta$. For numerical stability, it can be a good idea to also do max-rescaling of $v^k_i$ at every iteration.\n",
    "\n",
    "Let $p$ denote the solution to the utility maximization problem. Formally, the Kullback-Leibler divergence $D_{KL}(p||q)=p'\\ln \\frac{p}{q}$ decays linearly with each iteration,\n",
    "$$\n",
    "D_{KL}(p||q^{k+1})\\leq \\left(1- \\sum_g \\lambda_g \\right)D_{KL}(p||q^k),\n",
    "$$\n",
    "Noting that $(1-\\sum_g \\lambda_g)\\in [0,1)$ by assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_ccp(Theta, x, psi_stack, nest_count, tol = 1.0e-15, maximum_iterations = 1000, MAXRESCALE:bool = True):\n",
    "    '''\n",
    "    This function finds approximations to the true conditional choice probabilities given parameters.\n",
    "\n",
    "    Args.\n",
    "        Theta: a numpy array (K+G,) of parameters\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "        tol: tolerated approximation error\n",
    "        maximum_iterations: a no. of maximum iterations which if reached will stop the algorithm\n",
    "        MAXRESCALE: whether or not to max rescale the choice probabilities during iteration\n",
    "\n",
    "    Output\n",
    "        q_1: a dictionary of T numpy arrays (J[t],) of approximative IPDL choice probabilities for each market t\n",
    "    '''\n",
    "\n",
    "    T = len(x)\n",
    "    K = x[0].shape[1]\n",
    "\n",
    "    # Parameters\n",
    "    Beta = Theta[:K]\n",
    "    Lambda = Theta[K:]\n",
    "\n",
    "    # Amount of categories\n",
    "    G = len(Lambda)\n",
    "\n",
    "    # Calculate small beta\n",
    "    C_minus = np.array([g for g in np.arange(G) if Lambda[g] < 0]) # Find the categories g with negative a negative parameter lambda_g\n",
    "    b = {t: np.max(np.einsum('c,cj->j', Lambda[C_minus], psi_stack[t][C_minus,:])) if (len(C_minus) != 0) else 0 for t in np.arange(T)} # Set the sum equal to 0 if C_minus is empty\n",
    "\n",
    "    Gamma = Create_Gamma(Lambda, psi_stack, nest_count) # Find the Gamma matrix\n",
    "\n",
    "    u = {t: np.einsum('jk,k->j', x[t], Beta) for t in np.arange(T)} # Calculate linear utilities\n",
    "    q = {t: np.exp(u[t]) / np.exp(u[t]).sum() for t in np.arange(T)} # Find logit choice probabilities\n",
    "    q0 = q\n",
    "    \n",
    "    Epsilon = 1.0e-10\n",
    "\n",
    "    for k in range(maximum_iterations):\n",
    "        q1 = {}\n",
    "        for t in np.arange(T):\n",
    "            # Calculate v\n",
    "            gamma_q = np.einsum('cj,j->c', Gamma[t], q0[t]) # Compute matrix product\n",
    "            log_gammaq = np.log(np.abs(gamma_q) + Epsilon) # Add Epsilon to avoid zeros in log\n",
    "            gamma_log_prod = np.einsum('cj,c->j', Gamma[t], log_gammaq) # Compute matrix product\n",
    "            v = np.log(q0[t], out = -np.inf*np.ones_like(q0[t]), where = (q0[t] > 0)) + np.divide(u[t] - gamma_log_prod, 1 + b[t]) # Calculate v = log(q) + (u - Gamma^T %o% log(Gamma %o% q) %o% Gamma)/(1 + b)\n",
    "\n",
    "            if MAXRESCALE:\n",
    "                v -= v.max(keepdims = True) # Do max rescaling wrt. alternatives\n",
    "\n",
    "            # Calculate iterated ccp q^k\n",
    "            denom = np.exp(v).sum()\n",
    "            numerator = np.exp(v)\n",
    "            q1[t] = np.divide(numerator, denom)\n",
    "\n",
    "        # Check convergence in an appropriate distance function\n",
    "        dist = np.max(np.array([np.sum((q1[t]-q0[t])**2/q[t]) for t in np.arange(T)])) # Uses logit weights. This avoids precision issues when q1~q0~0.\n",
    "\n",
    "        if dist<tol:\n",
    "            break\n",
    "        elif k==maximum_iterations:\n",
    "            break\n",
    "        else:\n",
    "            None\n",
    "            \n",
    "        # Iteration step\n",
    "        q0 = q1\n",
    "\n",
    "    return q1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Products</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Markets</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99562</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Products       0         1         2         3         4         5         6   \\\n",
       "Markets                                                                         \n",
       "0         0.99562  0.000065  0.000141  0.000037  0.000029  0.000063  0.000036   \n",
       "\n",
       "Products        7         8         9   ...        35        36        37  \\\n",
       "Markets                                 ...                                 \n",
       "0         0.000012  0.000013  0.000053  ...  0.000029  0.000036  0.000182   \n",
       "\n",
       "Products        38        39        40        41        42       43        44  \n",
       "Markets                                                                        \n",
       "0         0.000137  0.000087  0.000024  0.000239  0.000072  0.00011  0.000013  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta0 = np.append(logit_beta, np.ones((G,))/(2*(G+1)))\n",
    "\n",
    "q0_hat = IPDL_ccp(theta0, x, Psi_stack, Nest_count)\n",
    "pd.DataFrame(q0_hat[0]).rename_axis(index='Products', columns='Markets').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.array([np.sum(q0_hat[t]) for t in np.arange(T)]).all() == 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demand derivatives and price Elasticity\n",
    "\n",
    "While the demand derivatives in the IPDL model are not quite as simple as in the logit model, they are still easy to compute. \n",
    "Let $q=P(u|\\lambda)$, then\n",
    "$$\n",
    "\\nabla_u P(u|\\lambda)=\\left(\\nabla^2_{qq}\\Omega(q|\\lambda)\\right)^{-1}-qq'\n",
    "$$\n",
    "where the $()^{-1}$ denotes the matrix inverse. The derivatives with respect to any $x_{ij\\ell}$ can now easily be computed by the chain rule,\n",
    "$$\n",
    "    \\frac{\\partial P_j(u_i|\\lambda)}{\\partial x_{ik\\ell}}=\\frac{\\partial P_j(u_i|\\lambda)}{\\partial u_{ik}}\\frac{\\partial u_{ik}}{\\partial x_{ik\\ell}}=\\frac{\\partial P_j(u_i|\\lambda)}{\\partial u_{ik}}\\beta_\\ell,\n",
    "$$\n",
    "\n",
    "Finally, moving to price elasticity is the same as in the logit model, if $x_{ik\\ell}$ is the log price of product $k$ for individual $i$, then\n",
    "$$\n",
    "    \\mathcal{E}_{jk}= \\frac{\\partial P_j(u_i|\\lambda)}{\\partial x_{ik\\ell}}\\frac{1}{P_j(u_i|\\lambda)}=\\frac{\\partial P_j(u_i|\\lambda)}{\\partial u_{ik}}\\frac{1}{P_j(u_i|\\lambda)}\\beta_\\ell=\\frac{\\partial \\ln P_j(u_i|\\lambda)}{\\partial u_{ik}}\\beta_\\ell$$\n",
    "we can also write this compactly as\n",
    "$$\n",
    "\\nabla_u \\ln P(u|\\lambda)=\\mathrm{diag}(P(u|\\lambda))^{-1}\\nabla_u P(u|\\lambda).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pertubation_hessian(q, x, Theta, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calucates the hessian of the pertubation function \\Omega\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        Theta: a numpy array (K+G,) of parameters\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "    \n",
    "    Returns\n",
    "        Hess: a dictionary of T numpy arrays (J[t],J[t]) of second partial derivatives of the pertubation function \\Omega for each market t\n",
    "    '''\n",
    "    \n",
    "    T = len(q.keys())\n",
    "    K = x[0].shape[1]\n",
    "\n",
    "    Gamma = Create_Gamma(Theta[K:], psi_stack, nest_count) # Find the \\Gamma matrices \n",
    "    Hess = {}\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        gamma_q = np.einsum('cj,j->c', Gamma[t], q[t]) # Compute a matrix product\n",
    "        inv_gamma_q = np.divide(1, gamma_q, out = np.inf*np.ones_like(gamma_q), where = (gamma_q!=0)) # Divide 1 with gamma_q by broadcasting and assign infinity to entries where gamma_q = 0 \n",
    "        Hess[t] = np.einsum('cj,ck->jk', Gamma[t], np.einsum('c,cj->cj', inv_gamma_q, Gamma[t])) # Compute Gamma^T %o% diag(gamma_q)^-1 %o% Gamma\n",
    "\n",
    "    return Hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccp_gradient(q, x, Theta, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calucates the gradient of the choice proabilities wrt. characteristics\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        Theta: a numpy array (K+G,) of parameters\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "    \n",
    "    Returns\n",
    "        Grad: a dictionary of T numpy arrays (J[t],K) of partial derivatives of the choice proabilities wrt. utilities for each market t\n",
    "    '''\n",
    "\n",
    "    T = len(q.keys())\n",
    "    Grad = {}\n",
    "    Hess = compute_pertubation_hessian(q, x, Theta, psi_stack, nest_count) # Compute the hessian of the pertubation function\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        inv_omega_hess = la.inv(Hess[t]) # (J,J) for each t=1,...,T , computes the inverse of the Hessian\n",
    "        qqT = np.einsum('j,k->jk', q[t], q[t]) # (J,J) outerproduct of ccp's for each market t\n",
    "        Grad[t] = inv_omega_hess - qqT  # Compute IPDL gradient of ccp's wrt. utilities\n",
    "\n",
    "    return Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_u_grad_Log_ccp(q, x, Theta, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calucates the gradient of the log choice proabilities wrt. characteristics\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        Theta: a numpy array (K+G,) of parameters\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "    \n",
    "    Returns\n",
    "        Epsilon: a dictionary of T numpy arrays (J[t],J[t]) of partial derivatives of the log choice proabilities of products j wrt. utilites of products k for each market t\n",
    "    '''\n",
    "\n",
    "    T = len(q.keys())\n",
    "    Epsilon = {}\n",
    "    Grad = ccp_gradient(q, x, Theta, psi_stack, nest_count) # Find the gradient of ccp's wrt. utilities\n",
    "    \n",
    "    for t in np.arange(T):\n",
    "        ccp_grad = Grad[t]\n",
    "        inv_diagq = np.divide(1, q[t], out = np.inf*np.ones_like(q[t]), where = (q[t] > 0)) # Find the inverse of the ccp's and assign infinity to any entry if that entry has q = 0\n",
    "        Epsilon[t] = np.einsum('j,jk->jk', inv_diagq, ccp_grad) # Computes a Hadamard product. Is equivalent to:   diag(q)^-1 %o% ccp_grad\n",
    "\n",
    "    return Epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_elasticity(q, x, Theta, psi_stack, nest_count, char_number = K-1):\n",
    "    ''' \n",
    "    This function calculates the elasticity of choice probabilities wrt. any characteristic or nest grouping of products\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        Theta: a numpy array (K+G,) of parameters\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "        char_number: an integer which is an index of the parameter in theta wrt. which we wish calculate the elasticity. Default is the index for the parameter of 'pr'.\n",
    "\n",
    "    Returns\n",
    "        a dictionary of T numpy arrays (J[t],J[t]) of choice probability semi-elasticities for each market t\n",
    "    '''\n",
    "    T = len(q.keys())\n",
    "    Epsilon = {}\n",
    "    Grad = IPDL_u_grad_Log_ccp(q, x, Theta, psi_stack, nest_count) # Find the gradient of log ccp's wrt. utilities\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        Epsilon[t] = np.multiply(Grad[t], Theta[char_number]) # Calculate semi-elasticities\n",
    "\n",
    "    return Epsilon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using guess parameters $\\hat \\theta^0$ we calculate price-to-log-income elasticities for individual $i=0$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003490</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000023</td>\n",
       "      <td>-0.000029</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000191</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>1.221517</td>\n",
       "      <td>-0.023503</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>-0.003267</td>\n",
       "      <td>-0.004531</td>\n",
       "      <td>-0.002991</td>\n",
       "      <td>-0.002209</td>\n",
       "      <td>-0.055487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>-0.009918</td>\n",
       "      <td>-0.008838</td>\n",
       "      <td>-0.001616</td>\n",
       "      <td>-0.036981</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>-0.003089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.010772</td>\n",
       "      <td>1.258537</td>\n",
       "      <td>-0.020705</td>\n",
       "      <td>-0.004756</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.019957</td>\n",
       "      <td>-0.010863</td>\n",
       "      <td>-0.051859</td>\n",
       "      <td>-0.022845</td>\n",
       "      <td>-0.004255</td>\n",
       "      <td>-0.020093</td>\n",
       "      <td>0.001303</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>-0.002594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>-0.080184</td>\n",
       "      <td>1.406145</td>\n",
       "      <td>-0.021992</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.005438</td>\n",
       "      <td>-0.000920</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>-0.000413</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004271</td>\n",
       "      <td>-0.011639</td>\n",
       "      <td>-0.051604</td>\n",
       "      <td>-0.064372</td>\n",
       "      <td>-0.003330</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-0.005093</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>-0.004452</td>\n",
       "      <td>-0.009906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>-0.023160</td>\n",
       "      <td>-0.027654</td>\n",
       "      <td>1.388426</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.003043</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.019128</td>\n",
       "      <td>-0.000180</td>\n",
       "      <td>-0.002169</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>-0.021596</td>\n",
       "      <td>-0.012724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.003347</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>1.075185</td>\n",
       "      <td>-0.000234</td>\n",
       "      <td>-0.002168</td>\n",
       "      <td>-0.001292</td>\n",
       "      <td>-0.020210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.000409</td>\n",
       "      <td>-0.002140</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>-0.020311</td>\n",
       "      <td>-0.004115</td>\n",
       "      <td>-0.028922</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>-0.009401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.008258</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>-0.005584</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>-0.000416</td>\n",
       "      <td>1.406600</td>\n",
       "      <td>-0.009168</td>\n",
       "      <td>-0.008288</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036781</td>\n",
       "      <td>-0.030729</td>\n",
       "      <td>-0.025321</td>\n",
       "      <td>-0.037989</td>\n",
       "      <td>-0.017455</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>-0.114979</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>-0.022716</td>\n",
       "      <td>0.001125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.015802</td>\n",
       "      <td>0.004515</td>\n",
       "      <td>-0.002738</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>-0.011179</td>\n",
       "      <td>-0.026574</td>\n",
       "      <td>1.440181</td>\n",
       "      <td>-0.026414</td>\n",
       "      <td>-0.031524</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020292</td>\n",
       "      <td>-0.025379</td>\n",
       "      <td>-0.011257</td>\n",
       "      <td>-0.003276</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>-0.006036</td>\n",
       "      <td>-0.060427</td>\n",
       "      <td>-0.049456</td>\n",
       "      <td>-0.014264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.010790</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>-0.006160</td>\n",
       "      <td>-0.022210</td>\n",
       "      <td>-0.024420</td>\n",
       "      <td>1.288751</td>\n",
       "      <td>-0.091129</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019300</td>\n",
       "      <td>-0.024180</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>-0.036913</td>\n",
       "      <td>-0.001310</td>\n",
       "      <td>-0.038378</td>\n",
       "      <td>-0.008316</td>\n",
       "      <td>-0.009620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.067568</td>\n",
       "      <td>-0.000525</td>\n",
       "      <td>-0.000284</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>-0.024019</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>-0.007266</td>\n",
       "      <td>-0.022719</td>\n",
       "      <td>1.261013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000952</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>-0.000132</td>\n",
       "      <td>-0.001052</td>\n",
       "      <td>0.002134</td>\n",
       "      <td>-0.020568</td>\n",
       "      <td>-0.003823</td>\n",
       "      <td>-0.073362</td>\n",
       "      <td>-0.005301</td>\n",
       "      <td>-0.000168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.007498</td>\n",
       "      <td>-0.002695</td>\n",
       "      <td>-0.007349</td>\n",
       "      <td>0.001063</td>\n",
       "      <td>-0.005902</td>\n",
       "      <td>0.000493</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>-0.023089</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015153</td>\n",
       "      <td>-0.010378</td>\n",
       "      <td>-0.032927</td>\n",
       "      <td>-0.010311</td>\n",
       "      <td>-0.047447</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>-0.004126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>-0.025050</td>\n",
       "      <td>0.001801</td>\n",
       "      <td>-0.028400</td>\n",
       "      <td>0.001691</td>\n",
       "      <td>-0.003434</td>\n",
       "      <td>-0.008892</td>\n",
       "      <td>-0.001079</td>\n",
       "      <td>-0.003347</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006745</td>\n",
       "      <td>-0.006808</td>\n",
       "      <td>-0.031128</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>-0.005183</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>-0.015333</td>\n",
       "      <td>-0.041152</td>\n",
       "      <td>-0.006309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>-0.063158</td>\n",
       "      <td>-0.008030</td>\n",
       "      <td>-0.012597</td>\n",
       "      <td>-0.016194</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>0.001416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005638</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>-0.032243</td>\n",
       "      <td>0.003755</td>\n",
       "      <td>-0.033517</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.001990</td>\n",
       "      <td>-0.007891</td>\n",
       "      <td>-0.036346</td>\n",
       "      <td>-0.000598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>-0.002757</td>\n",
       "      <td>-0.000536</td>\n",
       "      <td>-0.000797</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>-0.000109</td>\n",
       "      <td>-0.000598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000823</td>\n",
       "      <td>-0.009063</td>\n",
       "      <td>-0.021631</td>\n",
       "      <td>-0.045253</td>\n",
       "      <td>-0.025626</td>\n",
       "      <td>-0.003980</td>\n",
       "      <td>-0.028221</td>\n",
       "      <td>-0.000352</td>\n",
       "      <td>-0.006336</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.037747</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>-0.005028</td>\n",
       "      <td>-0.010420</td>\n",
       "      <td>-0.004512</td>\n",
       "      <td>-0.000018</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>-0.048743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>-0.010938</td>\n",
       "      <td>-0.008962</td>\n",
       "      <td>-0.000842</td>\n",
       "      <td>-0.059470</td>\n",
       "      <td>-0.028015</td>\n",
       "      <td>-0.004569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>-0.008666</td>\n",
       "      <td>-0.014718</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.008740</td>\n",
       "      <td>-0.001884</td>\n",
       "      <td>-0.001219</td>\n",
       "      <td>-0.004406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008134</td>\n",
       "      <td>-0.006775</td>\n",
       "      <td>-0.070048</td>\n",
       "      <td>-0.030284</td>\n",
       "      <td>-0.006341</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>-0.030495</td>\n",
       "      <td>-0.023601</td>\n",
       "      <td>-0.044078</td>\n",
       "      <td>-0.001176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.016749</td>\n",
       "      <td>0.003337</td>\n",
       "      <td>-0.003228</td>\n",
       "      <td>-0.002823</td>\n",
       "      <td>-0.004340</td>\n",
       "      <td>-0.006859</td>\n",
       "      <td>-0.001415</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>-0.012464</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.012749</td>\n",
       "      <td>-0.002985</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>-0.012149</td>\n",
       "      <td>-0.017238</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>-0.030328</td>\n",
       "      <td>-0.013722</td>\n",
       "      <td>-0.001275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.004881</td>\n",
       "      <td>-0.024624</td>\n",
       "      <td>-0.005413</td>\n",
       "      <td>-0.008048</td>\n",
       "      <td>-0.008629</td>\n",
       "      <td>-0.002210</td>\n",
       "      <td>-0.003332</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.007430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004982</td>\n",
       "      <td>-0.005681</td>\n",
       "      <td>-0.052442</td>\n",
       "      <td>-0.007820</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>-0.025381</td>\n",
       "      <td>-0.009244</td>\n",
       "      <td>0.005860</td>\n",
       "      <td>0.000658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.003325</td>\n",
       "      <td>-0.041764</td>\n",
       "      <td>0.001372</td>\n",
       "      <td>-0.004734</td>\n",
       "      <td>0.000999</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>-0.002437</td>\n",
       "      <td>-0.001098</td>\n",
       "      <td>-0.004458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003442</td>\n",
       "      <td>-0.001933</td>\n",
       "      <td>0.004436</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>-0.017091</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>-0.015420</td>\n",
       "      <td>-0.067927</td>\n",
       "      <td>-0.006124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.005586</td>\n",
       "      <td>-0.025661</td>\n",
       "      <td>-0.001138</td>\n",
       "      <td>-0.003475</td>\n",
       "      <td>-0.000823</td>\n",
       "      <td>-0.011159</td>\n",
       "      <td>-0.000098</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>-0.000367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>-0.007628</td>\n",
       "      <td>-0.013334</td>\n",
       "      <td>-0.012184</td>\n",
       "      <td>-0.016286</td>\n",
       "      <td>-0.000087</td>\n",
       "      <td>-0.030435</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>-0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.006000</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>-0.003528</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>-0.000962</td>\n",
       "      <td>-0.001689</td>\n",
       "      <td>-0.000999</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.000489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-0.000330</td>\n",
       "      <td>-0.021958</td>\n",
       "      <td>-0.005651</td>\n",
       "      <td>0.001487</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.029078</td>\n",
       "      <td>-0.000423</td>\n",
       "      <td>-0.007251</td>\n",
       "      <td>-0.000054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.002617</td>\n",
       "      <td>-0.000353</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.009847</td>\n",
       "      <td>-0.008692</td>\n",
       "      <td>-0.010465</td>\n",
       "      <td>-0.040874</td>\n",
       "      <td>-0.006879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000870</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>-0.032312</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.013895</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>-0.008285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.063356</td>\n",
       "      <td>-0.016606</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>-0.003124</td>\n",
       "      <td>-0.001115</td>\n",
       "      <td>-0.003144</td>\n",
       "      <td>-0.000903</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>-0.000553</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007250</td>\n",
       "      <td>-0.009266</td>\n",
       "      <td>-0.037338</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>-0.000325</td>\n",
       "      <td>-0.002026</td>\n",
       "      <td>-0.011905</td>\n",
       "      <td>-0.003062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.145345</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>-0.014314</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>-0.007910</td>\n",
       "      <td>-0.005926</td>\n",
       "      <td>-0.066477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>-0.001095</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>-0.008364</td>\n",
       "      <td>-0.002475</td>\n",
       "      <td>-0.049191</td>\n",
       "      <td>-0.006695</td>\n",
       "      <td>-0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.003516</td>\n",
       "      <td>-0.017886</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>-0.003704</td>\n",
       "      <td>-0.083159</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000431</td>\n",
       "      <td>0.002780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006944</td>\n",
       "      <td>-0.008685</td>\n",
       "      <td>-0.033164</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>-0.001700</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>-0.000614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.009555</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.000457</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>-0.043999</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>-0.012157</td>\n",
       "      <td>-0.024817</td>\n",
       "      <td>-0.006064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000554</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.001564</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>-0.194929</td>\n",
       "      <td>-0.004180</td>\n",
       "      <td>-0.016036</td>\n",
       "      <td>-0.010715</td>\n",
       "      <td>-0.022650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.000617</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>-0.008239</td>\n",
       "      <td>-0.000636</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>-0.000223</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>-0.000816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002804</td>\n",
       "      <td>-0.000912</td>\n",
       "      <td>-0.030267</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>-0.000286</td>\n",
       "      <td>-0.039996</td>\n",
       "      <td>-0.000818</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>-0.000116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.019369</td>\n",
       "      <td>-0.068636</td>\n",
       "      <td>-0.001554</td>\n",
       "      <td>-0.005938</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>-0.004105</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008748</td>\n",
       "      <td>-0.009662</td>\n",
       "      <td>-0.014762</td>\n",
       "      <td>0.006854</td>\n",
       "      <td>-0.077514</td>\n",
       "      <td>-0.004141</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>-0.010243</td>\n",
       "      <td>-0.014152</td>\n",
       "      <td>-0.005518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.018650</td>\n",
       "      <td>-0.058803</td>\n",
       "      <td>-0.002118</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>-0.004906</td>\n",
       "      <td>-0.001657</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001524</td>\n",
       "      <td>-0.003137</td>\n",
       "      <td>-0.013525</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>-0.006456</td>\n",
       "      <td>-0.004341</td>\n",
       "      <td>0.000840</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>-0.010786</td>\n",
       "      <td>-0.001163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.000511</td>\n",
       "      <td>-0.036307</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>-0.002263</td>\n",
       "      <td>-0.029767</td>\n",
       "      <td>-0.003467</td>\n",
       "      <td>-0.001216</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>-0.009001</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007369</td>\n",
       "      <td>-0.009748</td>\n",
       "      <td>0.002712</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.004710</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.057203</td>\n",
       "      <td>-0.012986</td>\n",
       "      <td>-0.000927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.000241</td>\n",
       "      <td>-0.015623</td>\n",
       "      <td>-0.002888</td>\n",
       "      <td>-0.006273</td>\n",
       "      <td>-0.000794</td>\n",
       "      <td>-0.002095</td>\n",
       "      <td>-0.001042</td>\n",
       "      <td>-0.000222</td>\n",
       "      <td>-0.000700</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>-0.000301</td>\n",
       "      <td>-0.021288</td>\n",
       "      <td>-0.006596</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>-0.000155</td>\n",
       "      <td>-0.029266</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>-0.007611</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>-0.014617</td>\n",
       "      <td>-0.029412</td>\n",
       "      <td>-0.051849</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>-0.013680</td>\n",
       "      <td>-0.000207</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>-0.009751</td>\n",
       "      <td>-0.006411</td>\n",
       "      <td>-0.023608</td>\n",
       "      <td>-0.008930</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.092523</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>-0.047119</td>\n",
       "      <td>-0.009326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.028435</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>-0.028106</td>\n",
       "      <td>-0.019946</td>\n",
       "      <td>-0.057433</td>\n",
       "      <td>-0.003547</td>\n",
       "      <td>-0.010234</td>\n",
       "      <td>-0.028532</td>\n",
       "      <td>-0.011359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>-0.011334</td>\n",
       "      <td>-0.025334</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.018879</td>\n",
       "      <td>-0.007286</td>\n",
       "      <td>-0.039112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.003455</td>\n",
       "      <td>-0.013587</td>\n",
       "      <td>-0.002953</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>-0.005589</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>-0.001092</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>-0.004997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>-0.009349</td>\n",
       "      <td>-0.015390</td>\n",
       "      <td>-0.014671</td>\n",
       "      <td>-0.009100</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>-0.004900</td>\n",
       "      <td>-0.038395</td>\n",
       "      <td>-0.001122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.021350</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>-0.002589</td>\n",
       "      <td>-0.013069</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>-0.017640</td>\n",
       "      <td>0.000350</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.003305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009900</td>\n",
       "      <td>-0.002503</td>\n",
       "      <td>0.002325</td>\n",
       "      <td>-0.009950</td>\n",
       "      <td>-0.015643</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>-0.037595</td>\n",
       "      <td>0.003118</td>\n",
       "      <td>0.003105</td>\n",
       "      <td>-0.002685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>-0.025614</td>\n",
       "      <td>-0.005329</td>\n",
       "      <td>-0.002665</td>\n",
       "      <td>0.000570</td>\n",
       "      <td>-0.044685</td>\n",
       "      <td>-0.008505</td>\n",
       "      <td>-0.008749</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>...</td>\n",
       "      <td>1.418279</td>\n",
       "      <td>-0.041869</td>\n",
       "      <td>-0.028360</td>\n",
       "      <td>-0.018868</td>\n",
       "      <td>-0.035381</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.062973</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>-0.006924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.001457</td>\n",
       "      <td>-0.077887</td>\n",
       "      <td>-0.011730</td>\n",
       "      <td>-0.002439</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>-0.030155</td>\n",
       "      <td>-0.008592</td>\n",
       "      <td>-0.008855</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033820</td>\n",
       "      <td>1.404943</td>\n",
       "      <td>-0.016490</td>\n",
       "      <td>-0.059857</td>\n",
       "      <td>-0.034290</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>-0.003793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.000445</td>\n",
       "      <td>-0.008425</td>\n",
       "      <td>-0.010334</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.004938</td>\n",
       "      <td>-0.000757</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004552</td>\n",
       "      <td>-0.003277</td>\n",
       "      <td>1.297343</td>\n",
       "      <td>-0.017678</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.064058</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>-0.004619</td>\n",
       "      <td>0.000266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.000113</td>\n",
       "      <td>-0.053444</td>\n",
       "      <td>-0.017130</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-0.000987</td>\n",
       "      <td>-0.009844</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004025</td>\n",
       "      <td>-0.015806</td>\n",
       "      <td>-0.023491</td>\n",
       "      <td>1.246246</td>\n",
       "      <td>-0.040095</td>\n",
       "      <td>-0.003589</td>\n",
       "      <td>-0.063851</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>-0.022295</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.007395</td>\n",
       "      <td>-0.037165</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>-0.006390</td>\n",
       "      <td>-0.000097</td>\n",
       "      <td>-0.007140</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>0.001306</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011913</td>\n",
       "      <td>-0.014294</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>-0.063295</td>\n",
       "      <td>1.350742</td>\n",
       "      <td>-0.003461</td>\n",
       "      <td>-0.019649</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.005320</td>\n",
       "      <td>-0.005730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.023804</td>\n",
       "      <td>-0.025005</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>-0.000217</td>\n",
       "      <td>-0.053394</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>-0.005255</td>\n",
       "      <td>-0.020355</td>\n",
       "      <td>-0.045494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>-0.002341</td>\n",
       "      <td>-0.020466</td>\n",
       "      <td>-0.012502</td>\n",
       "      <td>1.223537</td>\n",
       "      <td>-0.002108</td>\n",
       "      <td>-0.031044</td>\n",
       "      <td>0.002447</td>\n",
       "      <td>0.002937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.000438</td>\n",
       "      <td>-0.011870</td>\n",
       "      <td>-0.000777</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>-0.001087</td>\n",
       "      <td>-0.017079</td>\n",
       "      <td>-0.000309</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000850</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007700</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>-0.048796</td>\n",
       "      <td>-0.036602</td>\n",
       "      <td>-0.007135</td>\n",
       "      <td>-0.000212</td>\n",
       "      <td>1.202567</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.022181</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.033303</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>-0.025420</td>\n",
       "      <td>0.001338</td>\n",
       "      <td>-0.010300</td>\n",
       "      <td>-0.007075</td>\n",
       "      <td>-0.054253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>-0.010379</td>\n",
       "      <td>-0.000692</td>\n",
       "      <td>1.320040</td>\n",
       "      <td>-0.069855</td>\n",
       "      <td>-0.000137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>-0.001480</td>\n",
       "      <td>-0.005711</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>-0.007355</td>\n",
       "      <td>-0.005525</td>\n",
       "      <td>-0.001005</td>\n",
       "      <td>-0.002569</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>-0.007670</td>\n",
       "      <td>-0.027860</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>-0.048353</td>\n",
       "      <td>-0.045783</td>\n",
       "      <td>1.302184</td>\n",
       "      <td>-0.002873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.793301</td>\n",
       "      <td>-0.015163</td>\n",
       "      <td>-0.027781</td>\n",
       "      <td>-0.027401</td>\n",
       "      <td>-0.027989</td>\n",
       "      <td>-0.045044</td>\n",
       "      <td>0.003030</td>\n",
       "      <td>-0.013254</td>\n",
       "      <td>-0.009668</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015351</td>\n",
       "      <td>-0.010410</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.004457</td>\n",
       "      <td>-0.037730</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>-0.000745</td>\n",
       "      <td>-0.023898</td>\n",
       "      <td>1.427562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.003490 -0.000052 -0.000113 -0.000029 -0.000023 -0.000050 -0.000028   \n",
       "1  -0.793301  1.221517 -0.023503  0.000210  0.000587 -0.003267 -0.004531   \n",
       "2  -0.793301 -0.010772  1.258537 -0.020705 -0.004756  0.000654  0.001892   \n",
       "3  -0.793301  0.000373 -0.080184  1.406145 -0.021992 -0.000020 -0.005438   \n",
       "4  -0.793301  0.001311 -0.023160 -0.027654  1.388426  0.001002  0.001020   \n",
       "5  -0.793301 -0.003347  0.001462 -0.000012  0.000460  1.075185 -0.000234   \n",
       "6  -0.793301 -0.008258  0.007523 -0.005584  0.000833 -0.000416  1.406600   \n",
       "7  -0.793301 -0.015802  0.004515 -0.002738  0.002553 -0.011179 -0.026574   \n",
       "8  -0.793301 -0.010790  0.000050  0.000485  0.000192 -0.006160 -0.022210   \n",
       "9  -0.793301 -0.067568 -0.000525 -0.000284  0.000478 -0.024019  0.001022   \n",
       "10 -0.793301  0.003206  0.007498 -0.002695 -0.007349  0.001063 -0.005902   \n",
       "11 -0.793301  0.002057 -0.025050  0.001801 -0.028400  0.001691 -0.003434   \n",
       "12 -0.793301  0.001382 -0.063158 -0.008030 -0.012597 -0.016194  0.000705   \n",
       "13 -0.793301 -0.000288  0.003454 -0.002757 -0.000536 -0.000797 -0.001277   \n",
       "14 -0.793301 -0.037747  0.002759  0.000401 -0.005028 -0.010420 -0.004512   \n",
       "15 -0.793301  0.001227 -0.008666 -0.014718  0.000275 -0.000077 -0.008740   \n",
       "16 -0.793301 -0.016749  0.003337 -0.003228 -0.002823 -0.004340 -0.006859   \n",
       "17 -0.793301 -0.004881 -0.024624 -0.005413 -0.008048 -0.008629 -0.002210   \n",
       "18 -0.793301 -0.003325 -0.041764  0.001372 -0.004734  0.000999  0.000815   \n",
       "19 -0.793301 -0.005586 -0.025661 -0.001138 -0.003475 -0.000823 -0.011159   \n",
       "20 -0.793301 -0.006000  0.000896 -0.003528 -0.000658 -0.000962 -0.001689   \n",
       "21 -0.793301 -0.002617 -0.000353  0.000183  0.000008 -0.009847 -0.008692   \n",
       "22 -0.793301 -0.063356 -0.016606  0.000784 -0.003124 -0.001115 -0.003144   \n",
       "23 -0.793301 -0.145345  0.002530 -0.000144  0.000810 -0.014314  0.001770   \n",
       "24 -0.793301  0.003516 -0.017886  0.000384 -0.003704 -0.083159 -0.003775   \n",
       "25 -0.793301  0.009555  0.002083  0.000457  0.000761 -0.043999  0.001097   \n",
       "26 -0.793301 -0.000617  0.000927 -0.008239 -0.000636 -0.000896 -0.000223   \n",
       "27 -0.793301 -0.019369 -0.068636 -0.001554 -0.005938  0.000584 -0.004105   \n",
       "28 -0.793301 -0.018650 -0.058803 -0.002118  0.001538  0.000828 -0.004906   \n",
       "29 -0.793301 -0.000511 -0.036307  0.001147 -0.002263 -0.029767 -0.003467   \n",
       "30 -0.793301 -0.000241 -0.015623 -0.002888 -0.006273 -0.000794 -0.002095   \n",
       "31 -0.793301  0.001557 -0.014617 -0.029412 -0.051849  0.000698 -0.013680   \n",
       "32 -0.793301 -0.028435  0.004762 -0.028106 -0.019946 -0.057433 -0.003547   \n",
       "33 -0.793301 -0.003455 -0.013587 -0.002953  0.000977 -0.005589  0.001325   \n",
       "34 -0.793301 -0.021350  0.002257 -0.002589 -0.013069  0.000590 -0.017640   \n",
       "35 -0.793301  0.001693 -0.025614 -0.005329 -0.002665  0.000570 -0.044685   \n",
       "36 -0.793301  0.001457 -0.077887 -0.011730 -0.002439  0.000074 -0.030155   \n",
       "37 -0.793301 -0.000445 -0.008425 -0.010334  0.000201 -0.000142 -0.004938   \n",
       "38 -0.793301 -0.000113 -0.053444 -0.017130 -0.000081 -0.000987 -0.009844   \n",
       "39 -0.793301 -0.007395 -0.037165 -0.001399 -0.006390 -0.000097 -0.007140   \n",
       "40 -0.793301 -0.023804 -0.025005  0.000282 -0.000217 -0.053394  0.000308   \n",
       "41 -0.793301 -0.000438 -0.011870 -0.000777 -0.000263 -0.001087 -0.017079   \n",
       "42 -0.793301 -0.033303  0.002559  0.000278  0.001333 -0.025420  0.001338   \n",
       "43 -0.793301  0.002215  0.006982 -0.001480 -0.005711  0.001176 -0.007355   \n",
       "44 -0.793301 -0.015163 -0.027781 -0.027401 -0.027989 -0.045044  0.003030   \n",
       "\n",
       "          7         8         9   ...        35        36        37        38  \\\n",
       "0  -0.000010 -0.000011 -0.000042  ... -0.000023 -0.000029 -0.000145 -0.000109   \n",
       "1  -0.002991 -0.002209 -0.055487  ...  0.000765  0.000815 -0.001252 -0.000240   \n",
       "2   0.000392  0.000005 -0.000198  ... -0.005301 -0.019957 -0.010863 -0.051859   \n",
       "3  -0.000920  0.000176 -0.000413  ... -0.004271 -0.011639 -0.051604 -0.064372   \n",
       "4   0.001079  0.000088  0.000877  ... -0.002686 -0.003043  0.001261 -0.000381   \n",
       "5  -0.002168 -0.001292 -0.020210  ...  0.000264  0.000042 -0.000409 -0.002140   \n",
       "6  -0.009168 -0.008288  0.001530  ... -0.036781 -0.030729 -0.025321 -0.037989   \n",
       "7   1.440181 -0.026414 -0.031524  ... -0.020292 -0.025379 -0.011257 -0.003276   \n",
       "8  -0.024420  1.288751 -0.091129  ... -0.019300 -0.024180  0.002549  0.000260   \n",
       "9  -0.007266 -0.022719  1.261013  ...  0.000952  0.000634 -0.000132 -0.001052   \n",
       "10  0.000493  0.000634 -0.023089  ... -0.015153 -0.010378 -0.032927 -0.010311   \n",
       "11 -0.008892 -0.001079 -0.003347  ... -0.006745 -0.006808 -0.031128  0.002146   \n",
       "12  0.000422 -0.000131  0.001416  ... -0.005638  0.002388 -0.032243  0.003755   \n",
       "13 -0.001002 -0.000109 -0.000598  ...  0.000823 -0.009063 -0.021631 -0.045253   \n",
       "14 -0.000018  0.000324 -0.048743  ...  0.000852  0.000334 -0.000847 -0.000299   \n",
       "15 -0.001884 -0.001219 -0.004406  ... -0.008134 -0.006775 -0.070048 -0.030284   \n",
       "16 -0.001415  0.000482 -0.012464  ... -0.012749 -0.002985  0.002659 -0.012149   \n",
       "17 -0.003332  0.000360 -0.007430  ... -0.004982 -0.005681 -0.052442 -0.007820   \n",
       "18 -0.002437 -0.001098 -0.004458  ... -0.003442 -0.001933  0.004436  0.002914   \n",
       "19 -0.000098  0.000475 -0.000367  ...  0.001087 -0.007628 -0.013334 -0.012184   \n",
       "20 -0.000999 -0.000083 -0.000489  ...  0.000086 -0.000330 -0.021958 -0.005651   \n",
       "21 -0.010465 -0.040874 -0.006879  ...  0.000870  0.001566 -0.032312 -0.000601   \n",
       "22 -0.000903  0.000918 -0.000553  ... -0.007250 -0.009266 -0.037338  0.001070   \n",
       "23 -0.007910 -0.005926 -0.066477  ...  0.000709  0.000812  0.000319 -0.001095   \n",
       "24  0.000677  0.000431  0.002780  ... -0.006944 -0.008685 -0.033164  0.000136   \n",
       "25 -0.012157 -0.024817 -0.006064  ...  0.000554  0.000379  0.001564  0.000691   \n",
       "26 -0.000491 -0.000214 -0.000816  ... -0.002804 -0.000912 -0.030267 -0.001316   \n",
       "27  0.000447  0.000132  0.002217  ... -0.008748 -0.009662 -0.014762  0.006854   \n",
       "28 -0.001657 -0.000081  0.001952  ... -0.001524 -0.003137 -0.013525  0.003403   \n",
       "29 -0.001216  0.000729 -0.009001  ... -0.007369 -0.009748  0.002712  0.001149   \n",
       "30 -0.001042 -0.000222 -0.000700  ...  0.000513 -0.000301 -0.021288 -0.006596   \n",
       "31 -0.000207  0.000163 -0.000004  ... -0.003746 -0.009751 -0.006411 -0.023608   \n",
       "32 -0.010234 -0.028532 -0.011359  ...  0.002183  0.001942  0.000512  0.001267   \n",
       "33 -0.001092  0.000772 -0.004997  ...  0.000981 -0.009349 -0.015390 -0.014671   \n",
       "34  0.000350  0.000146  0.003305  ... -0.009900 -0.002503  0.002325 -0.009950   \n",
       "35 -0.008505 -0.008749  0.001732  ...  1.418279 -0.041869 -0.028360 -0.018868   \n",
       "36 -0.008592 -0.008855  0.000931  ... -0.033820  1.404943 -0.016490 -0.059857   \n",
       "37 -0.000757  0.000186 -0.000039  ... -0.004552 -0.003277  1.297343 -0.017678   \n",
       "38 -0.000293  0.000025 -0.000408  ... -0.004025 -0.015806 -0.023491  1.246246   \n",
       "39  0.000253  0.000068  0.001306  ... -0.011913 -0.014294  0.006518 -0.063295   \n",
       "40 -0.005255 -0.020355 -0.045494  ...  0.000011  0.000852 -0.002341 -0.020466   \n",
       "41 -0.000309 -0.000073 -0.000850  ... -0.007700  0.000498 -0.048796 -0.036602   \n",
       "42 -0.010300 -0.007075 -0.054253  ...  0.001054  0.000692  0.002012  0.000527   \n",
       "43 -0.005525 -0.001005 -0.002569  ...  0.001554  0.000081 -0.007670 -0.027860   \n",
       "44 -0.013254 -0.009668 -0.000678  ... -0.015351 -0.010410  0.003672  0.004457   \n",
       "\n",
       "          39        40        41        42        43        44  \n",
       "0  -0.000069 -0.000019 -0.000191 -0.000057 -0.000087 -0.000011  \n",
       "1  -0.009918 -0.008838 -0.001616 -0.036981  0.003753 -0.003089  \n",
       "2  -0.022845 -0.004255 -0.020093  0.001303  0.005422 -0.002594  \n",
       "3  -0.003330  0.000186 -0.005093  0.000547 -0.004452 -0.009906  \n",
       "4  -0.019128 -0.000180 -0.002169  0.003304 -0.021596 -0.012724  \n",
       "5  -0.000133 -0.020311 -0.004115 -0.028922  0.002041 -0.009401  \n",
       "6  -0.017455  0.000209 -0.114979  0.002708 -0.022716  0.001125  \n",
       "7   0.001792 -0.010309 -0.006036 -0.060427 -0.049456 -0.014264  \n",
       "8   0.000443 -0.036913 -0.001310 -0.038378 -0.008316 -0.009620  \n",
       "9   0.002134 -0.020568 -0.003823 -0.073362 -0.005301 -0.000168  \n",
       "10 -0.047447  0.000132  0.001371  0.002488  0.002114 -0.004126  \n",
       "11 -0.005183  0.000087  0.001664 -0.015333 -0.041152 -0.006309  \n",
       "12 -0.033517  0.000431  0.001990 -0.007891 -0.036346 -0.000598  \n",
       "13 -0.025626 -0.003980 -0.028221 -0.000352 -0.006336  0.000003  \n",
       "14 -0.010938 -0.008962 -0.000842 -0.059470 -0.028015 -0.004569  \n",
       "15 -0.006341  0.000430 -0.030495 -0.023601 -0.044078 -0.001176  \n",
       "16 -0.017238  0.000535 -0.000212 -0.030328 -0.013722 -0.001275  \n",
       "17  0.002441  0.000291 -0.025381 -0.009244  0.005860  0.000658  \n",
       "18 -0.017091  0.000371  0.000811 -0.015420 -0.067927 -0.006124  \n",
       "19 -0.016286 -0.000087 -0.030435 -0.000011 -0.001304 -0.001210  \n",
       "20  0.001487 -0.000142 -0.029078 -0.000423 -0.007251 -0.000054  \n",
       "21  0.000464 -0.000161 -0.000013 -0.013895  0.001820 -0.008285  \n",
       "22  0.004163  0.002307 -0.000325 -0.002026 -0.011905 -0.003062  \n",
       "23  0.001027 -0.008364 -0.002475 -0.049191 -0.006695 -0.004287  \n",
       "24  0.002043  0.002705 -0.001700  0.003561  0.001983 -0.000614  \n",
       "25  0.000884 -0.194929 -0.004180 -0.016036 -0.010715 -0.022650  \n",
       "26  0.000324 -0.000286 -0.039996 -0.000818 -0.002415 -0.000116  \n",
       "27 -0.077514 -0.004141  0.001605 -0.010243 -0.014152 -0.005518  \n",
       "28 -0.006456 -0.004341  0.000840  0.002849 -0.010786 -0.001163  \n",
       "29  0.004710  0.001540 -0.000543 -0.057203 -0.012986 -0.000927  \n",
       "30  0.001183 -0.000155 -0.029266 -0.000248 -0.007611 -0.000027  \n",
       "31 -0.008930  0.000019 -0.092523  0.002179 -0.047119 -0.009326  \n",
       "32 -0.011334 -0.025334  0.000800 -0.018879 -0.007286 -0.039112  \n",
       "33 -0.009100  0.000382  0.000924 -0.004900 -0.038395 -0.001122  \n",
       "34 -0.015643  0.000149 -0.037595  0.003118  0.003105 -0.002685  \n",
       "35 -0.035381  0.000009 -0.062973  0.002592  0.005830 -0.006924  \n",
       "36 -0.034290  0.000566  0.003288  0.001374  0.000244 -0.003793  \n",
       "37  0.003107 -0.000309 -0.064058  0.000794 -0.004619  0.000266  \n",
       "38 -0.040095 -0.003589 -0.063851  0.000277 -0.022295  0.000429  \n",
       "39  1.350742 -0.003461 -0.019649  0.001256  0.005320 -0.005730  \n",
       "40 -0.012502  1.223537 -0.002108 -0.031044  0.002447  0.002937  \n",
       "41 -0.007135 -0.000212  1.202567 -0.000208 -0.022181  0.000031  \n",
       "42  0.001517 -0.010379 -0.000692  1.320040 -0.069855 -0.000137  \n",
       "43  0.004211  0.000536 -0.048353 -0.045783  1.302184 -0.002873  \n",
       "44 -0.037730  0.005353  0.000561 -0.000745 -0.023898  1.427562  \n",
       "\n",
       "[45 rows x 45 columns]"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(IPDL_elasticity(q0_hat, x, theta0, Psi_stack, Nest_count)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum likelihood estimation of IPDL\n",
    "\n",
    "The log-likelihood contribution is\n",
    "$$\n",
    "\\ell_t(\\theta)=y_t'\\ln p(\\mathbf{X}_t,\\theta),\n",
    "$$\n",
    "and an estimation routine must therefore have a function that - given $\\mathbf{X}_t$ and $\\theta$ - calculates $u_t=\\mathbf{X}_t\\beta$ and constructs $\\Gamma$, and then calls the fixed point routine described above. That routine will return $p(\\mathbf{X}_t,\\theta)$, and we can then evaluate $\\ell_t(\\theta)$. Using our above defined functions we now construct precisely such an estimation procedure.\n",
    "\n",
    "For maximizing the likelihood, we want the derivates at some $\\theta=(\\beta',\\lambda')$. Let $q_t=p(\\mathbf{X}_t,\\theta)$, then we have\n",
    "$$\n",
    "\\nabla_\\theta \\ln p(\\mathbf{X}_t,\\theta)=\\mathrm{diag}(q_t)^{-1}\\left(\\nabla_{qq}^2\\Omega(q_t|\\lambda)^{-1}-q_tq_t' \\right)\\left[\\mathbf{X}_t,-\\nabla_{q,\\lambda}^2 \\Omega(q_t|\\lambda)\\right]\n",
    "$$\n",
    "Note that the first two components is the elasticity $\\nabla_u \\ln P(u|\\lambda)$ and the last term is a block matrix of size $J\\times dim(\\theta)$. Note that the latter cross derivative $\\nabla_{q,\\lambda}^2 \\Omega(q_t|\\lambda)$ is given by $\\nabla_{q,\\lambda}^2 \\Omega(q_t|\\lambda)_g = \\ln(q) - \\Psi^g \\ln(\\Psi^g q)$ for each row $g=1,\\ldots,G$. The derivative of the log-likelihood function can be obtained from this as\n",
    "$$\n",
    "\\nabla_\\theta \\ell_t(\\theta)=\\nabla_\\theta \\ln p(\\mathbf{X}_t,\\theta)' y_t \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_loglikelihood(Theta, y, x, sample_share, psi_stack, nest_count):\n",
    "    ''' \n",
    "    This function computes the loglikehood contribution for each individual i.\n",
    "    \n",
    "    Args.\n",
    "        Theta: a numpy array (K+G,) of parameters of (\\beta', \\lambda')',\n",
    "        y: a dictionary of T numpy arrays (J[t],) of observed market shares in onehot encoding for each market t,\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t,\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "\n",
    "    Output\n",
    "        ll: a numpy array (T,) of IPDL loglikelihood contributions\n",
    "    '''\n",
    "\n",
    "    T = len(x.keys())\n",
    "    K = x[0].shape[1]\n",
    "    ccp_hat = IPDL_ccp(Theta, x, psi_stack, nest_count)\n",
    "    ll = np.empty(T)\n",
    "    \n",
    "    print(np.array([theta for theta in Theta[K:] if theta >0]).sum())\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        ll[t] = np.einsum('j,j', y[t], np.log(ccp_hat[t], out = -np.inf*np.ones_like(ccp_hat[t]), where = (ccp_hat[t] > 0)))\n",
    "    \n",
    "    LL = np.einsum('t,t->t', sample_share, ll)\n",
    "\n",
    "    return LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_IPDL(Theta, y, x, sample_share, psi_stack, nest_count):\n",
    "    ''' The negative loglikelihood criterion to minimize\n",
    "    '''\n",
    "    Q = -IPDL_loglikelihood(Theta, y, x, sample_share, psi_stack, nest_count)\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also implement the derivative of the loglikehood wrt. parameters $\\nabla_\\theta \\ell_t(\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_grad_pertubation(q, psi_stack, nest_count):\n",
    "    ''' \n",
    "    This function calculates the cross diffential of the pertubation function \\Omega wrt. first ccp's and then the lambda parameters\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "    \n",
    "    Returns\n",
    "        Z: a dictionary of T numpy arrays (J[t],G) of cross diffentials of the pertubation function \\Omega wrt. first ccp's and then the lambda parameters\n",
    "    '''\n",
    "\n",
    "    T = len(q.keys())\n",
    "    log_q = {t: np.log(q[t], out = -np.inf*np.ones_like(q[t]), where = (q[t] > 0)) for t in np.arange(T)} # Determine log(q), and set entries equal minus inifinity if entry <= 0\n",
    "    Z = {}\n",
    "    \n",
    "    for t in np.arange(T):\n",
    "        G = len(nest_count[t])\n",
    "        indices = np.int64(np.cumsum(nest_count[t])) # Find the indices of the categories g used in the psi_stack matrices\n",
    "        J = np.int64(psi_stack[t].shape[0] - np.sum(nest_count[t])) # Find the number of alternatives\n",
    "        Z_t = np.empty((J,G)) # Initialize a J[t] by G numpy matrix for market t\n",
    "\n",
    "        for g in np.arange(G):\n",
    "\n",
    "            # Find the \\psi^g matrix for category g\n",
    "            if g == 0:\n",
    "                Psi = psi_stack[t][J:J+indices[g],:] \n",
    "            else:\n",
    "                Psi = psi_stack[t][J+indices[g-1]:J+indices[g],:]\n",
    "\n",
    "            Psi_q = np.einsum('cj,j->c', Psi, q[t]) # Compute a matrix product\n",
    "            log_Psiq = np.log(Psi_q, out = -np.inf*np.ones_like(Psi_q), where = (Psi_q > 0)) # Determine log of Psi_q, and set entries equal to minus infinity if entry <= 0.\n",
    "            Psi_logPsiq = np.einsum('cj,c->j', Psi, log_Psiq) # Compute matrix product\n",
    "\n",
    "            Z_t[:,g] = log_q[t] - Psi_logPsiq # Compute cross differential\n",
    "        \n",
    "        Z[t] = Z_t\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_theta_grad_log_ccp(Theta, x, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calculates the derivative of the IPDL log ccp's wrt. parameters theta\n",
    "\n",
    "    Args.\n",
    "        Theta: a numpy array (K+G,) of parameters of (\\beta', \\lambda')',\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t,\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "    Returns\n",
    "        Grad: a dictionary of T numpy arrays (J[t],K+G) of derivatives of the IPDL log ccp's wrt. parameters theta for each market t\n",
    "    '''\n",
    "\n",
    "    T = len(x.keys())\n",
    "\n",
    "    q = IPDL_ccp(Theta, x, psi_stack, nest_count) # Find choice probabilities\n",
    "\n",
    "    Z = cross_grad_pertubation(q, psi_stack, nest_count) # Find cross differentials of the pertubation function\n",
    "    G = [np.concatenate((x[t], Z[t]), axis=1) for t in np.arange(T)] # Construct the block matrix of the covariates and the cross differentials as block matrices\n",
    "\n",
    "    u_grad = IPDL_u_grad_Log_ccp(q, x, Theta, psi_stack, nest_count) # Find the gradient of log ccp's wrt. utilities\n",
    "\n",
    "    Grad = {t: np.einsum('jk,kd->jd', u_grad[t], G[t]) for t in np.arange(T)} # Compute the derivative by matrix multiplication.\n",
    "\n",
    "    return Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_score(Theta, y, x, sample_share, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calculates the score of the IPDL loglikelihood.\n",
    "\n",
    "    Args.\n",
    "        Theta: a numpy array (K+G,) of parameters of (\\beta', \\lambda')',\n",
    "        y: a dictionary of T numpy arrays (J[t],) of observed market shares in onehot encoding for each market t,\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t,\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "\n",
    "    Returns\n",
    "        Score: a numpy array (T,K+G) of IPDL scores\n",
    "    '''\n",
    "    T = len(x.keys())\n",
    "\n",
    "    log_ccp_grad = IPDL_theta_grad_log_ccp(Theta, x, psi_stack, nest_count) # Find derivatives of the IPDL log ccp's wrt. parameters theta\n",
    "    D = log_ccp_grad[0].shape[1] # equal to K+G\n",
    "    yLog_grad = np.empty((T,D))\n",
    "    \n",
    "    for t in np.arange(T):\n",
    "        yLog_grad[t,:] = np.einsum('j,jd->d', y[t], log_ccp_grad[t]) # Computes a matrix product\n",
    "\n",
    "    Score = np.einsum('t,td->td', sample_share, yLog_grad)\n",
    "\n",
    "    return Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_IPDL_score(Theta, y, x, sample_share, psi_stack, nest_count):\n",
    "    ''' The derivative of the negative loglikelihood criterion\n",
    "    '''\n",
    "    return -IPDL_score(Theta, y, x, sample_share, psi_stack, nest_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "delta = 1.0e-4\n",
    "numgrad = np.empty((T, K+G))\n",
    "\n",
    "for i in np.arange(K+G):\n",
    "    vec = np.zeros((K+G,))\n",
    "    vec[i] = 1\n",
    "    numgrad[:,i] = (IPDL_loglikelihood(theta0 + delta*vec, y, x, Psi_stack, Nest_count) - IPDL_loglikelihood(theta0, y, x, Psi_stack, Nest_count)) / delta"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "angrad = IPDL_score(theta0, y, x, Psi_stack, Nest_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "numgrad.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame(numgrad[0,:]).tranpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame(angrad[0,:]).tranpose()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.mean(angrad - numgrad[0, :], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard errors in Maximum Likelihood estimation\n",
    "\n",
    "As usual we may consistently estimate the Covariance Matrix  of the IPDL maximum likelihood estimator for some estimate $\\hat \\theta = (\\hat \\beta', \\hat \\lambda')'\\in \\mathbb{R}^{K+G}$ as:\n",
    "\n",
    "$$\n",
    "\\hat \\Sigma = \\left( \\sum_{i=1}^N \\nabla_\\theta \\ell_i (\\hat \\theta) \\nabla_\\theta \\ell_i (\\hat \\theta)' \\right)^{-1}\n",
    "$$\n",
    "\n",
    "Thereby we may find the estimated standard error of parameter $d$ as the squareroot of the d'th diagonal entry of $\\hat \\Sigma$:\n",
    "\n",
    "$$\n",
    "\\hat \\sigma_d = \\sqrt{\\hat \\Sigma_{dd}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_se(score, N):\n",
    "    '''\n",
    "    This function computes the asymptotic standard errors of the MLE.\n",
    "\n",
    "    Args.\n",
    "        score: a numpy array (T,K+G) of IPDL scores\n",
    "        N: an integer giving the number of observations\n",
    "\n",
    "    Returns\n",
    "        SE: a numpy array (K+G,) of asymptotic IPDL MLE standard errors\n",
    "    '''\n",
    "\n",
    "    SE = np.sqrt(np.diag(la.inv(np.einsum('td,tm->dm', score, score))) / N)\n",
    "\n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_t_p(SE, Theta, N, Theta_hypothesis = 0):\n",
    "    ''' \n",
    "    This function calculates t statistics and p values for characteristic and nest grouping parameters\n",
    "\n",
    "    Args.\n",
    "        SE: a numpy array (K+G,) of asymptotic IPDL MLE standard errors\n",
    "        Theta: a numpy array (K+G,) of parameters of (\\beta', \\lambda')',\n",
    "        N: an integer giving the number of observations\n",
    "        Theta_hypothesis: a (K+G,) array or integer of parameter values to test in t-test. Default value is 0.\n",
    "    \n",
    "    Returns\n",
    "        T: a (K+G,) array of estimated t tests\n",
    "        p: a (K+G,) array of estimated asymptotic p values computed using the above t-tests\n",
    "    '''\n",
    "\n",
    "    T = np.abs(Theta - Theta_hypothesis) / SE\n",
    "    p = 2*scstat.t.sf(T, df = N-1)\n",
    "\n",
    "    return T,p"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_IPDL(f, Theta0, y, x, sample_share, psi_stack, nest_count, N, Analytic_jac:bool = True, options = {'disp': True}, **kwargs):\n",
    "    ''' \n",
    "    Takes a function and returns the minimum, given starting values and variables necessary in the IPDL model specification.\n",
    "\n",
    "    Args:\n",
    "        f: a function to minimize,\n",
    "        Theta0 : a numpy array (K+G,) of initial guess parameters (\\beta', \\lambda')',\n",
    "        y: a dictionary of T numpy arrays (J[t],) of observed market shares in onehot encoding for each market t,\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t,\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests', \n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t,\n",
    "        N: an integer giving the number of observations,\n",
    "        Analytic_jac: a boolean. Default value is 'True'. If 'True' the analytic jacobian of the IPDL loglikelihood function is used in estimation. Else the numerical jacobian is used.\n",
    "        options: dictionary with options for the optimizer (e.g. disp=True which tells it to display information at termination.)\n",
    "    \n",
    "    Returns:\n",
    "        res: a dictionary with results from the estimation.\n",
    "    '''\n",
    "\n",
    "    # The objective function is the average of q(), \n",
    "    # but Q is only a function of one variable, theta, \n",
    "    # which is what minimize() will expect\n",
    "    Q = lambda Theta: np.mean(f(Theta, y, x, sample_share, psi_stack, nest_count))\n",
    "\n",
    "    if Analytic_jac == True:\n",
    "        Grad = lambda Theta: np.mean(q_IPDL_score(Theta, y, x, sample_share, psi_stack, nest_count), axis=0) # Finds the Jacobian of Q. Takes mean of criterion q derivatives along axis=0, i.e. the mean across individuals.\n",
    "    else:\n",
    "        Grad = None\n",
    "\n",
    "    # call optimizer\n",
    "    result = optimize.minimize(Q, Theta0.tolist(), options=options, jac=Grad, **kwargs) # optimize.minimize takes a list of parameters Theta0 (not a numpy array) as initial guess.\n",
    "    se = IPDL_se(IPDL_score(result.x, y, x, sample_share, psi_stack, nest_count), N)\n",
    "    T,p = IPDL_t_p(se, result.x, N)\n",
    "\n",
    "    # collect output in a dict \n",
    "    res = {\n",
    "        'theta': result.x,\n",
    "        'se': se,\n",
    "        't': T,\n",
    "        'p': p,\n",
    "        'success':  result.success, # bool, whether convergence was succesful \n",
    "        'nit':      result.nit, # no. algorithm iterations \n",
    "        'nfev':     result.nfev, # no. function evaluations \n",
    "        'fun':      result.fun # function value at termination \n",
    "    }\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46153846153846145\n",
      "0.4566877345901953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4372848267971301\n",
      "0.3596731956248692\n",
      "0.12089668974022115\n",
      "0.07428411799561326\n",
      "0.08147305677277689\n",
      "0.0833004091855898\n",
      "0.08528106029641751\n",
      "0.09320366473972835\n",
      "0.10643818643499312\n",
      "0.12476122733790798\n",
      "0.15102514178694776\n",
      "0.1906034927019265\n",
      "0.2592064114194111\n",
      "0.2836109827573435\n",
      "0.2772351886287216\n",
      "0.2654304494620005\n",
      "0.26120597608661933\n",
      "0.260346440741585\n",
      "0.2595073171997134\n",
      "0.25847801616271937\n",
      "0.2543608120147431\n",
      "0.24908016478487663\n",
      "0.2444054938473904\n",
      "0.24030411998429055\n",
      "0.23708333382090024\n",
      "0.23742000278102632\n",
      "0.26110313091053555\n",
      "0.3215747865659672\n",
      "0.35365373977354514\n",
      "0.36929034223334567\n",
      "0.36676939810689924\n",
      "0.36424482721252915\n",
      "0.3624906457641227\n",
      "0.36069880068343396\n",
      "0.35863064601044453\n",
      "0.3559839525373415\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.001531\n",
      "         Iterations: 33\n",
      "         Function evaluations: 38\n",
      "         Gradient evaluations: 38\n"
     ]
    }
   ],
   "source": [
    "resbla2 = estimate_IPDL(q_IPDL, theta0, y, x, pop_share, Psi_stack, Nest_count, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variables</th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>t (theta == 0)</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in_out</th>\n",
       "      <td>-2.443</td>\n",
       "      <td>3.921125</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cy</th>\n",
       "      <td>-0.247</td>\n",
       "      <td>2.156073</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hp</th>\n",
       "      <td>-0.389</td>\n",
       "      <td>2.199548</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>-0.853</td>\n",
       "      <td>1.931258</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>-1.824</td>\n",
       "      <td>2.847992</td>\n",
       "      <td>0.641</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wi</th>\n",
       "      <td>-1.98</td>\n",
       "      <td>3.535185</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>-2.0</td>\n",
       "      <td>3.183799</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>li</th>\n",
       "      <td>-0.658</td>\n",
       "      <td>1.202141</td>\n",
       "      <td>0.547</td>\n",
       "      <td>0.584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp</th>\n",
       "      <td>-1.309</td>\n",
       "      <td>2.395003</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac</th>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.242422</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr</th>\n",
       "      <td>0.849</td>\n",
       "      <td>1.244501</td>\n",
       "      <td>0.682</td>\n",
       "      <td>0.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_2</th>\n",
       "      <td>1.7294***</td>\n",
       "      <td>0.357217</td>\n",
       "      <td>4.841</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_2</th>\n",
       "      <td>0.993</td>\n",
       "      <td>1.474251</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_3</th>\n",
       "      <td>0.9873***</td>\n",
       "      <td>0.309937</td>\n",
       "      <td>3.185</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_4</th>\n",
       "      <td>0.805</td>\n",
       "      <td>0.631185</td>\n",
       "      <td>1.275</td>\n",
       "      <td>0.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_5</th>\n",
       "      <td>0.78**</td>\n",
       "      <td>0.383536</td>\n",
       "      <td>2.033</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_6</th>\n",
       "      <td>0.665*</td>\n",
       "      <td>0.395703</td>\n",
       "      <td>1.681</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_7</th>\n",
       "      <td>0.955</td>\n",
       "      <td>1.335844</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_8</th>\n",
       "      <td>0.964</td>\n",
       "      <td>1.776312</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_9</th>\n",
       "      <td>0.896</td>\n",
       "      <td>1.072536</td>\n",
       "      <td>0.836</td>\n",
       "      <td>0.403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_10</th>\n",
       "      <td>0.728</td>\n",
       "      <td>0.450792</td>\n",
       "      <td>1.615</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_12</th>\n",
       "      <td>0.868</td>\n",
       "      <td>1.590547</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_13</th>\n",
       "      <td>0.925</td>\n",
       "      <td>2.098225</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_14</th>\n",
       "      <td>0.92*</td>\n",
       "      <td>0.551301</td>\n",
       "      <td>1.669</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_15</th>\n",
       "      <td>0.958</td>\n",
       "      <td>1.628326</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_16</th>\n",
       "      <td>0.633</td>\n",
       "      <td>0.499969</td>\n",
       "      <td>1.266</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_17</th>\n",
       "      <td>0.83</td>\n",
       "      <td>1.038725</td>\n",
       "      <td>0.799</td>\n",
       "      <td>0.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_18</th>\n",
       "      <td>0.915</td>\n",
       "      <td>0.565841</td>\n",
       "      <td>1.617</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_19</th>\n",
       "      <td>0.893</td>\n",
       "      <td>1.243785</td>\n",
       "      <td>0.718</td>\n",
       "      <td>0.473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_20</th>\n",
       "      <td>0.894</td>\n",
       "      <td>1.389870</td>\n",
       "      <td>0.643</td>\n",
       "      <td>0.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_22</th>\n",
       "      <td>0.777*</td>\n",
       "      <td>0.398174</td>\n",
       "      <td>1.951</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_23</th>\n",
       "      <td>0.9471***</td>\n",
       "      <td>0.309849</td>\n",
       "      <td>3.057</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_24</th>\n",
       "      <td>0.471</td>\n",
       "      <td>0.348680</td>\n",
       "      <td>1.350</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_25</th>\n",
       "      <td>0.859</td>\n",
       "      <td>2.288902</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_26</th>\n",
       "      <td>0.784</td>\n",
       "      <td>1.142124</td>\n",
       "      <td>0.686</td>\n",
       "      <td>0.493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_27</th>\n",
       "      <td>0.999</td>\n",
       "      <td>7.240475</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_28</th>\n",
       "      <td>0.962</td>\n",
       "      <td>3.526196</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_29</th>\n",
       "      <td>0.988</td>\n",
       "      <td>6.118144</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_30</th>\n",
       "      <td>0.939</td>\n",
       "      <td>1.347797</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_32</th>\n",
       "      <td>0.954</td>\n",
       "      <td>0.653249</td>\n",
       "      <td>1.461</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_33</th>\n",
       "      <td>0.997</td>\n",
       "      <td>0.755519</td>\n",
       "      <td>1.320</td>\n",
       "      <td>0.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_34</th>\n",
       "      <td>0.8586***</td>\n",
       "      <td>0.292666</td>\n",
       "      <td>2.934</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_35</th>\n",
       "      <td>0.864</td>\n",
       "      <td>1.170614</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_36</th>\n",
       "      <td>0.796</td>\n",
       "      <td>1.209625</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_in_out</th>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.245252</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_cy</th>\n",
       "      <td>-0.012</td>\n",
       "      <td>0.044323</td>\n",
       "      <td>0.282</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_hp</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.052839</td>\n",
       "      <td>0.263</td>\n",
       "      <td>0.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_we</th>\n",
       "      <td>0.043</td>\n",
       "      <td>0.055957</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_le</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.078207</td>\n",
       "      <td>1.477</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_wi</th>\n",
       "      <td>0.102</td>\n",
       "      <td>0.068449</td>\n",
       "      <td>1.483</td>\n",
       "      <td>0.138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_he</th>\n",
       "      <td>0.042</td>\n",
       "      <td>0.050934</td>\n",
       "      <td>0.823</td>\n",
       "      <td>0.411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_li</th>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.029706</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_sp</th>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.053276</td>\n",
       "      <td>0.257</td>\n",
       "      <td>0.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_ac</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.070839</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_home</th>\n",
       "      <td>-0.101</td>\n",
       "      <td>0.156935</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_brand</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.157492</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variables         theta        se  t (theta == 0)      p\n",
       "in_out           -2.443  3.921125           0.623  0.533\n",
       "cy               -0.247  2.156073           0.114  0.909\n",
       "hp               -0.389  2.199548           0.177  0.860\n",
       "we               -0.853  1.931258           0.442  0.659\n",
       "le               -1.824  2.847992           0.641  0.522\n",
       "wi                -1.98  3.535185           0.560  0.575\n",
       "he                 -2.0  3.183799           0.628  0.530\n",
       "li               -0.658  1.202141           0.547  0.584\n",
       "sp               -1.309  2.395003           0.546  0.585\n",
       "ac                -0.03  1.242422           0.024  0.981\n",
       "pr                0.849  1.244501           0.682  0.495\n",
       "home_2        1.7294***  0.357217           4.841  0.000\n",
       "brand_2           0.993  1.474251           0.674  0.500\n",
       "brand_3       0.9873***  0.309937           3.185  0.001\n",
       "brand_4           0.805  0.631185           1.275  0.202\n",
       "brand_5          0.78**  0.383536           2.033  0.042\n",
       "brand_6          0.665*  0.395703           1.681  0.093\n",
       "brand_7           0.955  1.335844           0.715  0.475\n",
       "brand_8           0.964  1.776312           0.543  0.587\n",
       "brand_9           0.896  1.072536           0.836  0.403\n",
       "brand_10          0.728  0.450792           1.615  0.106\n",
       "brand_12          0.868  1.590547           0.546  0.585\n",
       "brand_13          0.925  2.098225           0.441  0.659\n",
       "brand_14          0.92*  0.551301           1.669  0.095\n",
       "brand_15          0.958  1.628326           0.588  0.556\n",
       "brand_16          0.633  0.499969           1.266  0.205\n",
       "brand_17           0.83  1.038725           0.799  0.424\n",
       "brand_18          0.915  0.565841           1.617  0.106\n",
       "brand_19          0.893  1.243785           0.718  0.473\n",
       "brand_20          0.894  1.389870           0.643  0.520\n",
       "brand_22         0.777*  0.398174           1.951  0.051\n",
       "brand_23      0.9471***  0.309849           3.057  0.002\n",
       "brand_24          0.471  0.348680           1.350  0.177\n",
       "brand_25          0.859  2.288902           0.375  0.708\n",
       "brand_26          0.784  1.142124           0.686  0.493\n",
       "brand_27          0.999  7.240475           0.138  0.890\n",
       "brand_28          0.962  3.526196           0.273  0.785\n",
       "brand_29          0.988  6.118144           0.161  0.872\n",
       "brand_30          0.939  1.347797           0.697  0.486\n",
       "brand_32          0.954  0.653249           1.461  0.144\n",
       "brand_33          0.997  0.755519           1.320  0.187\n",
       "brand_34      0.8586***  0.292666           2.934  0.003\n",
       "brand_35          0.864  1.170614           0.738  0.461\n",
       "brand_36          0.796  1.209625           0.658  0.510\n",
       "group_in_out       -0.1  0.245252           0.409  0.682\n",
       "group_cy         -0.012  0.044323           0.282  0.778\n",
       "group_hp          0.014  0.052839           0.263  0.792\n",
       "group_we          0.043  0.055957           0.762  0.446\n",
       "group_le          0.115  0.078207           1.477  0.140\n",
       "group_wi          0.102  0.068449           1.483  0.138\n",
       "group_he          0.042  0.050934           0.823  0.411\n",
       "group_li         -0.033  0.029706           1.100  0.271\n",
       "group_sp         -0.014  0.053276           0.257  0.798\n",
       "group_ac          0.024  0.070839           0.342  0.732\n",
       "group_home       -0.101  0.156935           0.646  0.518\n",
       "group_brand       0.016  0.157492           0.104  0.918"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPDL_theta, IPDL_SE = resbla2['theta'], resbla2['se']\n",
    "IPDL_t, IPDL_p = IPDL_t_p(IPDL_SE, IPDL_theta, N)\n",
    "\n",
    "if OO:\n",
    "    regdex = [*x_vars, *['group_' + var for var in nest_vars]]\n",
    "else:\n",
    "    regdex = [*x_vars, *['group_' + var for var in nest_vars]]\n",
    "\n",
    "bla  = pd.DataFrame({'theta': [ str(np.round(IPDL_theta[i], decimals = 4)) + '***' if IPDL_p[i] <0.01 else str(np.round(IPDL_theta[i], decimals = 3)) + '**' if IPDL_p[i] <0.05 else str(np.round(IPDL_theta[i], decimals = 3)) + '*' if IPDL_p[i] <0.1 else np.round(IPDL_theta[i], decimals = 3) for i in range(len(IPDL_theta))], \n",
    "              'se' : np.round(IPDL_SE, decimals = 10),\n",
    "              't (theta == 0)': np.round(IPDL_t, decimals = 3),\n",
    "              'p': np.round(IPDL_p, decimals = 3)}, index = regdex).rename_axis(columns = 'variables')\n",
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3559839525373415\n"
     ]
    }
   ],
   "source": [
    "LR = 2*(IPDL_loglikelihood(IPDL_theta, y, x, pop_share, Psi_stack, Nest_count).sum() - logit.logit_loglikehood(logit_beta, y, x, pop_share).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004744599550101258"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scstat.chi2.sf(LR, df = G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find the corresponding choice probabilities implied by the MLE $\\hat \\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_hat = IPDL_ccp(IPDL_theta, x, Psi_stack, Nest_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For market $t=1$ the choice probabilites $\\hat q_t$ are: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>products</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.986866</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "products        0         1         2         3         4         5   \\\n",
       "market                                                                 \n",
       "0         0.986866  0.000256  0.000396  0.000184  0.000167  0.000247   \n",
       "\n",
       "products        6         7         8         9   ...        35        36  \\\n",
       "market                                            ...                       \n",
       "0         0.000173  0.000093  0.000066  0.000209  ...  0.000147  0.000189   \n",
       "\n",
       "products        37        38        39        40        41        42  \\\n",
       "market                                                                 \n",
       "0         0.000515  0.000373  0.000278  0.000095  0.000597  0.000247   \n",
       "\n",
       "products        43        44  \n",
       "market                        \n",
       "0         0.000365  0.000104  \n",
       "\n",
       "[1 rows x 45 columns]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(q_hat[0]).transpose().rename_axis(columns = 'products', index = 'market')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also find the IPDL price elasticities $\\mathcal{E}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_hat = IPDL_elasticity(q_hat, x, IPDL_theta, Psi_stack, Nest_count)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For market $t=1$ the price elasticities are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame(E_hat[0]).rename_axis(columns = 'wrt. product', index = 'elasticity of product')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversion ratios for the IPDL model\n",
    "\n",
    "The diversion ratio to product j from product k is the fraction of consumers leaving product k and switching to product j following a one percent increase in the price of product k. Hence we have:\n",
    "\n",
    "$$\n",
    "\\mathcal{D}_{jk}^i = -100 \\cdot \\frac{\\partial P_j(u_i|\\lambda) / \\partial x_{ik\\ell}}{\\partial P_k(u_i|\\lambda) / \\partial x_{ik\\ell}} = -100 \\cdot \\frac{\\partial P_j(u_i|\\lambda) / \\partial u_{ik}}{\\partial P_k(u_i|\\lambda) / \\partial u_{ik}}\n",
    "$$\n",
    "\n",
    "Where $\\mathcal{D}^i = \\left( \\mathcal{D}_{jk}^i \\right)_{j,k \\in \\{0,1,\\ldots ,5\\}}$ is the matrix of diversion ratios for individual i. This can be written more compactly as:\n",
    "\n",
    "$$\n",
    "\\mathcal{D}^i = -100 \\cdot  (\\nabla_u P(u|\\lambda) \\circ I_J)^{-1}\\nabla_u P(u|\\lambda)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IPDL_diversion_ratio(q, x, Theta, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calculates diversion ratios from the IPDL model\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        Theta: a numpy array (K+G,) of parameters\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "\n",
    "    Returns\n",
    "        Diversion_ratio: a dictionary of T numpy arrays (J,J) of diversion ratios from product j to product k for each individual i\n",
    "    '''\n",
    "\n",
    "    T = len(q.keys())\n",
    "\n",
    "    Grad = ccp_gradient(q, x, Theta, psi_stack, nest_count) # Find the derivatives of ccp's wrt. utilities\n",
    "    inv_diaggrad = {t: np.divide(1, np.diag(Grad[t]), out = np.zeros_like(np.diag(Grad[t])), where = (np.diag(Grad[t]) != 0)) for t in np.arange(T)}  # Compute the inverse of the 'own'-derivatives of ccp's\n",
    "    DR = {t: np.multiply(-100, np.einsum('j,jk->jk', inv_diaggrad[t], Grad[t])) for t in np.arange(T)} # Compute diversion ratios as a hadamard product.\n",
    "\n",
    "    \n",
    "    return DR "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the implied diversion ratios $\\mathcal{ D}^i$ from our estimates $\\hat \\theta^{\\text{IPDL}}$, we find for market $t=1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "DR_hat = IPDL_diversion_ratio(q_hat, x, IPDL_theta, Psi_stack, Nest_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.DataFrame(DR_hat[0]).rename_axis(index = 'DR of products', columns = 'DR wrt. products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.,  0.,  0.,  0., -0., -0.,  0.,  0.,  0., -0.,  0.,  0.,  0.,\n",
       "        0.,  0., -0.,  0., -0.,  0.,  0.,  0., -0., -0.,  0.,  0., -0.,\n",
       "        0.,  0., -0.,  0., -0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0., -0.,  0.])"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DR_hat[0].sum(axis = 1).round(decimals = 8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of elasticities and diversion ratios\n",
    "\n",
    "We now compare the elasticities and the diversion ratios of the Logit and IPDL model. To clarify the interpretation of our results we will aggregate these according to the categorical variable `cla` describing the class or segment code of each vehicle. This variable takes values 'subcompact', 'compact', 'intermediate', 'standard', and 'luxury' encoded as the integers $1,\\ldots, 5$. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all classes/segments $c,\\ell \\in \\{1,\\ldots, 5\\}$ we calculate the change in the probability of class $c$, given as $q_c = \\sum_j 1_{\\{j\\in c\\}} q_j$, for a one unit increase in each of the utilities $u_j$ for products $j\\in\\ell$ i.e. we calculate the directional derivatives $\\frac{\\partial q_c}{\\partial u_{\\ell}}$. Then the price-to-income semi-elasticity of class $c$ wrt. class $\\ell$ is given as $\\bar E_{c\\ell} = \\frac{\\partial q_c}{\\partial u_\\ell} \\frac{1}{q_c} \\beta_{\\text{princ}}$. We use the fact that the directional derivative is calculated as $\\frac{\\partial q_c}{\\partial u_{\\ell}} = \\sum_{j\\in c} \\sum_{k\\in \\ell} \\frac{\\partial q_j}{\\partial u_k}$. In matrix notation this may be calulated as $\\bar E = \\psi^{\\text{class}} \\mathcal{E} {\\psi^{\\text{class}}}'$, where $\\bar E = (\\bar E_{c\\ell})_{c,\\ell = 1,\\ldots,5}$ is the matrix of semi-elasticities between vehicle classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psi_clafull, cla_descr, cla_count = Create_nests(dat[['cla', 'market', 'co']], 'market', 'co', ['cla'], outside_option=OO)\n",
    "\n",
    "if OO:\n",
    "    Psi_cla = {t: Psi_clafull[t][J[t]:, :] for t in np.arange(T)}\n",
    "else:\n",
    "    Psi_cla = {t: Psi_clafull[t][J[t]:, :] for t in np.arange(T)}\n",
    "    \n",
    "T_agg = Psi_cla[0].shape[0]\n",
    "\n",
    "q_Logit_agg = {t: np.einsum('cj,j->c', Psi_cla[t], logit_q[t]) for t in np.arange(T)}\n",
    "q_IPDL_agg = {t: np.einsum('cj,j->c', Psi_cla[t], q_hat[t]) for t in np.arange(T)}\n",
    "\n",
    "Grad_Logit = {t: (np.diag(logit_q[t]) - np.einsum('j,k->jk', logit_q[t], logit_q[t])) for t in np.arange(T)}\n",
    "Grad_IPDL = ccp_gradient(q_hat, x, IPDL_theta, Psi_stack, Nest_count)\n",
    "\n",
    "dq_dp_Logit_agg = {t: np.einsum('cj,jk,lk->cl', Psi_cla[t], Grad_Logit[t], Psi_cla[t])*logit_beta[K-1] for t in np.arange(T)}\n",
    "dq_dp_IPDL_agg = {t: np.einsum('cj,jk,lk->cl', Psi_cla[t], Grad_IPDL[t], Psi_cla[t])*IPDL_theta[K-1] for t in np.arange(T)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logit_E_agg = {t:  np.einsum('c,cl->cl', 1./ q_Logit_agg[t], dq_dp_Logit_agg[t]) for t in np.arange(T)}\n",
    "IPDL_E_agg = {t: np.einsum('c,cl->cl', 1./q_IPDL_agg[t], dq_dp_IPDL_agg[t]) for t in np.arange(T)}\n",
    "\n",
    "E0, E1 = np.empty((T, T_agg, T_agg)), np.empty((T, T_agg, T_agg))\n",
    "for t in np.arange(T):\n",
    "    E0[t,:,:] = Logit_E_agg[t]\n",
    "    E1[t,:,:] = IPDL_E_agg[t]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we plot histograms of our results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "E0p = {j : (E0.reshape((T, T_agg**2))[:,j]).flatten() for j in np.arange(T_agg**2)} # Finds j'th entry in each of the elasticity matrices of individuals i.\n",
    "\n",
    "j_pairs = iter.product(np.arange(T_agg), np.arange(T_agg))\n",
    "num_bins = 25\n",
    "\n",
    "fig, axes = plt.subplots(T_agg, T_agg)\n",
    "\n",
    "for p, j in zip(j_pairs, np.arange(T_agg**2)):\n",
    "    axes[p].hist(E0p[j], num_bins, range = (np.quantile(E0p[j], 0.10), np.quantile(E0p[j], 0.90)), color = 'r', alpha = 1) # Logit is blue\n",
    "    axes[p].vlines(0, 0, 25, 'g', 'dotted')\n",
    "    axes[p].get_xaxis().set_visible(False)\n",
    "    axes[p].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.suptitle('Histograms of weigthed sums of Logit (red) and IPDL (blue) price elasticities by class')\n",
    "fig.supxlabel('Weigthed sum of elasticities wrt. classes')\n",
    "fig.supylabel('Weigthed sum of elasticities of classes')\n",
    "fig.text(0.11, 0.8, '1', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.64, '2', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.48, '3', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.32, '4', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.16, '5', ha = 'center', va = 'center')\n",
    "fig.text(0.2, 0.9, '1', ha = 'center', va = 'center')\n",
    "fig.text(0.36, 0.9, '2', ha = 'center', va = 'center')\n",
    "fig.text(0.52, 0.9, '3', ha = 'center', va = 'center')\n",
    "fig.text(0.68, 0.9, '4', ha = 'center', va = 'center')\n",
    "fig.text(0.84, 0.9, '5', ha = 'center', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "E1p = {j : (E1.reshape((T, T_agg**2))[:,j]).flatten() for j in np.arange(T_agg**2)}\n",
    "\n",
    "j_pairs = iter.product(np.arange(T_agg), np.arange(T_agg))\n",
    "num_bins = 25\n",
    "\n",
    "fig1, axes1 = plt.subplots(T_agg, T_agg)\n",
    "\n",
    "for p, j in zip(j_pairs, np.arange(T_agg**2)):\n",
    "    axes1[p].hist(E1p[j], num_bins, range = (np.quantile(E1p[j], 0.10), np.quantile(E1p[j], 0.90)), color = 'b', alpha = 1) # IPDL is blue\n",
    "    axes1[p].vlines(0, 0, 25, 'red', 'dotted')\n",
    "    axes1[p].get_xaxis().set_visible(False)\n",
    "    axes1[p].get_yaxis().set_visible(False)\n",
    "\n",
    "fig1.suptitle('Histograms of weigthed sums of Logit (red) and IPDL (blue) price elasticities by class')\n",
    "fig1.supxlabel('Weigthed sum of elasticities wrt. classes')\n",
    "fig1.supylabel('Weigthed sum of elasticities of classes')\n",
    "fig1.text(0.11, 0.8, '1', ha = 'center', va = 'center')\n",
    "fig1.text(0.11, 0.64, '2', ha = 'center', va = 'center')\n",
    "fig1.text(0.11, 0.48, '3', ha = 'center', va = 'center')\n",
    "fig1.text(0.11, 0.32, '4', ha = 'center', va = 'center')\n",
    "fig1.text(0.11, 0.16, '5', ha = 'center', va = 'center')\n",
    "fig1.text(0.2, 0.9, '1', ha = 'center', va = 'center')\n",
    "fig1.text(0.36, 0.9, '2', ha = 'center', va = 'center')\n",
    "fig1.text(0.52, 0.9, '3', ha = 'center', va = 'center')\n",
    "fig1.text(0.68, 0.9, '4', ha = 'center', va = 'center')\n",
    "fig1.text(0.84, 0.9, '5', ha = 'center', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The mean elasticities for the logit model are given as..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Mean elasticity wrt. product</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean elasticity of product</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021136</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.003375</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>-0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.775655</td>\n",
       "      <td>0.786409</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.003375</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>-0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.775655</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>0.791808</td>\n",
       "      <td>-0.003375</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>-0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.775655</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>0.793416</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>-0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.775655</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.003375</td>\n",
       "      <td>0.795145</td>\n",
       "      <td>-0.000749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.775655</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.003375</td>\n",
       "      <td>-0.001647</td>\n",
       "      <td>0.796043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Mean elasticity wrt. product         0         1         2         3  \\\n",
       "Mean elasticity of product                                             \n",
       "0                             0.021136 -0.010383 -0.004983 -0.003375   \n",
       "1                            -0.775655  0.786409 -0.004983 -0.003375   \n",
       "2                            -0.775655 -0.010383  0.791808 -0.003375   \n",
       "3                            -0.775655 -0.010383 -0.004983  0.793416   \n",
       "4                            -0.775655 -0.010383 -0.004983 -0.003375   \n",
       "5                            -0.775655 -0.010383 -0.004983 -0.003375   \n",
       "\n",
       "Mean elasticity wrt. product         4         5  \n",
       "Mean elasticity of product                        \n",
       "0                            -0.001647 -0.000749  \n",
       "1                            -0.001647 -0.000749  \n",
       "2                            -0.001647 -0.000749  \n",
       "3                            -0.001647 -0.000749  \n",
       "4                             0.795145 -0.000749  \n",
       "5                            -0.001647  0.796043  "
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(E0.mean(axis = 0)).rename_axis(columns = 'Mean elasticity wrt. product', index = 'Mean elasticity of product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For IPDL the mean elasticities are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Mean elasticity wrt. product</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean elasticity of product</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.021379</td>\n",
       "      <td>-0.008483</td>\n",
       "      <td>-0.005694</td>\n",
       "      <td>-0.004078</td>\n",
       "      <td>-0.002152</td>\n",
       "      <td>-0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.815071</td>\n",
       "      <td>0.779320</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.004374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.780338</td>\n",
       "      <td>0.012001</td>\n",
       "      <td>0.773234</td>\n",
       "      <td>-0.013015</td>\n",
       "      <td>0.004899</td>\n",
       "      <td>0.003218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.780047</td>\n",
       "      <td>0.027293</td>\n",
       "      <td>-0.017304</td>\n",
       "      <td>0.777230</td>\n",
       "      <td>-0.005001</td>\n",
       "      <td>-0.002170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.779764</td>\n",
       "      <td>0.033687</td>\n",
       "      <td>0.012474</td>\n",
       "      <td>-0.009470</td>\n",
       "      <td>0.768247</td>\n",
       "      <td>-0.025174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.782954</td>\n",
       "      <td>0.037209</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>-0.006422</td>\n",
       "      <td>-0.061080</td>\n",
       "      <td>0.792535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Mean elasticity wrt. product         0         1         2         3  \\\n",
       "Mean elasticity of product                                             \n",
       "0                             0.021379 -0.008483 -0.005694 -0.004078   \n",
       "1                            -0.815071  0.779320  0.007760  0.014157   \n",
       "2                            -0.780338  0.012001  0.773234 -0.013015   \n",
       "3                            -0.780047  0.027293 -0.017304  0.777230   \n",
       "4                            -0.779764  0.033687  0.012474 -0.009470   \n",
       "5                            -0.782954  0.037209  0.020711 -0.006422   \n",
       "\n",
       "Mean elasticity wrt. product         4         5  \n",
       "Mean elasticity of product                        \n",
       "0                            -0.002152 -0.000970  \n",
       "1                             0.009460  0.004374  \n",
       "2                             0.004899  0.003218  \n",
       "3                            -0.005001 -0.002170  \n",
       "4                             0.768247 -0.025174  \n",
       "5                            -0.061080  0.792535  "
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(E1.mean(axis = 0)).rename_axis(columns = 'Mean elasticity wrt. product', index = 'Mean elasticity of product')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diversion ratios\n",
    "\n",
    "We now visualize the implied diversion ratios $\\mathcal{D}$. If $\\bar D_{c\\ell}$ denotes the sum of choice probability weigthed diversion ratios, then we have as above that $\\bar D_{c\\ell} = \\sum_{j}\\sum_{k} \\mathrm{1}_{\\{j\\in c\\}} \\mathrm{1}_{\\{k\\in \\ell\\}} q_j q_k \\mathcal{D}_{jk}$ i.e. more generally $\\bar D = (\\psi^{\\text{class}} \\circ q) \\mathcal{D} (\\psi^{\\text{class}} \\circ q).'$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "Logit_D_agg = {t: -100*np.einsum('c,cl->cl', 1./np.diag(dq_dp_Logit_agg[t]), dq_dp_Logit_agg[t]) for t in np.arange(T)}\n",
    "IPDL_D_agg = {t: -100*np.einsum('c,cl->cl', 1./np.diag(dq_dp_IPDL_agg[t]), dq_dp_IPDL_agg[t]) for t in np.arange(T)}\n",
    "\n",
    "D0, D1 = np.empty((T, T_agg, T_agg)), np.empty((T, T_agg, T_agg))\n",
    "for t in np.arange(T):\n",
    "    D0[t,:,:] = Logit_D_agg[t]\n",
    "    D1[t,:,:] = IPDL_D_agg[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D0p = {j : (D0.reshape((T, T_agg**2))[:,j]).flatten() for j in np.arange(T_agg**2)} # Finds j'th entry in each of the elasticity matrices of individuals i.\n",
    "\n",
    "j_pairs = iter.product(np.arange(T_agg), np.arange(T_agg))\n",
    "num_bins = 25\n",
    "\n",
    "fig, axes = plt.subplots(T_agg, T_agg)\n",
    "\n",
    "for p, j in zip(j_pairs, np.arange(T_agg**2)):\n",
    "    axes[p].hist(D0p[j], num_bins, range = (np.quantile(D0p[j], 0.10), np.quantile(D0p[j], 0.90)), color = 'r', alpha = 1) # Logit is red\n",
    "    axes[p].vlines(0, 0, 25, 'g', 'dotted')\n",
    "    axes[p].get_xaxis().set_visible(False)\n",
    "    axes[p].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.suptitle('Histograms of weigthed sums of Logit (red) and IPDL (blue) price diversion ratios by class')\n",
    "fig.supxlabel('Weigthed sum of diversion ratios wrt. classes')\n",
    "fig.supylabel('Weigthed sum of diversion ratios of classes')\n",
    "fig.text(0.11, 0.8, '1', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.64, '2', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.48, '3', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.32, '4', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.16, '5', ha = 'center', va = 'center')\n",
    "fig.text(0.2, 0.9, '1', ha = 'center', va = 'center')\n",
    "fig.text(0.36, 0.9, '2', ha = 'center', va = 'center')\n",
    "fig.text(0.52, 0.9, '3', ha = 'center', va = 'center')\n",
    "fig.text(0.68, 0.9, '4', ha = 'center', va = 'center')\n",
    "fig.text(0.84, 0.9, '5', ha = 'center', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 36 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "D1p = {j : (D1.reshape((T, T_agg**2))[:,j]).flatten() for j in np.arange(T_agg**2)}\n",
    "\n",
    "j_pairs = iter.product(np.arange(T_agg), np.arange(T_agg))\n",
    "num_bins = 25\n",
    "\n",
    "fig, axes = plt.subplots(T_agg, T_agg, sharex=False, sharey=False)\n",
    "\n",
    "for p, j in zip(j_pairs, np.arange(T_agg**2)):\n",
    "    axes[p].hist(D1p[j], num_bins, range = (np.quantile(D1p[j], 0.10), np.quantile(D1p[j], 0.90)), color = 'b', alpha = 1) # IPDL is blue\n",
    "    axes[p].vlines(0, 0, 25, 'red', 'dotted')\n",
    "    axes[p].get_xaxis().set_visible(False)\n",
    "    axes[p].get_yaxis().set_visible(False)\n",
    "\n",
    "fig.suptitle('Histograms of weigthed sums of Logit (red) and IPDL (blue) price diversion ratios by class')\n",
    "fig.supxlabel('Weigthed sum of diversion ratios wrt. classes')\n",
    "fig.supylabel('Weigthed sum of diversion ratios of classes')\n",
    "fig.text(0.11, 0.8, '1', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.64, '2', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.48, '3', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.32, '4', ha = 'center', va = 'center')\n",
    "fig.text(0.11, 0.16, '5', ha = 'center', va = 'center')\n",
    "fig.text(0.2, 0.9, '1', ha = 'center', va = 'center')\n",
    "fig.text(0.36, 0.9, '2', ha = 'center', va = 'center')\n",
    "fig.text(0.52, 0.9, '3', ha = 'center', va = 'center')\n",
    "fig.text(0.68, 0.9, '4', ha = 'center', va = 'center')\n",
    "fig.text(0.84, 0.9, '5', ha = 'center', va = 'center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We also calculate the mean diversion ratios within each class. For the Logit model these are given as..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Mean diversion ratio wrt. product</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean diversion ratio of product</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-100.000000</td>\n",
       "      <td>48.782097</td>\n",
       "      <td>23.849507</td>\n",
       "      <td>15.971722</td>\n",
       "      <td>7.977454</td>\n",
       "      <td>3.419220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98.631311</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.634197</td>\n",
       "      <td>0.429712</td>\n",
       "      <td>0.209490</td>\n",
       "      <td>0.095290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>97.959027</td>\n",
       "      <td>1.311828</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.426505</td>\n",
       "      <td>0.208053</td>\n",
       "      <td>0.094587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97.760639</td>\n",
       "      <td>1.309103</td>\n",
       "      <td>0.628249</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.207616</td>\n",
       "      <td>0.094393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97.548601</td>\n",
       "      <td>1.305885</td>\n",
       "      <td>0.626770</td>\n",
       "      <td>0.424587</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.094157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>97.438612</td>\n",
       "      <td>1.304417</td>\n",
       "      <td>0.626022</td>\n",
       "      <td>0.424078</td>\n",
       "      <td>0.206871</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Mean diversion ratio wrt. product           0           1           2  \\\n",
       "Mean diversion ratio of product                                         \n",
       "0                                 -100.000000   48.782097   23.849507   \n",
       "1                                   98.631311 -100.000000    0.634197   \n",
       "2                                   97.959027    1.311828 -100.000000   \n",
       "3                                   97.760639    1.309103    0.628249   \n",
       "4                                   97.548601    1.305885    0.626770   \n",
       "5                                   97.438612    1.304417    0.626022   \n",
       "\n",
       "Mean diversion ratio wrt. product           3           4           5  \n",
       "Mean diversion ratio of product                                        \n",
       "0                                   15.971722    7.977454    3.419220  \n",
       "1                                    0.429712    0.209490    0.095290  \n",
       "2                                    0.426505    0.208053    0.094587  \n",
       "3                                 -100.000000    0.207616    0.094393  \n",
       "4                                    0.424587 -100.000000    0.094157  \n",
       "5                                    0.424078    0.206871 -100.000000  "
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(D0.mean(axis = 0)).rename_axis(columns = 'Mean diversion ratio wrt. product', index = 'Mean diversion ratio of product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For the IPDL model the mean diversion ratios are..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Mean diversion ratio wrt. product</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mean diversion ratio of product</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-100.000000</td>\n",
       "      <td>39.496052</td>\n",
       "      <td>26.881012</td>\n",
       "      <td>18.974514</td>\n",
       "      <td>10.264926</td>\n",
       "      <td>4.383496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.652976</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>-1.045935</td>\n",
       "      <td>-1.829014</td>\n",
       "      <td>-1.213758</td>\n",
       "      <td>-0.564269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.986074</td>\n",
       "      <td>-1.612356</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>1.674446</td>\n",
       "      <td>-0.631465</td>\n",
       "      <td>-0.416699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.413461</td>\n",
       "      <td>-3.531402</td>\n",
       "      <td>2.205802</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>0.630756</td>\n",
       "      <td>0.281384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101.625198</td>\n",
       "      <td>-4.387740</td>\n",
       "      <td>-1.654001</td>\n",
       "      <td>1.186493</td>\n",
       "      <td>-100.000000</td>\n",
       "      <td>3.230050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>99.012551</td>\n",
       "      <td>-4.713950</td>\n",
       "      <td>-2.638694</td>\n",
       "      <td>0.727219</td>\n",
       "      <td>7.612874</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Mean diversion ratio wrt. product           0           1           2  \\\n",
       "Mean diversion ratio of product                                         \n",
       "0                                 -100.000000   39.496052   26.881012   \n",
       "1                                  104.652976 -100.000000   -1.045935   \n",
       "2                                  100.986074   -1.612356 -100.000000   \n",
       "3                                  100.413461   -3.531402    2.205802   \n",
       "4                                  101.625198   -4.387740   -1.654001   \n",
       "5                                   99.012551   -4.713950   -2.638694   \n",
       "\n",
       "Mean diversion ratio wrt. product           3           4           5  \n",
       "Mean diversion ratio of product                                        \n",
       "0                                   18.974514   10.264926    4.383496  \n",
       "1                                   -1.829014   -1.213758   -0.564269  \n",
       "2                                    1.674446   -0.631465   -0.416699  \n",
       "3                                 -100.000000    0.630756    0.281384  \n",
       "4                                    1.186493 -100.000000    3.230050  \n",
       "5                                    0.727219    7.612874 -100.000000  "
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(D1.mean(axis = 0)).rename_axis(columns = 'Mean diversion ratio wrt. product', index = 'Mean diversion ratio of product')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FKN estimation algorithm\n",
    "\n",
    "The FKN estimator begins with a nonparametric estimate of the CCP function, yielding choice probabilities $\\hat q^0_i$ for $i=1,\\ldots,N$. We wish to find parameters such that the PUM first-order condition is approximately satisfied at $\\hat q^0_i$, i.e. $\\hat \\theta^0$ such that \n",
    "$$\n",
    "\\hat q_i^0\\approx P(X_i,\\hat \\theta^0),\n",
    "$$\n",
    "approximately over the sample. We introduce a residual,\n",
    "$$\n",
    "\\hat \\varepsilon^0_i(\\theta)=\\hat D^0_i(u(X_i,\\beta)- \\nabla_q \\Omega(\\hat q_i^0|\\lambda)),\n",
    "$$\n",
    "where $\\hat D^0_i=\\textrm{diag}(\\hat q^0_i)-\\hat q^0_i (\\hat q^0_i)'$. We have already seen that we can write\n",
    "$$\n",
    "u(X_i,\\beta)-\\nabla_q \\Omega(\\hat q_i^0|\\lambda)=\\hat G^0_i \\theta-\\ln \\hat q^0_i\n",
    "$$\n",
    "where $\\hat G^0_i=[X_i,\\hat Z_i^0]$, where $Z_i^0 = \\nabla_{q,\\lambda}\\Omega(q_i^0|\\lambda)$. Letting $\\hat A^0_i=\\hat D^0_i \\hat G^0_i$ and $\\hat r_i^0=\\hat D^0_i \\ln \\hat q^0_i$, we therefore have\n",
    "$$\n",
    "\\hat \\varepsilon^0_i(\\theta)=\\hat A^0_i\\theta-\\hat r^0_i.\n",
    "$$\n",
    "We minimize the weigthed mean of these residuals over $\\theta$, with weights $\\hat W^0_i=\\textrm{diag}(\\hat q^0_i)^{-1}$,\n",
    "\n",
    "$$\n",
    "\\hat \\theta^0 =\\arg \\min_{\\theta} \\frac{1}{N}\\sum_i \\hat \\varepsilon_i(\\theta)'\\hat W_i^0 \\hat \\varepsilon_i(\\theta)\n",
    "$$\n",
    "which has the closed-form solution\n",
    "$$\n",
    "\\hat \\theta^0 =\\left(\\frac{1}{N}\\sum_i  (\\hat A^0_i)'\\hat W^0_i \\hat A^0_i \\right)^{-1}\\left(\\frac{1}{N}\\sum_i  (\\hat A^0_i)'\\hat W^0_i \\hat r_i^0 \\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [],
   "source": [
    "def G_array(q, x, psi_stack, nest_count):\n",
    "    ''' \n",
    "    This function calculates the G block matrix\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "\n",
    "    Returns\n",
    "        G: a dictionary  of T numpy arrays (J[t],K+G): a G matrix for each market t\n",
    "    '''\n",
    "    T = len(x)\n",
    "\n",
    "    Z = cross_grad_pertubation(q, psi_stack, nest_count) # Find the cross derivative of the pertubation function \\Omega wrt. lambda and ccp's q\n",
    "    G = {t: np.concatenate((x[t],Z[t]), axis=1) for t in np.arange(T)} # Join block matrices along 2nd dimensions  s.t. last dimension is K+G (same dimension as theta)\n",
    "\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_array(q):\n",
    "    '''\n",
    "    This function calculates the D matrix - the logit derivative of ccp's wrt. utilities\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "\n",
    "    Returns\n",
    "        D: a dictionary of T numpy arrays (J[t],J[t]) of logit derivatives of ccp's wrt. utilities for each market t\n",
    "    '''\n",
    "    T = len(q)\n",
    "\n",
    "    D = {t: np.diag(q[t]) - np.einsum('j,k->jk', q[t], q[t]) for t in np.arange(T)}\n",
    "    \n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "def A_array(q, x, psi_stack, nest_count):\n",
    "    '''\n",
    "    This function calculates the A matrix\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "\n",
    "    Returns\n",
    "        A: a dictionary  of T numpy arrays (J[t],K+G): an A matrix for each market t\n",
    "    '''\n",
    "    T = len(x)\n",
    "\n",
    "    D = D_array(q)\n",
    "    G = G_array(q, x, psi_stack, nest_count)\n",
    "    A = {t: np.einsum('jk,kd->jd', D[t], G[t]) for t in np.arange(T)}\n",
    "\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r_array(q):\n",
    "    '''\n",
    "    This function calculates 'r'; the logarithm of observed or nonparametrically estimated market shares\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "    \n",
    "    Returns\n",
    "        r: a dictionary of T numpy arrays (J[t],) of the log of ccp's for each market t\n",
    "    '''\n",
    "    T = len(q)\n",
    "\n",
    "    D = D_array(q) \n",
    "    log_q = {t: np.log(q[t], out = -np.inf*np.ones_like(q[t]), where = (q[t] > 0)) for t in np.arange(T)}\n",
    "    r = {t: np.einsum('jk,k->j', D[t], log_q[t]) for t in np.arange(T)}\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WLS_init(q, x, sample_share, psi_stack, nest_count, N):\n",
    "    ''' \n",
    "    This function calculates the weighted least squares estimator \\hat \\theta^k and its relevant estimated standard error for the initial FKN parameter estimates.\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        sample_share: A (T,) numpy array of the fraction of observations in each market t \n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "        N: An integer giving the total amount of observations\n",
    "\n",
    "    Returns\n",
    "        theta_hat: a (K+G,) numpy array of initial FKN parameter estimates\n",
    "        se_hat: a (K+G,) numpy array of standard errors for initial FKN parameter estimates\n",
    "    '''\n",
    "\n",
    "    T = len(x)\n",
    "\n",
    "    W = {t: la.inv(np.diag(q[t])) for t in np.arange(T)}\n",
    "    A = A_array(q, x, psi_stack, nest_count)\n",
    "    r = r_array(q)\n",
    "\n",
    "    d = A[0].shape[1]\n",
    "    \n",
    "    AWA = np.empty((T,d,d))\n",
    "    AWr = np.empty((T,d))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        AWA[t,:,:] = sample_share[t]*np.einsum('jd,jk,kp->dp', A[t], W[t], A[t], optimize = True)\n",
    "        AWr[t,:] = sample_share[t]*np.einsum('jd,jk,k->d', A[t], W[t], r[t], optimize = True)\n",
    "    \n",
    "    theta_hat = la.solve(AWA.sum(axis = 0), AWr.sum(axis = 0))\n",
    "    se_hat = np.sqrt(np.diag(la.inv(AWA.sum(axis = 0))) / N)\n",
    "    \n",
    "    return theta_hat,se_hat\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the observed market shares we may thus find initial parameter estimates $\\hat \\theta^0$ as described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetaFKN0,seFKN0 = WLS_init(y, x, pop_share, Psi_stack, Nest_count, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97014652, -0.00224835, -0.00600991, -0.00209521, -0.01570851,\n",
       "        0.00361645,  0.00822438, -0.01589948,  0.00603873,  0.00388372,\n",
       "       -0.05416584,  0.03497509])"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetaFKN0[K:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.01609511e-03, 2.83903623e-03, 3.05584179e-03, 2.61930605e-03,\n",
       "       2.70621047e-03, 4.89192680e-03, 4.34925968e-03, 1.76902754e-03,\n",
       "       3.54249018e-03, 1.55615617e-03, 1.37569616e-03, 2.80281150e-04,\n",
       "       4.38670856e-03, 2.68958759e-04, 7.49329391e-04, 4.16962021e-04,\n",
       "       3.56686104e-04, 1.75785191e-03, 2.14604945e-03, 2.67876857e-03,\n",
       "       3.30346413e-04, 9.07330557e-04, 1.65228575e-03, 1.69593153e-03,\n",
       "       3.22369097e-03, 5.62604136e-04, 7.97203752e-04, 4.55376137e-04,\n",
       "       1.30665579e-03, 6.82737992e-04, 3.05693876e-04, 2.97750813e-04,\n",
       "       3.80599098e-04, 1.48035566e-03, 7.71677490e-04, 3.99755904e-02,\n",
       "       1.51722882e-03, 1.66228119e-02, 3.06088124e-03, 1.03886279e-03,\n",
       "       1.50217279e-02, 6.90271009e-04, 7.63022104e-04, 7.26195759e-04,\n",
       "       2.66804774e-04, 6.88537697e-05, 7.77830555e-05, 6.65060548e-05,\n",
       "       7.48444627e-05, 8.21801290e-05, 5.63144061e-05, 5.16297734e-05,\n",
       "       6.94100888e-05, 7.59488137e-05, 2.50698448e-04, 1.78502767e-04])"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seFKN0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization for parameter bounds\n",
    "\n",
    "As we see above, the least squares estimator is not guaranteed to respect the parameter bounds $\\sum_g \\hat \\lambda_g<1$. However, we know that the logit probabilities $\\hat q^{logit}_i$ returns the estimates $\\hat \\theta^{logit}=(\\hat \\beta^{logit},0,0)'$. We can construct a sequence of estimators using the mixture probabilities\n",
    "$$\n",
    "\\hat q^{(t)}_i =(1-\\alpha_t) \\hat q^{logit}_i+\\alpha_t \\hat q_i\n",
    "$$\n",
    "and we know that $\\hat q^{(t)}_i$ respects the parameter bounds for $\\alpha_t$ sufficiently close to zero by continuity. We can then compare the likelihood values of each $\\hat \\theta^{(t)}$ and pick the best one. This ensures that the likelihood value of the initial estimator is at least as good as the logit solution. \n",
    "\n",
    "Note that the benefit of doing this is that we only ever need to do a one-dimensional grid search on the interval $[0,1]$ which is very simple. \n",
    "$$\n",
    "\\hat \\theta^*=\\arg \\max_{t} \\mathcal L_N(\\hat \\theta^{(t)})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogL(Theta, y, x, sample_share, psi_stack, nest_count):\n",
    "    ''' A function giving the mean IPDL loglikehood evaluated at data and an array of parameters 'Theta'\n",
    "    '''\n",
    "    return np.mean(IPDL_loglikelihood(Theta, y, x, sample_share, psi_stack, nest_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch(Theta0, Logit_Beta, y, x, sample_share, psi_stack, nest_count, N, num_alpha = 5):\n",
    "    ''' \n",
    "    '''\n",
    "    T = len(x)\n",
    "    d = Theta0.shape[0]\n",
    "    K = x[0].shape[1]\n",
    "    G = d-K\n",
    "\n",
    "    # Find probabilities\n",
    "    q_logit = logit.logit_ccp(Logit_Beta, x)\n",
    "    q_obs = y\n",
    "\n",
    "    # Search\n",
    "    alpha_line = np.linspace(0, 1, num_alpha)\n",
    "    LogL_alpha = np.empty((num_alpha,))\n",
    "    theta_alpha = np.empty((num_alpha, d))\n",
    "\n",
    "    for k in np.arange(num_alpha):\n",
    "\n",
    "        alpha = alpha_line[k]\n",
    "\n",
    "        if alpha == 0:\n",
    "            theta_alpha[k,:] = np.concatenate((Logit_Beta, np.zeros((G,))))\n",
    "        else:\n",
    "            q_alpha = {t: (1 - alpha)*q_logit[t] + alpha*q_obs[t] for t in np.arange(T)}\n",
    "            theta_alpha[k,:] = WLS_init(q_alpha, x, sample_share, psi_stack, nest_count, N)[0]\n",
    "\n",
    "        lambda_alpha = theta_alpha[k,K:]\n",
    "        \n",
    "        pos_pars = np.array([theta for theta in lambda_alpha if theta > 0])\n",
    "\n",
    "        if pos_pars.sum() > 0.999:\n",
    "            LogL_alpha[k] = np.NINF\n",
    "        else:\n",
    "            LogL_alpha[k] = LogL(theta_alpha[k,:], y, x, sample_share, psi_stack, nest_count)\n",
    "    \n",
    "    # Pick the best set of parameters\n",
    "    best_index = np.argmax(LogL_alpha)\n",
    "    best_alpha = alpha_line[best_index]\n",
    "    theta_hat_star = theta_alpha[best_index,:]\n",
    "\n",
    "    return theta_hat_star,best_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the grid search method we find corressponding parameters $\\hat \\theta^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.583821646614179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8492343145984843\n",
      "0.9513572188815023\n"
     ]
    }
   ],
   "source": [
    "theta_hat_star = GridSearch(thetaFKN0, logit_beta, y, x, pop_share, Psi_stack, Nest_count, N)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7.81168466e-01,  7.08167229e-04, -8.03213491e-04, -9.16587615e-03,\n",
       "       -8.23486772e-03,  1.63695727e-03,  9.73097846e-03, -4.70500605e-03,\n",
       "        6.55987886e-03,  2.99059446e-03,  1.60510041e-02,  3.03882687e-02])"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_hat_star[K:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterated FKN estimator\n",
    "\n",
    "The iterated estimator is as the initial one, except there is an additional term on $\\hat \\varepsilon$. First, we update the choice probabilities,\n",
    "$$\n",
    "\\hat q^k_i=p(\\mathbf X_i,\\hat \\theta^{k-1})\\\\\n",
    "$$\n",
    "Then we assign\n",
    "$$\n",
    "\\hat D^k_i=\\nabla^2_{qq}\\Omega(\\hat q_i^k|\\hat \\lambda^{k-1})^{-1}-(\\hat q^k_i \\hat q^k_i)'\n",
    "$$\n",
    "and then construct the residual\n",
    "$$\n",
    "\\hat \\varepsilon^k_i(\\theta)=\\hat D^k_i\\left( u(x_i,\\beta)-\\nabla_q \\Omega(\\hat q_i^k|\\lambda)\\right) -y_i+\\hat q_i^k,\n",
    "$$\n",
    "Which can once again be simplified as\n",
    "$$\n",
    "\\hat \\varepsilon^k_i(\\theta)= \\hat A_i^k \\theta-\\hat r^k_i,\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\hat A^k_i=\\hat D_i^k\\hat G^k_i, \\hat r_i^k =\\hat D^k_i\\ln \\hat q_i^k-y_i\n",
    "$$\n",
    "and where $\\hat G^k_i$ is constructed as in the initial estimator. Using the weighted least squares estimator with weights $\\hat W_i^k=\\textrm{diag}(\\hat q^k_i)^{-1}$, we get the estimator\n",
    "$$\n",
    "\\hat \\theta^k = \\arg \\min_{\\theta}\\frac{1}{n}\\sum_i \\hat \\varepsilon^k_i(\\theta)'\\hat W_i^k \\hat \\varepsilon^k_i(\\theta).\n",
    "$$\n",
    "We can once again solve it in closed form as\n",
    "$$\n",
    "\\hat \\theta^k =\\left( \\frac{1}{n}\\sum_i \\hat (A^k_i)'\\hat W_i^k \\hat A^k_i)\\right)^{-1}\\left( \\frac{1}{n}\\sum_i (\\hat A_i^k)'\\hat W_i^k \\hat r_i^k\\right)\n",
    "$$\n",
    "Now we implement this procedure and iterate starting from our initial guess $\\hat \\theta^{*}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WLS(Theta, y, x, sample_share, psi_stack, nest_count, N):\n",
    "    '''\n",
    "    This function calculates the weighted least squares estimator \\hat \\theta^k and its relevant estimated standard error for the iterated parameter estimates.\n",
    "\n",
    "    Args.\n",
    "        q: a dictionary of T numpy arrays (J[t],) of choice probabilities for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        sample_share: A (T,) numpy array of the fraction of observations in each market t \n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "        N: An integer giving the total amount of observations\n",
    "\n",
    "    Returns\n",
    "        theta_hat: a (K+G,) numpy array of initial FKN parameter estimates\n",
    "        se_hat: a (K+G,) numpy array of standard errors for initial FKN parameter estimates\n",
    "    '''\n",
    "    T = len(x)\n",
    "    d = Theta.shape[0]\n",
    "    \n",
    "    # Get ccp's\n",
    "    q = IPDL_ccp(Theta, x, psi_stack, nest_count)\n",
    "\n",
    "    # Construct A\n",
    "    D = ccp_gradient(q, x, Theta, psi_stack, nest_count) # A is here constructed using the IPDL derivative of ccp's wrt. utilities instead of teh Logit derivative\n",
    "    G = G_array(q, x, psi_stack, nest_count)\n",
    "    A = {t: np.einsum('jk,kd->jd', D[t], G[t]) for t in np.arange(T)}\n",
    "    W = {t: la.inv(np.diag(q[t])) for t in np.arange(T)}\n",
    "\n",
    "    # Construct r\n",
    "    log_q = {t: np.log(q[t], out = -np.inf*np.ones_like(q[t]), where=(q[t] > 0)) for t in np.arange(T)}\n",
    "    r = {t: np.einsum('jk,k->j', D[t], log_q[t]) + y[t] for t in np.arange(T)}\n",
    "\n",
    "    # Estimate parameters\n",
    "    AWA = np.empty((T,d,d))\n",
    "    AWr = np.empty((T,d))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        AWA[t,:,:] = sample_share[t]*np.einsum('jd,jk,kp->dp', A[t], W[t], A[t], optimize = True)\n",
    "        AWr[t,:] = sample_share[t]*np.einsum('jd,jk,k->d', A[t], W[t], r[t], optimize = True)\n",
    "\n",
    "    theta_hat = la.solve(AWA.sum(axis = 0), AWr.sum(axis = 0))\n",
    "    se_hat = np.sqrt(np.diag(la.inv(AWA.sum(axis = 0))) / N)\n",
    "\n",
    "    return theta_hat,se_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FKN_estimator(logit_beta, q_obs, x, sample_share, psi_stack, nest_count, N, tol = 1.0e-15, max_iters = 1000):\n",
    "    ''' \n",
    "    '''\n",
    "\n",
    "    theta_init = WLS_init(q_obs, x, sample_share, psi_stack, nest_count,  N)[0]\n",
    "    theta_hat_star = GridSearch(theta_init, logit_beta, y, x, sample_share, psi_stack, nest_count, N)[0]\n",
    "    theta0 = theta_hat_star\n",
    "    \n",
    "    for k in np.arange(max_iters):\n",
    "        theta1, se1 = WLS(theta0, q_obs, x, sample_share, psi_stack, nest_count, N)\n",
    "\n",
    "        # Check convergence in an appropriate distance function\n",
    "        dist = np.max(np.abs(theta1 - theta0))\n",
    "\n",
    "        if dist<tol:\n",
    "            succes = True\n",
    "            iter = k\n",
    "            break\n",
    "        elif k==max_iters:\n",
    "            succes = False\n",
    "            iter = max_iters\n",
    "            break\n",
    "        else:\n",
    "            None\n",
    "            \n",
    "        # Iteration step\n",
    "        theta0 = theta1\n",
    "\n",
    "    res = {'theta': theta1,\n",
    "           'se': se1,\n",
    "           'fun': -LogL(theta1, y, x, sample_share, psi_stack, nest_count),\n",
    "           'iter': iter,\n",
    "           'succes': succes}\n",
    "    \n",
    "    return res \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.583821646614179\n",
      "0.8492343145984843\n",
      "0.9513572188815023\n",
      "0.7934622460204379\n"
     ]
    }
   ],
   "source": [
    "res = FKN_estimator(logit_beta, y, x, pop_share, Psi_stack, Nest_count, N, tol=1.0e-8, max_iters=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "FKN_theta = res['theta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7934622460204379\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0014935862052751073"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_IPDL(FKN_theta, y, x, pop_share, Psi_stack, Nest_count).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLP Estimation and instruments\n",
    "\n",
    "The setting is now a bit different. Instead of the noise coming from random sampling of individuals, we now have an additional source of uncertainty, stemming frm the random sampling of the fixed effects ξmj for each market and each product. The number of ”observations” is therefore\n",
    "\n",
    "$$\n",
    "T = M \\cdot \\sum_m J_m\n",
    "$$\n",
    "\n",
    "Note that while random sampling of individuals choices (number of observations\n",
    "in the hundreds of millions) still has an effect on the estimated parameters in\n",
    "principle, this effect is completely drowned out by the sampling variance of the\n",
    "fixed effects (number of observations T ≈ 15000?), so we choose to ignore it\n",
    "here. When estimating random coefficients models, there is also a third source\n",
    "of uncertainty stemming from approximation of numerical integrals. This is not\n",
    "an issue in IPDL, as we have the inverse demand in closed form.\n",
    "\n",
    "The principles are pretty similar to what we have been doing already. When\n",
    "applicable, I will use the same notation as in the FKN section. Define the\n",
    "residual,\n",
    "\n",
    "$$\\xi_m(\\theta) = u(X_m, \\beta) − \\nabla_q \\Omega(q^0|\\lambda)$$\n",
    "\n",
    "In the IPDL model, this residual is a linear function of $\\theta$ which has the form\n",
    "\n",
    "$$\\xi_m(\\theta) =  G^0_m \\theta − r_m^0$$\n",
    "\n",
    "where $ G^0_m=[X_m, Z_m^0]$, where $Z_m^0 = \\nabla_{q,\\lambda}\\Omega(q_m^0|\\lambda)$ and $r^0_m = \\ln q^0_m$ as in the FKN section with $q^0_m$ being e.g. the observed market shares in market $m$. For the BLP estimator, we set this residual orthogonal to a matrix of instruments $\\hat Z_m$ of size $J_m \\times d$, and find the estimator $ \\hat \\theta^{IV}$ which solves the moment conditions\n",
    "\n",
    "$$\\frac{1}{T} \\sum_m \\hat Z_m' \\xi(\\hat \\theta^{IV}) = 0$$\n",
    "\n",
    "Since $\\hat \\xi$ is linear, the moment equations have a unique solution,\n",
    "\n",
    "$$\\hat \\theta^{IV} = \\left(\\frac{1}{T}\\sum_m \\hat Z_m' G^0_m \\right)^{-1}\\left(\\frac{1}{T}\\sum_m \\hat Z_m' r^0_m \\right)$$\n",
    "\n",
    "We require an instrument for the price of the goods. This is something which is correlated with the price, but uncorrelated with the error term $\\xi_m$ (in the BLP model, $\\xi_{mj}$ represents unobserved components of car quality). A standard instrument in this case would be a measure of marginal cost (or something which is correlated with marginal cost, like a production price index). For everything other than price, we can simply use the regressor itself as the instrument i.e. $ \\hat Z^{mjd} = G^0_{mjd}$, for all other dimensions than price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct our instruments $\\hat Z$. We'll use the average exchange rate of the destination country relative to average exchange rate of the origin country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "xexr = {t: dat[dat['market'] == t]['xexr'].values for t in np.arange(T)}\n",
    "G0 = G_array(y, x, Psi_stack, Nest_count)\n",
    "pr_index = len(x_contvars)\n",
    "for t in np.arange(T):\n",
    "    G0[t][:,pr_index] = xexr[t] / xexr[t].max()\n",
    "\n",
    "z = G0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the moment estimator $\\hat \\theta^{IV}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLP_estimator(y, z, x, sample_share, psi_stack, nest_count):\n",
    "    '''\n",
    "    Args.\n",
    "        y: a dictionary of T numpy arrasy (J[t],) of observed or nonparametrically estimated market shares for each market t\n",
    "        z: a dictionary of T numpy arrays (J[t],K+G) of instruments for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        sample_share: A (T,) numpy array of the fraction of observations in each market t \n",
    "        psi_stack: a dictionary of T numpy arrays (J[t] + sum(C_g),J[t]) of the J[t] by J[t] identity stacked on top of the \\psi^g matrices for each market t as outputted by 'Create_nests'\n",
    "        nest_count: a dictionary of T numpy arrays (G,) containing the amount of nests in each category g in each market t\n",
    "\n",
    "    Returns\n",
    "        theta_hat: a numpy array (K+G,) of BLP parameter estimates\n",
    "    '''\n",
    "    T = len(z)\n",
    "\n",
    "    G = G_array(y, x, psi_stack, nest_count)\n",
    "    d = G[0].shape[1]\n",
    "    r = {t: np.log(y[t], out = np.NINF*np.ones_like((y[t])), where = (y[t] > 0)) for t in np.arange(T)}\n",
    "    \n",
    "    sZG = np.empty((T,d,d))\n",
    "    sZr = np.empty((T,d))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        sZG[t,:,:] = sample_share[t]*np.einsum('jd,jp->dp', z[t], G[t])\n",
    "        sZr[t,:] = sample_share[t]*np.einsum('jd,j->d', z[t], r[t])\n",
    "\n",
    "    theta_hat = la.solve(sZG.sum(axis=0), sZr.sum(axis=0))\n",
    "    \n",
    "    return theta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLP_theta = BLP_estimator(y, z, x, np.ones((T,)), Psi_stack, Nest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0488350724635895"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([p for p in BLP_theta[K:] if p>0]).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Logit model we get the parameter estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_logit = x\n",
    "for t in np.arange(T):\n",
    "    G_logit[t][:,pr_index] = xexr[t] / xexr[t].max()\n",
    "\n",
    "z_logit = G_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogitBLP_beta = logit.LogitBLP_estimator(y, z_logit, x, np.ones((T,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-14.41280532,  -3.40334572,  -6.89531188,  -0.20128066,\n",
       "        -1.64085748,   9.70660596,  -1.33834143,  -0.35656005,\n",
       "         5.5599548 ,   0.04321336,  -0.20332981,   1.55202333,\n",
       "        -1.41808955,  -0.09416481,  -0.90156117,  -0.42922998,\n",
       "        -0.53882082,  -1.07436156,  -0.34372782,  -2.15059897,\n",
       "        -0.4392745 ,  -0.39547664,  -1.40645645,  -2.3489272 ,\n",
       "        -2.21275414,  -1.44546677,  -1.13740087,   1.00080306,\n",
       "        -1.30906969,  -0.15365879,  -0.24497036,  -0.14472295,\n",
       "        -0.78562084,  -0.48042182,  -1.21026099,  -2.98856691,\n",
       "        -0.81187713,  -2.72286568,  -1.53059041,  -0.14984331,\n",
       "        -1.31045303,  -0.91588229,  -0.52693591,   0.09731265])"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogitBLP_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLP approximation to optimal instruments\n",
    "\n",
    "BLP propose an algorithm for constructing an approximation to the optimal instruments. It is described in simple terms in Reynaert & Verboven (2014), and it has the following steps.\n",
    "It requires an initial parameter estimator $\\hat \\theta = (\\hat \\beta', \\hat \\lambda')'$, here we can just usethe MLE we have already computed. Let $W_m$ denote the matrix of instruments (this is the matrix $X_m$ with the price replaced by the exchange rate). The steps are then as follows:\n",
    "\n",
    "First we form the regression equation of the covariates on the instruments:\n",
    "$$\n",
    "X_m = W_m \\Pi + E_m\n",
    "$$\n",
    "\n",
    "The OLS estimate is then given as:\n",
    "$$\n",
    "\\hat \\Pi = \\left( \\frac{1}{T}\\sum_m W_m' W_m \\right)^{-1}\\left( \\frac{1}{T}\\sum_m W_m' X_m\\right)\n",
    "$$\n",
    "\n",
    "Thus the predicted covariates given the instruments $W$ are:\n",
    "$$\n",
    "\\hat X_m = W_m \\hat \\Pi\n",
    "$$\n",
    "\n",
    "Having constructed $\\hat X_m$ (which consists of the exogenous regressors, and the predicted price given $W_m$), we compute the predicted mean utility:\n",
    "\n",
    "$$\n",
    "\\hat u_m = \\hat X_m \\hat \\beta\n",
    "$$\n",
    "\n",
    "and then the predicted market shares at the mean utility:\n",
    "\n",
    "$$\n",
    "\\hat q_m^{*} = P(\\hat u_m | \\hat \\lambda)\n",
    "$$\n",
    "\n",
    "Computationally, here we just use $\\hat X_m$ in place of $X_m$ in the CCP function.\n",
    "Given the predicted market shares, we compute\n",
    "\n",
    "$$\n",
    "\\hat G_m^{*} = \\left[\\hat X_m, \\nabla_{q,\\lambda} \\Omega (\\hat q_m^{*} | \\hat \\lambda)\\right]\n",
    "$$\n",
    "\n",
    "which is the same as the function $\\hat G_m^0$ we already have constructed, except we evaluate it at the\n",
    "predictions $\\hat X_m$ and $\\hat q_m^{*}$ instead of at $X_m$ and $\\hat q_m^0$.\n",
    "\n",
    "The procedure above gives an approximation to the optimal instruments. We also require a weight matrix. The optimal weight matrix is the (generalized) inverse of the conditional (on the instruments) covariance of the fixed effects. Assuming $\\xi_{jm}$ is independetly and identically distributed over j and m, the conditional covariance simplifies to a scalar $\\sigma^2$ times an identity matrix (of size $J_m$).\n",
    "This means that all fixed effects are weighted equally, and the weights therefore drop out of the IV regression. The optimal IV estimator is therefore\n",
    "\n",
    "$$\n",
    "\\hat \\theta^{\\text{IV}} = \\left(\\frac{1}{T}\\sum_m (\\hat G_m^*)'\\hat G_m^0\\right)^{-1}\\left( \\frac{1}{T}\\sum_m (\\hat G_m^*)'\\hat r_m^0 \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\hat \\xi^*$ denote the estimated residual evaluated at the new parameter estimates,\n",
    "\n",
    "$$\n",
    "\\hat \\xi_{mj}^* = \\hat \\xi_{mj}(\\hat \\theta^{\\text{IV}})\n",
    "$$\n",
    "\n",
    "We may estimate the constant $\\sigma^2$ by\n",
    "\n",
    "$$\n",
    "\\hat \\sigma^2 = \\frac{1}{T}\\sum_{m}\\sum_{j = 1}^{J_m} \\left(\\hat \\xi_{mj}^*\\right)^2 \n",
    "$$\n",
    "\n",
    "The distribution of the estimator $\\hat \\theta^{\\text{IV}}$ is then\n",
    "\n",
    "$$\n",
    "\\hat \\theta^{\\text{IV}} \\sim \\mathcal{N}(\\theta_0, \\Sigma^{\\text{IV}})\n",
    "$$\n",
    "\n",
    "which can be consistently estimated by\n",
    "\n",
    "$$\n",
    "\\hat \\Sigma^{\\text{IV}} = \\hat \\sigma^2 \\left( \\sum_m (\\hat G_m^*)'\\hat G_m^0 \\right)^{-1}\n",
    "$$\n",
    "\n",
    "and the standard errors are then the square root of the diagonal elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_x(x, w, sample_share):\n",
    "    ''' \n",
    "    '''\n",
    "    T = len(w)\n",
    "    K = w[0].shape[1]\n",
    "\n",
    "    sWW = np.empty((T,K,K))\n",
    "    sWX = np.empty((T,K,K))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        sWW[t,:,:] = sample_share[t]*np.einsum('jk,jl->kl', w[t], w[t])\n",
    "        sWX[t,:,:] = sample_share[t]*np.einsum('jk,jl->kl', w[t], x[t])\n",
    "\n",
    "    Pi_hat = la.solve(sWW.sum(axis=0), sWX.sum(axis=0))\n",
    "    X_hat = {t: np.einsum('jl,lk->jk', w[t], Pi_hat) for t in np.arange(T)}\n",
    "\n",
    "    return X_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLP_se(Theta, y, x, psi_stack, nest_count):\n",
    "    ''' \n",
    "    '''\n",
    "    T = len(x)\n",
    "    S = T * np.array([x[t].shape[0] for t in np.arange(T)]).sum()\n",
    "\n",
    "    G = G_array(y, x, psi_stack, nest_count)\n",
    "    d = G[0].shape[1]\n",
    "    r = {t: np.log(y[t]) for t in np.arange(T)}\n",
    "    \n",
    "    # We calculate \\sigma^2\n",
    "    xi = {t: np.einsum('jd,d->j', G[t], Theta) - r[t] for t in np.arange(T)}\n",
    "    sum_xij2 = np.empty((T,))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        sum_xij2[t] = (xi[t]**2).sum()\n",
    "    \n",
    "    sigma2 = np.sum(sum_xij2) / S\n",
    "\n",
    "    # We calculate GG for each market t\n",
    "    GG = np.empty((T,d,d))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        GG[t,:,:] = np.einsum('jd,jp->dp', G[t], G[t])\n",
    "\n",
    "    # Finally we compute \\Sigma and the standard errors\n",
    "    Sigma = sigma2*la.inv(GG.sum(axis=0))\n",
    "    SE = np.sqrt(np.diag(Sigma))\n",
    "\n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimalBLP_estimator(Theta0, y, w, x, sample_share, psi_stack, nest_count):\n",
    "    ''' \n",
    "    '''\n",
    "    T = len(x)\n",
    "    K = x[0].shape[1]\n",
    "\n",
    "    beta0 = Theta0[:K]\n",
    "    lambda0 = Theta0[K:]\n",
    "    \n",
    "    X_hat = predict_x(x, w, sample_share)\n",
    "    q0 = IPDL_ccp(Theta0, X_hat, psi_stack, nest_count)\n",
    "    G_star =G_array(q0, X_hat, psi_stack, nest_count)\n",
    "    #G_star =G_array(y, w, psi_stack, nest_count)\n",
    "\n",
    "\n",
    "    G0 = G_array(y, x, psi_stack, nest_count)\n",
    "    \n",
    "    #G_star=G0\n",
    "    \n",
    "    r = {t: np.log(y[t]) for t in np.arange(T)}\n",
    "\n",
    "    d = G0[0].shape[1]\n",
    "\n",
    "    sGG = np.empty((T,d,d))\n",
    "    sGr = np.empty((T,d))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        sGG[t,:,:] = sample_share[t]*np.einsum('jd,jp->dp', G_star[t], G0[t])\n",
    "        sGr[t,:] = sample_share[t]*np.einsum('jd,j->d', G_star[t], r[t])\n",
    "\n",
    "    Theta_IV = la.solve(sGG.sum(axis=0), sGr.sum(axis=0))\n",
    "    SE_IV = BLP_se(Theta_IV, y, x, psi_stack, nest_count)\n",
    "\n",
    "    return Theta_IV, SE_IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThetaOptBLP, SEOptBLP = OptimalBLP_estimator(FKN_theta, y, z_logit, x, np.ones((T,)), Psi_stack, Nest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "G0 = G_array(y, x, Psi_stack, Nest_count)\n",
    "d = G0[0].shape[1]\n",
    "r = {t: np.log(y[t]) for t in np.arange(T)}\n",
    "\n",
    "# We calculate \\sigma^2\n",
    "xi = {t: np.einsum('jd,d->j', G0[t], ThetaOptBLP) - r[t] for t in np.arange(T)}\n",
    "xi_np = np.empty((np.int64(J.sum()),))\n",
    "index = J.cumsum()\n",
    "for t in np.arange(T):\n",
    "    if t == 0:\n",
    "        xi_np[:index[t]] = xi[t]\n",
    "    else:\n",
    "        xi_np[index[t-1]:index[t]] = xi[t]\n",
    "\n",
    "xi_np -= xi_np.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi_np.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8776777375151663"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([p for p in ThetaOptBLP[K:]  if p > 0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.28173042e-01, -3.15092898e-02,  3.44658661e-02, -2.08991905e-04,\n",
       "        1.94108492e-02, -9.95648060e-03,  3.95530634e-02, -2.71591621e-03,\n",
       "        7.28507623e-03,  4.97535967e-03, -4.47158701e-01,  2.43814481e-01])"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThetaOptBLP[K:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['in_out',\n",
       " 'cy',\n",
       " 'hp',\n",
       " 'we',\n",
       " 'le',\n",
       " 'wi',\n",
       " 'he',\n",
       " 'li',\n",
       " 'sp',\n",
       " 'ac',\n",
       " 'home',\n",
       " 'brand']"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nest_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00145795, 0.00054185, 0.00059773, 0.00050376, 0.000536  ,\n",
       "       0.00056075, 0.00041788, 0.00042156, 0.00051661, 0.00037735,\n",
       "       0.00129173, 0.00098001])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEOptBLP[K:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1402350"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = T*np.array([x[t].shape[0] for t in np.arange(T)]).sum()\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2033298123789972"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogitBLP_beta[pr_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.16183510387832414"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThetaOptBLP[pr_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8776777375151663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0015060950839790848"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-LogL(ThetaOptBLP, y, x, pop_share, Psi_stack, Nest_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.021697271544799"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.norm(FKN_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.496273124082977"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.norm(BLP_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.49276478812854"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la.norm(ThetaOptBLP)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
