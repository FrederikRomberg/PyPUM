{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eurocarsdata_file\n",
    "\n",
    "This file contains functions which are used in cleaning the `Eurocars.csv` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import os\n",
    "from numpy import linalg as la\n",
    "import itertools as iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Eurocars_cleandata(dat, x_contvars, x_discretevars, z_IV_contvars, z_IV_discretevars, outside_option = True):\n",
    "    ''' \n",
    "    '''\n",
    "\n",
    "    # Create the 'market' column of market index t\n",
    "\n",
    "    dat = dat.sort_values(by = ['ye', 'ma'], ascending = True) # Sorts data set by year and market\n",
    "    Used_cols = ['ye', 'ma', 'co', 'qu', 'pop', *x_contvars, *x_discretevars, *z_IV_contvars, *z_IV_discretevars]  \n",
    "    dat = dat[Used_cols] # Leaves out unused macro variables\n",
    "    market_vals = [*iter.product(dat['ye'].unique(), dat['ma'].unique())] # creates a list of ma-ye combinations\n",
    "    market_vals = pd.DataFrame({'ye' : [val[0] for val in market_vals], 'ma' : [val[1] for val in market_vals]}) \n",
    "    market_vals = market_vals.reset_index().rename(columns={'index' : 'market'}) # Creates market index\n",
    "    dat = dat.merge(market_vals, left_on=['ye', 'ma'], right_on=['ye', 'ma'], how='left') # Merges market index variable onto dat\n",
    "    dat_org = dat.copy() # Save the original data with the 'market'-column added as 'dat_org'.\n",
    "\n",
    "    # Create an inside/outside-option column if the outside option is included\n",
    "\n",
    "    if outside_option:\n",
    "        dat['in_out'] = 1\n",
    "\n",
    "    # Drop rows which contain NaN values in any explanatory variable or in the response variable.\n",
    "\n",
    "    dat = dat.dropna()\n",
    "\n",
    "    # Convert discrete explanatory variables to integer valued variables and make sure continuous variables are floats.\n",
    "\n",
    "    obj_columns = dat.select_dtypes(['object'])\n",
    "    for col in obj_columns:\n",
    "        if col in [*x_contvars, *z_IV_contvars]:\n",
    "            dat[col] = dat[col].str.replace(',', '.').astype('float64')\n",
    "        else:\n",
    "            dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64')\n",
    "\n",
    "    # Re-encode discrete variables such that only the outside option takes the value 0\n",
    "\n",
    "    ###############################################################################\n",
    "    x_0vars = [var for var in [*x_discretevars,*z_IV_discretevars] if len((dat[var].isin([0]))) > 0] # Picks out discrete variables where at least one car has category 0\n",
    "\n",
    "    for col in x_0vars:\n",
    "        dat[col] = dat[col].astype('category').cat.rename_categories(np.arange(1, dat[col].nunique() + 1)).astype('int64') # re-assigns category zero as category 1, and moves other categories up by one\n",
    "\n",
    "    #################################################################################\n",
    "    # Construct outside option for each market t\n",
    "    if outside_option:\n",
    "        outside_shares = dat.groupby('market', as_index=False)['qu'].sum() # sum of sales in each market\n",
    "        outside_shares = outside_shares.merge(dat[['market', 'pop']], on = 'market', how='left').dropna().drop_duplicates(subset = 'market', keep = 'first')  # Adds population to dataframe\n",
    "        outside_shares['qu'] = outside_shares['pop'] - outside_shares['qu'] # Assigns quantity for outside option as pop minus sum of sales\n",
    "        keys_add = [key for key in dat.keys() if (key!='market')&(key!='qu')&(key!='pop')] \n",
    "        for key in keys_add:\n",
    "            outside_shares[key] = 0 # Sets all variables other than market, qu and pop to zero for the outside option\n",
    "\n",
    "        dat = pd.concat([dat, outside_shares]) # Add outside option to data set\n",
    "\n",
    "    #################################################################################\n",
    "    # Compute market shares for each product j in each market t \n",
    "\n",
    "    dat['ms'] = dat.groupby('market')['qu'].transform(lambda x: x/x.sum())\n",
    "\n",
    "    #################################################################################\n",
    "    T = dat['market'].nunique() # Assigns the total number of markets T\n",
    "    J = np.array([dat[dat['market'] == t]['co'].nunique() for t in np.arange(T)]) # Array of number of choices in market t\n",
    "\n",
    "\n",
    "    # Number of observations \n",
    "    if outside_option:\n",
    "        N = np.array([dat[dat['market'] == t]['pop'].unique().sum() for t in np.arange(T)]).sum() # If outside option is included, number of observations in market t is the total population\n",
    "    else:\n",
    "        N = np.array([dat[dat['market'] == t]['qu'].sum() for t in np.arange(T)]).sum() # If outside option is not included, number of observations in market t is the total number of sales\n",
    "\n",
    "\n",
    "    # Get each market's share of total population N\n",
    "    pop_share = np.empty((T,))\n",
    "    for t in np.arange(T):\n",
    "        pop_share[t] = dat[dat['market'] == t]['qu'].sum() / N\n",
    "\n",
    "    ##################################################################################\n",
    "    dat[[*x_contvars, *z_IV_contvars]] = dat[[*x_contvars, *z_IV_contvars]] / dat[[*x_contvars, *z_IV_contvars]].abs().max() # Rescale continuous variables so that they lie in the interval [-1,1]. This is done for numerical stability.\n",
    "\n",
    "    ###################################################################################\n",
    "    # Construct dummies of discrete variables. For each variable, one of the columns is left out due to colinearity\n",
    "\n",
    "    datx_disc = pd.get_dummies(dat[x_discretevars], prefix = x_discretevars, columns = x_discretevars, drop_first=True)\n",
    "    if len(z_IV_discretevars) > 0:\n",
    "        datz_disc = pd.get_dummies(dat[z_IV_discretevars], prefix = z_IV_discretevars, columns = z_IV_discretevars, drop_first=True)\n",
    "    else:\n",
    "        datz_disc = None\n",
    "\n",
    "    # If outside option is included, then each variable results in a column which is 1 for the outside option, and zero for all other options. These columns are identical to the 'in_out' variable column,\n",
    "    # so a second column must be dropped for each variable.\n",
    "    if outside_option:\n",
    "        xdisc_keep = [[var for var in datx_disc.keys() if var.startswith(x_var)] for x_var in x_discretevars]\n",
    "        xdisc_keep = [xdisc_keep[i][1:] for i in np.arange(len(xdisc_keep))]\n",
    "        xdisc_keep = sum(xdisc_keep, [])\n",
    "        datx_disc = datx_disc[xdisc_keep] # Drops a second column from discrete columns if outside option is included\n",
    "        if len(z_IV_discretevars) > 0:\n",
    "            zdisc_keep = [[var for var in datz_disc.keys() if var.startswith(z_var)] for z_var in z_IV_discretevars]\n",
    "            zdisc_keep = [zdisc_keep[i][1:] for i in np.arange(len(zdisc_keep))]\n",
    "            zdisc_keep = sum(zdisc_keep, [])\n",
    "            datz_disc = datz_disc[[var for var in datz_disc.keys() if not var.endswith('1')]]\n",
    "\n",
    "    # Add dummy variables onto the original DataFrame\n",
    "    if len(z_IV_discretevars) > 0:\n",
    "        dat = pd.concat([dat, datx_disc, datz_disc], axis = 1)\n",
    "    else:\n",
    "        dat = pd.concat([dat, datx_disc], axis = 1)\n",
    "\n",
    "    # Record explanatory variables and IV regressors\n",
    "    if outside_option:\n",
    "        x_vars = ['in_out', *x_contvars, *datx_disc.keys() ]\n",
    "    else:\n",
    "        x_vars = [*x_contvars, *datx_disc.keys() ]\n",
    "\n",
    "    if len(z_IV_discretevars) > 0:\n",
    "        z_vars = [*z_IV_contvars, *datz_disc.keys()]\n",
    "    else:\n",
    "        z_vars = z_IV_contvars\n",
    "\n",
    "    # Count the number of characteristics\n",
    "    K = len(x_vars)\n",
    "\n",
    "    return dat,dat_org,x_vars,z_vars,N,pop_share,T,J,K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function tests whether the utility parameters are identified, by looking at the rank of the stacked matrix of explanatory variables.\n",
    "\n",
    "def rank_test(x):\n",
    "    x_stacked = np.concatenate([x[t] for t in np.arange(T)], axis = 0)\n",
    "    eigs=la.eig(x_stacked.T@x_stacked)[0]\n",
    "\n",
    "    if np.min(eigs)<1.0e-8:\n",
    "        print('x does not have full rank')\n",
    "    else:\n",
    "        print('x has full rank')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
