{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV estimation of the Similarity model\n",
    "\n",
    "This notebook introduces a BLP estimator of Similarity demand parameters. Since standard instruments often result in biased parameter estimates and higher standard errors, we also implement optimal instruments (See e.g. Reynaert & Verboven, 2014) in the Similarity Model setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import os\n",
    "import sys\n",
    "from numpy import linalg as la\n",
    "from scipy import optimize\n",
    "import scipy.stats as scstat\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools as iter\n",
    "%load_ext line_profiler\n",
    "\n",
    "# Files\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "data_path = os.path.join(module_path, 'data')\n",
    "\n",
    "from utilities.Logit_file import estimate_logit, logit_se, logit_t_p, q_logit, logit_score, logit_score_unweighted, logit_ccp, LogitBLP_estimator, LogitBLP_se\n",
    "from data.Eurocarsdata_file import Eurocars_cleandata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and variable names\n",
    "descr = (pd.read_stata(os.path.join(data_path,'eurocars.dta'), iterator = True)).variable_labels() # Obtain variable descriptions\n",
    "dat_file = pd.read_csv(os.path.join(data_path, 'eurocars.csv')) # reads in the data set as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable names</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cy</td>\n",
       "      <td>cylinder volume or displacement (in cc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hp</td>\n",
       "      <td>horsepower (in kW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we</td>\n",
       "      <td>weight (in kg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le</td>\n",
       "      <td>length (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wi</td>\n",
       "      <td>width (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he</td>\n",
       "      <td>height (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>li</td>\n",
       "      <td>average of li1, li2, li3 (used in papers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sp</td>\n",
       "      <td>maximum speed (km/hour)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ac</td>\n",
       "      <td>time to acceleration (in seconds from 0 to 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pr</td>\n",
       "      <td>price (in destination currency including V.A.T.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>brand</td>\n",
       "      <td>name of brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home</td>\n",
       "      <td>domestic car dummy (appropriate interaction of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cla</td>\n",
       "      <td>class or segment code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable names                                        description\n",
       "0              cy            cylinder volume or displacement (in cc)\n",
       "1              hp                                 horsepower (in kW)\n",
       "2              we                                     weight (in kg)\n",
       "3              le                                     length (in cm)\n",
       "4              wi                                      width (in cm)\n",
       "5              he                                     height (in cm)\n",
       "6              li          average of li1, li2, li3 (used in papers)\n",
       "7              sp                            maximum speed (km/hour)\n",
       "8              ac  time to acceleration (in seconds from 0 to 100...\n",
       "9              pr   price (in destination currency including V.A.T.)\n",
       "10          brand                                      name of brand\n",
       "11           home  domestic car dummy (appropriate interaction of...\n",
       "12            cla                              class or segment code"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outside option is included if OO == True, otherwise analysis is done on the inside options only.\n",
    "OO = True\n",
    "\n",
    "# Choose which variables to include in the analysis, and assign them either as discrete variables or continuous.\n",
    "\n",
    "x_discretevars = [ 'brand', 'home', 'cla']\n",
    "x_contvars = ['cy', 'hp', 'we', 'le', 'wi', 'he', 'li', 'sp', 'ac', 'pr']\n",
    "z_IV_contvars = ['xexr']\n",
    "z_IV_discretevars = []\n",
    "x_allvars =  [*x_contvars, *x_discretevars]\n",
    "z_allvars = [*z_IV_contvars, *z_IV_discretevars]\n",
    "\n",
    "if OO:\n",
    "    nest_contvars = [var for var in x_contvars if var != 'pr'] # We nest over all variables other than price, but an alternative list can be specified here if desired.\n",
    "    nest_discvars = ['in_out', *x_discretevars]\n",
    "    nest_vars = ['in_out', *nest_contvars, *x_discretevars]\n",
    "else:\n",
    "    nest_contvars = [var for var in x_contvars if (var != 'pr')]\n",
    "    nest_discvars = x_discretevars # See above\n",
    "    nest_vars = [*nest_contvars, *nest_discvars]\n",
    "\n",
    "G = len(nest_vars)\n",
    "\n",
    "# Print list of chosen variables as a dataframe\n",
    "pd.DataFrame(descr, index=['description'])[x_allvars].transpose().reset_index().rename(columns={'index' : 'variable names'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat, dat_org, x_vars, z_vars, N, pop_share, T, J, K = Eurocars_cleandata(dat_file, x_contvars, x_discretevars, z_IV_contvars, z_IV_discretevars, outside_option=OO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries of numpy arrays for each market. This allows the size of the data set to vary over markets.\n",
    "\n",
    "dat = dat.reset_index(drop = True).sort_values(by = ['market', 'co']) # Sort data so that reshape is successfull\n",
    "\n",
    "x = {t: dat[dat['market'] == t][x_vars].values.reshape((J[t],K)) for t in np.arange(T)} # Dict of explanatory variables\n",
    "y = {t: dat[dat['market'] == t]['ms'].to_numpy().reshape((J[t])) for t in np.arange(T)} # Dict of market shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLP Estimation and instruments\n",
    "\n",
    "The setting is now a bit different. Instead of the noise coming from random sampling of individuals, we now have an additional source of uncertainty, stemming frm the random sampling of the fixed effects $\\xi_{tj}$ for each market and each product. The number of ”observations” is therefore\n",
    "\n",
    "$$\n",
    "S = T \\cdot \\sum_t J_t\n",
    "$$\n",
    "\n",
    "Note that while random sampling of individuals choices (number of observations\n",
    "in the hundreds of millions) still has an effect on the estimated parameters in\n",
    "principle, this effect is completely drowned out by the sampling variance of the\n",
    "fixed effects (number of observations $S \\approx 150^2 \\cdot 50$), so we choose to ignore it\n",
    "here. When estimating random coefficients Models, there is also a third source\n",
    "of uncertainty stemming from approximation of numerical integrals. This is not\n",
    "an issue in Similarity, as we have the inverse demand in closed form.\n",
    "\n",
    "The principles are pretty similar to what we have been doing already. When\n",
    "applicable, we will use the same notation as in the FKN section. Define the\n",
    "residual,\n",
    "\n",
    "$$\\xi_t(\\theta) = u(X_t, \\beta) − \\nabla_q \\Omega(q_t^0|\\lambda)$$\n",
    "\n",
    "In the Similarity Model, this residual is a linear function of $\\theta$ which has the form\n",
    "\n",
    "$$\\xi_t(\\theta) =  G^0_t \\theta − r_t^0$$\n",
    "\n",
    "where $ G^0_t=[X_t, -\\nabla_{q,\\lambda}\\Omega(q_t^0|\\lambda)]$ and $r^0_t = \\ln q^0_t$ as in the FKN section with $q^0_t$ being e.g. the observed market shares in market $t = 1, \\ldots, T$. For the BLP estimator, we set this residual orthogonal to a matrix of instruments $ Z_t$ of size $J_t \\times (K+G)$, and find the estimator $ \\hat \\theta^{IV}$ which solves the moment conditions\n",
    "\n",
    "$$\\frac{1}{T} \\sum_t  Z_t' \\xi(\\hat \\theta^{IV}) = 0$$\n",
    "\n",
    "Since $\\hat \\xi$ is linear, the moment equations have a unique solution,\n",
    "\n",
    "$$\\hat \\theta^{IV} = \\left(\\frac{1}{T}\\sum_t  Z_t' G^0_t \\right)^{-1}\\left(\\frac{1}{T}\\sum_t  Z_t' r^0_t \\right)$$\n",
    "\n",
    "We require an instrument for the price of the goods. This is something which is correlated with the price, but uncorrelated with the error term $\\xi_t$ (in the BLP Model, $\\xi_{tj}$ represents unobserved components of car quality). A standard instrument in this case would be a measure of marginal cost (or something which is correlated with marginal cost, like a production price index). For everything other than price, we can simply use the regressor itself as the instrument i.e. $  Z^{tjd} = G^0_{tjd}$, for all other dimensions than price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we construct our instruments $ Z$. We'll use the average exchange rate of the destination country relative to average exchange rate of the origin country. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = T*np.sum(np.array([x[t].shape[0] for t in np.arange(T)]))\n",
    "\n",
    "xexr = {t: dat[dat['market'] == t][z_vars[0]].values for t in np.arange(T)}\n",
    "G0 = G_array(y, x, Model)\n",
    "pr_index = len(x_contvars)\n",
    "for t in np.arange(T):\n",
    "    G0[t][:,pr_index] = xexr[t] / xexr[t].max()\n",
    "\n",
    "z = G0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then calculate the moment estimator $\\hat \\theta^{IV}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLP_estimator(q_obs, z, x, sample_share, model):\n",
    "    '''\n",
    "    Args.\n",
    "        q_obs: a dictionary of T numpy arrasy (J[t],) of observed or nonparametrically estimated market shares for each market t\n",
    "        z: a dictionary of T numpy arrays (J[t],K+G) of instruments for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        sample_share: A (T,) numpy array of the fraction of observations in each market t \n",
    "        model: a dictionary of the Similarity Model specification as outputted by 'Similarity_specification'\n",
    "\n",
    "    Returns\n",
    "        theta_hat: a numpy array (K+G,) of BLP parameter estimates\n",
    "    '''\n",
    "    T = len(z)\n",
    "\n",
    "    G = G_array(q_obs, x, model)\n",
    "    d = G[0].shape[1]\n",
    "    r = {t: np.log(q_obs[t], out = np.NINF*np.ones_like((q_obs[t])), where = (q_obs[t] > 0)) for t in np.arange(T)}\n",
    "    \n",
    "    sZG = np.empty((T,d,d))\n",
    "    sZr = np.empty((T,d))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        sZG[t,:,:] = sample_share[t]*np.einsum('jd,jp->dp', z[t], G[t])\n",
    "        sZr[t,:] = sample_share[t]*np.einsum('jd,j->d', z[t], r[t])\n",
    "\n",
    "    theta_hat = la.solve(sZG.sum(axis=0), sZr.sum(axis=0))\n",
    "    \n",
    "    return theta_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLP_theta = BLP_estimator(y, z, x, np.ones((T,)), Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Logit Model we get the parameter estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_logit = x\n",
    "for t in np.arange(T):\n",
    "    G_logit[t][:,pr_index] = xexr[t] / xexr[t].max()\n",
    "\n",
    "z_logit = G_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-14.92920752,  -2.3589754 ,  -6.76421995,   0.02963003,\n",
       "        -2.05176127,  10.84731336,  -1.04140126,  -0.58331478,\n",
       "         5.15289118,   0.51808091,  -0.17336342,  -2.037768  ,\n",
       "        -0.81720168,  -1.44357757,  -1.04059281,  -1.16245013,\n",
       "        -1.74530433,  -0.85123531,  -2.72300281,  -1.08758839,\n",
       "        -0.68958989,  -0.95909482,  -2.11727698,  -2.93039275,\n",
       "        -2.90655875,  -2.05527142,  -1.82107985,   0.51974428,\n",
       "        -2.02980519,  -0.79701277,  -0.86356478,  -0.86816254,\n",
       "        -0.81661044,  -1.48858878,  -0.9378501 ,  -1.87621854,\n",
       "        -3.7657435 ,  -1.52567201,  -3.14936663,  -2.07998398,\n",
       "        -1.85954898,  -0.7631942 ,  -1.94891051,  -1.60837966,\n",
       "        -1.15784827,  -0.48973547,  -2.57588437,   1.56903974,\n",
       "         0.0275757 ,   0.04982496,  -0.30342661,  -0.3829885 ])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "LogitBLP_beta = LogitBLP_estimator(y, z_logit, x, np.ones((T,)))\n",
    "LogitBLP_SE = LogitBLP_se(LogitBLP_beta, y, z_logit, x)\n",
    "LogitBLP_t,LogitBLP_p = logit_t_p(LogitBLP_beta, logit_score_unweighted(LogitBLP_beta, y, x), np.ones((T,)), S)\n",
    "LogitBLP_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLP approximation to optimal instruments\n",
    "\n",
    "BLP propose an algorithm for constructing an approximation to the optimal instruments. It is described in simple terms in Reynaert & Verboven (2014), and it has the following steps.\n",
    "It requires a consistent initial parameter estimate $\\hat \\theta = (\\hat \\beta', \\hat \\lambda')'$; here we can just use the MLE or the FKN estimates we have already computed. Let $Z_t$ denote the matrix of instruments (this is the matrix $X_t$ with the price replaced by the exchange rate). The steps are then as follows:\n",
    "\n",
    "First we form the regression equation of the covariates on the instruments:\n",
    "$$\n",
    "X_t = Z_t \\Pi + \\Epsilon_t\n",
    "$$\n",
    "\n",
    "The OLS estimate is then given as:\n",
    "$$\n",
    "\\hat \\Pi = \\left( \\frac{1}{T}\\sum_t Z_t' Z_t \\right)^{-1}\\left( \\frac{1}{T}\\sum_t Z_t' X_t\\right)\n",
    "$$\n",
    "\n",
    "Thus the predicted covariates given the instruments $W$ are:\n",
    "$$\n",
    "\\hat X_t = Z_t \\hat \\Pi\n",
    "$$\n",
    "\n",
    "Having constructed $\\hat X_t$ (which consists of the exogenous regressors, and the predicted price given $Z_t$), we compute the predicted mean utility:\n",
    "\n",
    "$$\n",
    "\\hat u_t = \\hat X_t \\hat \\beta\n",
    "$$\n",
    "\n",
    "and then the predicted market shares at the mean utility:\n",
    "\n",
    "$$\n",
    "\\hat q_t^{*} = P(\\hat u_t | \\hat \\lambda)\n",
    "$$\n",
    "\n",
    "Computationally, here we just use $\\hat X_t$ in place of $X_t$ in the CCP function.\n",
    "Given the predicted market shares, we compute\n",
    "\n",
    "$$\n",
    "\\hat G_t^{*} = \\left[\\hat X_t, -\\nabla_{q,\\lambda} \\Omega (\\hat q_t^{*} | \\hat \\lambda)\\right]\n",
    "$$\n",
    "\n",
    "which is the same as the function $\\hat G_t^0$ we already have constructed, except we evaluate it at the\n",
    "predictions $\\hat X_t$ and $\\hat q_t^{*}$ instead of at $X_t$ and $\\hat q_t^0$.\n",
    "\n",
    "The procedure above gives an approximation to the optimal instruments. We also require a weight matrix. The optimal weight matrix is the (generalized) inverse of the conditional (on the instruments) covariance of the fixed effects. Assuming $\\xi_{tj}$ is independently and identically distributed over markets t and products j, the conditional covariance simplifies to a scalar $\\sigma^2$ times an identity matrix (of size $J_t$).\n",
    "This means that all fixed effects are weighted equally, and the weights therefore drop out of the IV regression. The optimal IV estimator is therefore\n",
    "\n",
    "$$\n",
    "\\hat \\theta^{\\text{IV}} = \\left(\\frac{1}{T}\\sum_t (\\hat G_t^*)'\\hat G_t^0\\right)^{-1}\\left( \\frac{1}{T}\\sum_t (\\hat G_t^*)'\\hat r_t^0 \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\hat \\xi^*$ denote the estimated residual evaluated at the new parameter estimates,\n",
    "\n",
    "$$\n",
    "\\hat \\xi_{tj}^* = \\hat \\xi_{tj}(\\hat \\theta^{\\text{IV}})\n",
    "$$\n",
    "\n",
    "We may estimate the constant $\\sigma^2$ by\n",
    "\n",
    "$$\n",
    "\\hat \\sigma^2 = \\frac{1}{S}\\sum_{t}\\sum_{j = 1}^{J_t} \\left(\\hat \\xi_{tj}^*\\right)^2 \n",
    "$$\n",
    "\n",
    "The distribution of the estimator $\\hat \\theta^{\\text{IV}}$ is then\n",
    "\n",
    "$$\n",
    "\\hat \\theta^{\\text{IV}} \\sim \\mathcal{N}(\\theta_0, \\Sigma^{\\text{IV}})\n",
    "$$\n",
    "\n",
    "which can be consistently estimated by\n",
    "\n",
    "$$\n",
    "\\hat \\Sigma^{\\text{IV}} = \\hat \\sigma^2 \\left( \\sum_t (\\hat G_t^*)'\\hat G_t^0 \\right)^{-1}\n",
    "$$\n",
    "\n",
    "and the standard errors are then the square root of the diagonal elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_x(x, w, sample_share):\n",
    "    ''' \n",
    "    This function computes the predicted covariates from a regression on the instruments\n",
    "\n",
    "    Args:\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        w: a dictionary of T numpy arrays (J[t],K) of instruments for each covariate for each market t\n",
    "        sample_share: A (T,) numpy array of the fraction of observations in each market t \n",
    "\n",
    "    Returns.\n",
    "        X_hat: a dictionary of T numpy arrays (J[t],K) of predicted covariates for each market t\n",
    "    '''\n",
    "    \n",
    "    T = len(w)\n",
    "    K = w[0].shape[1]\n",
    "\n",
    "    sWW = np.empty((T,K,K))\n",
    "    sWX = np.empty((T,K,K))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        sWW[t,:,:] = sample_share[t]*np.einsum('jk,jl->kl', w[t], w[t])\n",
    "        sWX[t,:,:] = sample_share[t]*np.einsum('jk,jl->kl', w[t], x[t])\n",
    "\n",
    "    Pi_hat = la.solve(sWW.sum(axis=0), sWX.sum(axis=0))\n",
    "    X_hat = {t: np.einsum('jl,lk->jk', w[t], Pi_hat) for t in np.arange(T)}\n",
    "\n",
    "    return X_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLP_se(Theta, y, x, model):\n",
    "    '''\n",
    "    This function computes BLP standard errors which are consistent when using optimal instruments\n",
    "\n",
    "    Args:\n",
    "        Theta: a numpy array (K+G,) of BLP estimated \n",
    "        y: a dictionary of T numpy arrasy (J[t],) of observed or nonparametrically estimated market shares for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t \n",
    "        model: a dictionary of the Similarity Model specification as outputted by 'Similarity_specification'\n",
    "\n",
    "    Returns.\n",
    "        SE: a numpy array (K+G,) of estimated BLP standard errors using optimal instruments\n",
    "    '''\n",
    "    T = len(x)\n",
    "    S = T * np.array([x[t].shape[0] for t in np.arange(T)]).sum()\n",
    "\n",
    "    G = G_array(y, x, model)\n",
    "    d = G[0].shape[1]\n",
    "    r = {t: np.log(y[t]) for t in np.arange(T)}\n",
    "    \n",
    "    # We calculate \\sigma^2\n",
    "    xi = {t: np.einsum('jd,d->j', G[t], Theta) - r[t] for t in np.arange(T)}\n",
    "    sum_xij2 = np.empty((T,))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        sum_xij2[t] = (xi[t]**2).sum()\n",
    "    \n",
    "    sigma2 = np.sum(sum_xij2) / S\n",
    "\n",
    "    # We calculate GG for each market t\n",
    "    GG = np.empty((T,d,d))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        GG[t,:,:] = np.einsum('jd,jp->dp', G[t], G[t])\n",
    "\n",
    "    # Finally we compute \\Sigma and the standard errors\n",
    "    Sigma = sigma2*la.inv(GG.sum(axis=0))\n",
    "    SE = np.sqrt(np.diag(Sigma))\n",
    "\n",
    "    return SE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimalBLP_estimator(Theta0, q_obs, w, x, sample_share, model):\n",
    "    '''\n",
    "    This function estimates the Similarity demand model using optimal instruments in the BLP setting\n",
    "    \n",
    "    Args:\n",
    "        Theta0: a numpy array (K+G,) of consistent parameter estimates from estimation using the covariates ('first-stage parameters')\n",
    "        q_obs: a dictionary of T numpy arrasy (J[t],) of observed or nonparametrically estimated market shares for each market t\n",
    "        w: a dictionary of T numpy arrays (J[t],K+G) of instruments for each market t\n",
    "        x: a dictionary of T numpy arrays (J[t],K) of covariates for each market t\n",
    "        sample_share: a (T,) numpy array of the fraction of observations in each market t \n",
    "        model: a dictionary of the Similarity Model specification as outputted by 'Similarity_specification'\n",
    "\n",
    "    Returns.\n",
    "        Theta_IV: a numpy array (K+G,) of BLP parameter estimates in the Similarity Model using optimal instruments\n",
    "        SE_IV: a numpy array (K+G,) of estimated BLP standard errors using optimal instruments\n",
    "    '''\n",
    "    \n",
    "    T = len(x)\n",
    "    K = x[0].shape[1]\n",
    "    \n",
    "    X_hat = predict_x(x, w, sample_share)\n",
    "    q0 = Similarity_ccp(Theta0, X_hat, model)\n",
    "    G_star = G_array(q0, X_hat, model)\n",
    "    G0 = G_array(q_obs, x, model)\n",
    "    \n",
    "    r = {t: np.log(q_obs[t]) for t in np.arange(T)}\n",
    "\n",
    "    d = G0[0].shape[1]\n",
    "\n",
    "    sGG = np.empty((T,d,d))\n",
    "    sGr = np.empty((T,d))\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        sGG[t,:,:] = sample_share[t]*np.einsum('jd,jp->dp', G_star[t], G0[t])\n",
    "        sGr[t,:] = sample_share[t]*np.einsum('jd,j->d', G_star[t], r[t])\n",
    "\n",
    "    Theta_IV = la.solve(sGG.sum(axis=0), sGr.sum(axis=0))\n",
    "    SE_IV = BLP_se(Theta_IV, q_obs, x, model)\n",
    "\n",
    "    return Theta_IV, SE_IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThetaOptBLP, SEOptBLP = OptimalBLP_estimator(FKN_theta, y, z_logit, x, np.ones((T,)), Model)\n",
    "OptBLP_t, OptBLP_p = Similarity_t_p(SEOptBLP, ThetaOptBLP, S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.259433210474408"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.array([p for p in ThetaOptBLP[K:]  if p > 0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variables</th>\n",
       "      <th>theta</th>\n",
       "      <th>se</th>\n",
       "      <th>t (theta == 0)</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>in_out</th>\n",
       "      <td>-11.7985***</td>\n",
       "      <td>0.03458</td>\n",
       "      <td>341.164</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cy</th>\n",
       "      <td>-0.7545***</td>\n",
       "      <td>0.02002</td>\n",
       "      <td>37.691</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hp</th>\n",
       "      <td>-5.587***</td>\n",
       "      <td>0.02601</td>\n",
       "      <td>214.837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>we</th>\n",
       "      <td>0.2574***</td>\n",
       "      <td>0.02089</td>\n",
       "      <td>12.326</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>le</th>\n",
       "      <td>-2.4046***</td>\n",
       "      <td>0.02323</td>\n",
       "      <td>103.500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wi</th>\n",
       "      <td>5.9706***</td>\n",
       "      <td>0.03394</td>\n",
       "      <td>175.927</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>he</th>\n",
       "      <td>0.8705***</td>\n",
       "      <td>0.02738</td>\n",
       "      <td>31.794</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>li</th>\n",
       "      <td>-0.77***</td>\n",
       "      <td>0.01218</td>\n",
       "      <td>63.199</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sp</th>\n",
       "      <td>5.02***</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>188.901</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ac</th>\n",
       "      <td>1.1385***</td>\n",
       "      <td>0.01299</td>\n",
       "      <td>87.662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr</th>\n",
       "      <td>-0.1493***</td>\n",
       "      <td>0.00237</td>\n",
       "      <td>63.042</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_2</th>\n",
       "      <td>-0.8311***</td>\n",
       "      <td>0.03193</td>\n",
       "      <td>26.030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_3</th>\n",
       "      <td>-0.1506***</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>33.578</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_4</th>\n",
       "      <td>-0.9499***</td>\n",
       "      <td>0.00480</td>\n",
       "      <td>197.945</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_5</th>\n",
       "      <td>-0.4631***</td>\n",
       "      <td>0.00446</td>\n",
       "      <td>103.938</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_6</th>\n",
       "      <td>-0.3605***</td>\n",
       "      <td>0.00438</td>\n",
       "      <td>82.317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_7</th>\n",
       "      <td>-0.9956***</td>\n",
       "      <td>0.00762</td>\n",
       "      <td>130.612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_8</th>\n",
       "      <td>-0.3995***</td>\n",
       "      <td>0.01094</td>\n",
       "      <td>36.520</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_9</th>\n",
       "      <td>-1.7608***</td>\n",
       "      <td>0.00720</td>\n",
       "      <td>244.600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_10</th>\n",
       "      <td>-0.2598***</td>\n",
       "      <td>0.00429</td>\n",
       "      <td>60.520</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_11</th>\n",
       "      <td>-0.0442***</td>\n",
       "      <td>0.00439</td>\n",
       "      <td>10.061</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_12</th>\n",
       "      <td>-0.49***</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>92.979</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_13</th>\n",
       "      <td>-1.2869***</td>\n",
       "      <td>0.00660</td>\n",
       "      <td>194.956</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_14</th>\n",
       "      <td>-2.1215***</td>\n",
       "      <td>0.00919</td>\n",
       "      <td>230.955</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_15</th>\n",
       "      <td>-1.9771***</td>\n",
       "      <td>0.00876</td>\n",
       "      <td>225.685</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_16</th>\n",
       "      <td>-1.2687***</td>\n",
       "      <td>0.00426</td>\n",
       "      <td>297.597</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_17</th>\n",
       "      <td>-0.9739***</td>\n",
       "      <td>0.00508</td>\n",
       "      <td>191.567</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_18</th>\n",
       "      <td>0.4086***</td>\n",
       "      <td>0.00471</td>\n",
       "      <td>86.702</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_19</th>\n",
       "      <td>-1.2959***</td>\n",
       "      <td>0.00586</td>\n",
       "      <td>221.279</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_20</th>\n",
       "      <td>-0.2857***</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>53.653</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_21</th>\n",
       "      <td>-0.252***</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>61.072</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_22</th>\n",
       "      <td>-0.2039***</td>\n",
       "      <td>0.00422</td>\n",
       "      <td>48.275</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_23</th>\n",
       "      <td>-0.1584***</td>\n",
       "      <td>0.00458</td>\n",
       "      <td>34.615</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_24</th>\n",
       "      <td>-0.6969***</td>\n",
       "      <td>0.00431</td>\n",
       "      <td>161.524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_25</th>\n",
       "      <td>-0.8286***</td>\n",
       "      <td>0.00512</td>\n",
       "      <td>161.965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_26</th>\n",
       "      <td>-1.053***</td>\n",
       "      <td>0.00510</td>\n",
       "      <td>206.553</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_27</th>\n",
       "      <td>-2.4134***</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>45.894</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_28</th>\n",
       "      <td>-1.0134***</td>\n",
       "      <td>0.00865</td>\n",
       "      <td>117.111</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_29</th>\n",
       "      <td>-2.001***</td>\n",
       "      <td>0.01765</td>\n",
       "      <td>113.381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_30</th>\n",
       "      <td>-1.2162***</td>\n",
       "      <td>0.00894</td>\n",
       "      <td>136.105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_31</th>\n",
       "      <td>-1.59***</td>\n",
       "      <td>0.01807</td>\n",
       "      <td>88.011</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_32</th>\n",
       "      <td>-0.4178***</td>\n",
       "      <td>0.00812</td>\n",
       "      <td>51.450</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_33</th>\n",
       "      <td>-1.689***</td>\n",
       "      <td>0.03057</td>\n",
       "      <td>55.247</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_34</th>\n",
       "      <td>-0.8166***</td>\n",
       "      <td>0.00547</td>\n",
       "      <td>149.207</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_35</th>\n",
       "      <td>-0.5157***</td>\n",
       "      <td>0.00514</td>\n",
       "      <td>100.390</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_36</th>\n",
       "      <td>-0.148***</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>32.947</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_37</th>\n",
       "      <td>-1.845***</td>\n",
       "      <td>0.01093</td>\n",
       "      <td>168.873</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home_2</th>\n",
       "      <td>1.0623***</td>\n",
       "      <td>0.00193</td>\n",
       "      <td>549.310</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cla_2</th>\n",
       "      <td>0.0278***</td>\n",
       "      <td>0.00245</td>\n",
       "      <td>11.317</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cla_3</th>\n",
       "      <td>0.133***</td>\n",
       "      <td>0.00330</td>\n",
       "      <td>40.263</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cla_4</th>\n",
       "      <td>0.1386***</td>\n",
       "      <td>0.00461</td>\n",
       "      <td>30.081</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cla_5</th>\n",
       "      <td>0.1537***</td>\n",
       "      <td>0.00585</td>\n",
       "      <td>26.258</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_in_out</th>\n",
       "      <td>0.8427***</td>\n",
       "      <td>0.00209</td>\n",
       "      <td>404.174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_cy</th>\n",
       "      <td>-0.0928***</td>\n",
       "      <td>0.00143</td>\n",
       "      <td>64.999</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_hp</th>\n",
       "      <td>0.2064***</td>\n",
       "      <td>0.00219</td>\n",
       "      <td>94.099</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_we</th>\n",
       "      <td>-0.0069***</td>\n",
       "      <td>0.00189</td>\n",
       "      <td>3.647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_le</th>\n",
       "      <td>-0.0488***</td>\n",
       "      <td>0.00172</td>\n",
       "      <td>28.375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_wi</th>\n",
       "      <td>-0.0669***</td>\n",
       "      <td>0.00101</td>\n",
       "      <td>66.415</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_he</th>\n",
       "      <td>-0.0613***</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>90.549</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_li</th>\n",
       "      <td>0.0221***</td>\n",
       "      <td>0.00092</td>\n",
       "      <td>24.009</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_sp</th>\n",
       "      <td>-0.0571***</td>\n",
       "      <td>0.00163</td>\n",
       "      <td>35.132</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_ac</th>\n",
       "      <td>-0.0402***</td>\n",
       "      <td>0.00109</td>\n",
       "      <td>37.025</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_brand</th>\n",
       "      <td>0.1882***</td>\n",
       "      <td>0.00097</td>\n",
       "      <td>193.976</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_home</th>\n",
       "      <td>-0.3915***</td>\n",
       "      <td>0.00119</td>\n",
       "      <td>329.078</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group_cla</th>\n",
       "      <td>-0.0971***</td>\n",
       "      <td>0.00142</td>\n",
       "      <td>68.498</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "variables           theta       se  t (theta == 0)    p\n",
       "in_out        -11.7985***  0.03458         341.164  0.0\n",
       "cy             -0.7545***  0.02002          37.691  0.0\n",
       "hp              -5.587***  0.02601         214.837  0.0\n",
       "we              0.2574***  0.02089          12.326  0.0\n",
       "le             -2.4046***  0.02323         103.500  0.0\n",
       "wi              5.9706***  0.03394         175.927  0.0\n",
       "he              0.8705***  0.02738          31.794  0.0\n",
       "li               -0.77***  0.01218          63.199  0.0\n",
       "sp                5.02***  0.02657         188.901  0.0\n",
       "ac              1.1385***  0.01299          87.662  0.0\n",
       "pr             -0.1493***  0.00237          63.042  0.0\n",
       "brand_2        -0.8311***  0.03193          26.030  0.0\n",
       "brand_3        -0.1506***  0.00449          33.578  0.0\n",
       "brand_4        -0.9499***  0.00480         197.945  0.0\n",
       "brand_5        -0.4631***  0.00446         103.938  0.0\n",
       "brand_6        -0.3605***  0.00438          82.317  0.0\n",
       "brand_7        -0.9956***  0.00762         130.612  0.0\n",
       "brand_8        -0.3995***  0.01094          36.520  0.0\n",
       "brand_9        -1.7608***  0.00720         244.600  0.0\n",
       "brand_10       -0.2598***  0.00429          60.520  0.0\n",
       "brand_11       -0.0442***  0.00439          10.061  0.0\n",
       "brand_12         -0.49***  0.00527          92.979  0.0\n",
       "brand_13       -1.2869***  0.00660         194.956  0.0\n",
       "brand_14       -2.1215***  0.00919         230.955  0.0\n",
       "brand_15       -1.9771***  0.00876         225.685  0.0\n",
       "brand_16       -1.2687***  0.00426         297.597  0.0\n",
       "brand_17       -0.9739***  0.00508         191.567  0.0\n",
       "brand_18        0.4086***  0.00471          86.702  0.0\n",
       "brand_19       -1.2959***  0.00586         221.279  0.0\n",
       "brand_20       -0.2857***  0.00533          53.653  0.0\n",
       "brand_21        -0.252***  0.00413          61.072  0.0\n",
       "brand_22       -0.2039***  0.00422          48.275  0.0\n",
       "brand_23       -0.1584***  0.00458          34.615  0.0\n",
       "brand_24       -0.6969***  0.00431         161.524  0.0\n",
       "brand_25       -0.8286***  0.00512         161.965  0.0\n",
       "brand_26        -1.053***  0.00510         206.553  0.0\n",
       "brand_27       -2.4134***  0.05259          45.894  0.0\n",
       "brand_28       -1.0134***  0.00865         117.111  0.0\n",
       "brand_29        -2.001***  0.01765         113.381  0.0\n",
       "brand_30       -1.2162***  0.00894         136.105  0.0\n",
       "brand_31         -1.59***  0.01807          88.011  0.0\n",
       "brand_32       -0.4178***  0.00812          51.450  0.0\n",
       "brand_33        -1.689***  0.03057          55.247  0.0\n",
       "brand_34       -0.8166***  0.00547         149.207  0.0\n",
       "brand_35       -0.5157***  0.00514         100.390  0.0\n",
       "brand_36        -0.148***  0.00449          32.947  0.0\n",
       "brand_37        -1.845***  0.01093         168.873  0.0\n",
       "home_2          1.0623***  0.00193         549.310  0.0\n",
       "cla_2           0.0278***  0.00245          11.317  0.0\n",
       "cla_3            0.133***  0.00330          40.263  0.0\n",
       "cla_4           0.1386***  0.00461          30.081  0.0\n",
       "cla_5           0.1537***  0.00585          26.258  0.0\n",
       "group_in_out    0.8427***  0.00209         404.174  0.0\n",
       "group_cy       -0.0928***  0.00143          64.999  0.0\n",
       "group_hp        0.2064***  0.00219          94.099  0.0\n",
       "group_we       -0.0069***  0.00189           3.647  0.0\n",
       "group_le       -0.0488***  0.00172          28.375  0.0\n",
       "group_wi       -0.0669***  0.00101          66.415  0.0\n",
       "group_he       -0.0613***  0.00068          90.549  0.0\n",
       "group_li        0.0221***  0.00092          24.009  0.0\n",
       "group_sp       -0.0571***  0.00163          35.132  0.0\n",
       "group_ac       -0.0402***  0.00109          37.025  0.0\n",
       "group_brand     0.1882***  0.00097         193.976  0.0\n",
       "group_home     -0.3915***  0.00119         329.078  0.0\n",
       "group_cla      -0.0971***  0.00142          68.498  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reg_table(ThetaOptBLP, SEOptBLP, N, x_vars, nest_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qOpt = Similarity_ccp(ThetaOptBLP, z_logit, Model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
