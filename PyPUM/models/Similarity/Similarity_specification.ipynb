{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUM and the Similarity Specification\n",
    "\n",
    "This notebook introduces the general theory of Perturbed Utility Models and adresses how the important subclass of 'Similarity Models' may be specified in practical applications.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   variable names                                        description\n",
      "0              cy            cylinder volume or displacement (in cc)\n",
      "1              hp                                 horsepower (in kW)\n",
      "2              we                                     weight (in kg)\n",
      "3              le                                     length (in cm)\n",
      "4              wi                                      width (in cm)\n",
      "5              he                                     height (in cm)\n",
      "6              li          average of li1, li2, li3 (used in papers)\n",
      "7              sp                            maximum speed (km/hour)\n",
      "8              ac  time to acceleration (in seconds from 0 to 100...\n",
      "9              pr   price (in destination currency including V.A.T.)\n",
      "10          brand                                      name of brand\n",
      "11           home  domestic car dummy (appropriate interaction of...\n",
      "12            cla                              class or segment code\n",
      "x has full rank\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import os\n",
    "import sys\n",
    "from numpy import linalg as la\n",
    "from scipy import optimize\n",
    "import scipy.stats as scstat\n",
    "from matplotlib import pyplot as plt\n",
    "import itertools as iter\n",
    "%load_ext line_profiler\n",
    "\n",
    "# Files\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from utilities.Logit_file import estimate_logit, logit_se, logit_t_p, q_logit, logit_score, logit_score_unweighted, logit_ccp, LogitBLP_estimator, LogitBLP_se\n",
    "from data.Eurocarsdata_file import Eurocars_cleandata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and variable names\n",
    "descr = (pd.read_stata('../data/eurocars.dta', iterator = True)).variable_labels() # Obtain variable descriptions\n",
    "dat_file = pd.read_csv('../data/eurocars.csv') # reads in the data set as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable names</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cy</td>\n",
       "      <td>cylinder volume or displacement (in cc)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hp</td>\n",
       "      <td>horsepower (in kW)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>we</td>\n",
       "      <td>weight (in kg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>le</td>\n",
       "      <td>length (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wi</td>\n",
       "      <td>width (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>he</td>\n",
       "      <td>height (in cm)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>li</td>\n",
       "      <td>average of li1, li2, li3 (used in papers)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sp</td>\n",
       "      <td>maximum speed (km/hour)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ac</td>\n",
       "      <td>time to acceleration (in seconds from 0 to 100...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pr</td>\n",
       "      <td>price (in destination currency including V.A.T.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>brand</td>\n",
       "      <td>name of brand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>home</td>\n",
       "      <td>domestic car dummy (appropriate interaction of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cla</td>\n",
       "      <td>class or segment code</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variable names                                        description\n",
       "0              cy            cylinder volume or displacement (in cc)\n",
       "1              hp                                 horsepower (in kW)\n",
       "2              we                                     weight (in kg)\n",
       "3              le                                     length (in cm)\n",
       "4              wi                                      width (in cm)\n",
       "5              he                                     height (in cm)\n",
       "6              li          average of li1, li2, li3 (used in papers)\n",
       "7              sp                            maximum speed (km/hour)\n",
       "8              ac  time to acceleration (in seconds from 0 to 100...\n",
       "9              pr   price (in destination currency including V.A.T.)\n",
       "10          brand                                      name of brand\n",
       "11           home  domestic car dummy (appropriate interaction of...\n",
       "12            cla                              class or segment code"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Outside option is included if OO == True, otherwise analysis is done on the inside options only.\n",
    "OO = True\n",
    "\n",
    "# Choose which variables to include in the analysis, and assign them either as discrete variables or continuous.\n",
    "\n",
    "x_discretevars = [ 'brand', 'home', 'cla']\n",
    "x_contvars = ['cy', 'hp', 'we', 'le', 'wi', 'he', 'li', 'sp', 'ac', 'pr']\n",
    "z_IV_contvars = ['xexr']\n",
    "z_IV_discretevars = []\n",
    "x_allvars =  [*x_contvars, *x_discretevars]\n",
    "z_allvars = [*z_IV_contvars, *z_IV_discretevars]\n",
    "\n",
    "if OO:\n",
    "    nest_contvars = [var for var in x_contvars if var != 'pr'] # We nest over all variables other than price, but an alternative list can be specified here if desired.\n",
    "    nest_discvars = ['in_out', *x_discretevars]\n",
    "    nest_vars = ['in_out', *nest_contvars, *x_discretevars]\n",
    "else:\n",
    "    nest_contvars = [var for var in x_contvars if (var != 'pr')]\n",
    "    nest_discvars = x_discretevars # See above\n",
    "    nest_vars = [*nest_contvars, *nest_discvars]\n",
    "\n",
    "G = len(nest_vars)\n",
    "\n",
    "# Print list of chosen variables as a dataframe\n",
    "pd.DataFrame(descr, index=['description'])[x_allvars].transpose().reset_index().rename(columns={'index' : 'variable names'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat, dat_org, x_vars, z_vars, N, pop_share, T, J, K = Eurocars_cleandata(dat_file, x_contvars, x_discretevars, z_IV_contvars, z_IV_discretevars, outside_option=OO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionaries of numpy arrays for each market. This allows the size of the data set to vary over markets.\n",
    "\n",
    "dat = dat.reset_index(drop = True).sort_values(by = ['market', 'co']) # Sort data so that reshape is successfull\n",
    "\n",
    "x = {t: dat[dat['market'] == t][x_vars].values.reshape((J[t],K)) for t in np.arange(T)} # Dict of explanatory variables\n",
    "y = {t: dat[dat['market'] == t]['ms'].to_numpy().reshape((J[t])) for t in np.arange(T)} # Dict of market shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perturbed utility, logit and nested logit\n",
    "\n",
    "In the following, a vector $z\\in \\mathbb R^d$ is always a column vector. The Similarity Model is a discrete choice model, where the probability vector over the alternatives is given by the solution to a utility maximization problem of the form\n",
    "$$\n",
    "P(u|\\theta)=\\arg\\max_{q\\in \\Delta} q'u(\\theta)-\\Omega(q|\\theta)\n",
    "$$\n",
    "where $\\Delta$ is the probability simplex over the set of discrete choices, $u$ is a vector of payoffs for each option, $\\Omega$ is a convex function and $q'$ denotes the transpose of $q$, and $\\theta$ is a vector of parameters. All Additive Random Utility Models can be represented in this way (Fosgerau and SÃ¸rensen (2021)). For example, the logit choice probabilities result from the perturbation function $\\Omega(q)=q'\\ln q$ where $\\ln q$ is the elementwise logarithm.\n",
    "\n",
    "In the Nested Logit Model, the choice set is divided into a partition $\\mathcal C=\\left\\{C_1,\\ldots,C_L\\right\\}$, and the perturbation function is given by\n",
    "$$\n",
    "\\Omega(q|\\lambda)=(1-\\lambda)q'\\ln q+\\lambda \\sum_{\\ell =1}^L \\left( \\sum_{j\\in C_\\ell}q_j\\right)\\ln \\left( \\sum_{j\\in C}q_j\\right),\n",
    "$$\n",
    "where $\\lambda\\in [0,1)$ is a parameter. This function can be written equivalently as\n",
    "$$\n",
    "\\Omega(q|\\lambda)=(1-\\lambda)q'\\ln q+\\lambda \\left(\\psi q\\right)'\\ln \\left( \\psi q\\right),\n",
    "$$\n",
    "where $\\psi$ is a $J \\times L$ matrix, where $\\psi_{j\\ell}=1$ if option $j$ belongs to nest $C_\\ell$ and zero otherwise.\n",
    " This specification generates nested logit choice probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Similarity Model\n",
    "\n",
    "The Similarity Model generalizes the Nested Logit Model. It allows for multiple nesting structures, and it also allows for 'continuous' nesting by measuring similarity of products in the space of characteristics. Let $g = 1,\\ldots, G$ index a set of distinct nesting structures represented by  matrices $\\psi^1, \\ldots, \\psi^G$ as in .... We define the Similarity pertubation function $\\Omega$ as:\n",
    "\n",
    "$$\n",
    "\\Omega(q|\\lambda) = \\left( 1 - \\sum_{g = 1}^G \\lambda_g\\right) q' \\ln (q) + \\sum_{g = 1}^G \\lambda_g (\\psi^g q)' \\ln( \\psi^g q) - q' \\delta\n",
    "$$\n",
    "\n",
    "where $\\lambda \\in \\mathbb{R}^G$ is a vector of nesting parameters and $\\delta \\in \\mathbb{R}^{J_t}$ is a normalizing constant vector. If the sum of the positive nesting parameters $\\sum_{g : \\lambda_g > 0} \\lambda_g $ is strictly less than $1$, then the pertubation function $\\Omega(\\cdot|\\lambda)$ is strictly convex, such that the Similarity Model is a perturbed utility Model.\n",
    "\n",
    "Note that $q$ and $\\psi^g q$ are probability distributions, wherefore the terms $q'\\ln(q)$ and $(\\psi^g q)' \\ln(\\psi^g q)$ are interpreted as the negative entropy of $q$ and of the probability distribution of similarity within characteristics $g=1,\\ldots,G$, respectively.\n",
    "\n",
    "When choosing the normalizing factor $\\delta$, we want to normalize the pertubation function such that $\\Omega(q|\\lambda) = 0$ at the corners of the probability simplex $\\Delta$, i.e. when the vector of choice probabilities $q$ contains a probability equal to $0$ or $1$. If $e_j$ is the $j$'th standard basis vector in $R^{J_t}$, then $0 = \\Omega(e_j | \\lambda) = \\left( 1 - \\sum_{g = 1}^G \\lambda_g\\right) \\cdot 0 + \\sum_{g = 1}^G \\lambda_g (\\psi_{[j]}^g)' \\ln( \\psi_{[j]}^g) - \\delta_j$ implies that we must choose $\\delta_j = \\sum_{g = 1}^G \\lambda_g (\\psi_{[j]}^g)' \\ln( \\psi_{[j]}^g)$ to achieve this normalization, where $\\psi_{[j]}^g$ here denotes the $j$'th row of $\\psi^g$.\n",
    "\n",
    "Furthermore, if $\\lambda = 0$ then the Similarity Model reduces to the Multinomial Logit Model, since $\\Omega(q|0) = q' \\ln (q)$ is the negative Shannon-entropy, and the Nested Logit Model, as described above, may be obtained if $G = 1$ and $\\delta = 0$. Furthermore, the IPDL Model by Fosgerau et. al (2022) may obtained by setting $\\delta = 0$. Hence the Similarity Model allows for greater flexibility than many workhorse models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In implementions of the Similarity Model, it will be useful to define a the following matrices to use in computations. First we define the matrix $\\Psi \\in \\mathbb{R}^{(G + 1)J_t \\times J_t}$ as the matrix stacking the Identity matrix $I_{J_t}$ in $R^{J_t \\times J_t}$ on top of the $\\psi^g$ matrices:\n",
    "\n",
    "$$\n",
    "\\Psi = \\left(\n",
    "    \\begin{array}{c}\n",
    "        I_{J_t} \\\\\n",
    "        \\psi^1 \\\\\n",
    "        \\vdots \\\\\n",
    "        \\psi^G\n",
    "    \\end{array}\n",
    "    \\right)\n",
    "$$\n",
    "\n",
    "Another useful matrix for carrying out computations is the matrix $\\Gamma \\in \\mathbb{R}^{(G + 1)J_t \\times J_t}$ defined by:\n",
    "\n",
    "$$\n",
    "\\Gamma = \\left(\n",
    "    \\begin{array}{c}\n",
    "        \\left(1 - \\sum_{g = 1}^G \\lambda_g\\right) I_{J_t} \\\\\n",
    "        \\lambda_1 \\psi^1 \\\\\n",
    "        \\vdots \\\\\n",
    "        \\lambda_G \\psi^G\n",
    "    \\end{array}\n",
    "    \\right)\n",
    "$$\n",
    "\n",
    "Finally, since the nomarlizing vector $\\delta$ is linear-in-parameters $\\lambda$, we wish to construct a matrix $\\varphi \\in \\mathbb{R}^{J_t \\times G}$ such that $\\delta = \\varphi \\lambda$. Hence for any nesting structure $g$, set $\\varphi_{[g]} = (\\psi^g \\circ \\ln (\\psi^g))'\\iota_{J_t}$, where $\\iota_{J_t} = (1, \\ldots, 1)' \\in R^{J_t}$ is the all-ones vector; then \n",
    "\n",
    "$$\n",
    "\\varphi = \\left(\\varphi_{[1]} \\ldots \\varphi_{[G]}\\right)$$ \n",
    "\n",
    "has the desired property. Using the above matrices, we may compute the Similarity pertubation function by: $\\Omega(q|\\lambda) = (\\Gamma q)' \\ln (\\Psi q) - q' \\varphi \\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_nests(data, markets_id, products_id, in_out_id, cont_var, disc_var, outside_option = True):\n",
    "    '''\n",
    "    This function creates the nest matrices \\Psi^{gt}, and stack them over groups g for each market t.\n",
    "\n",
    "    Args.\n",
    "        data: a pandas DataFrame\n",
    "        markets_id: a string denoting the column of 'data' containing an enumeration t=0,1,...,T-1 of markets\n",
    "        products_id: a string denoting the column of 'data' containing product codes which uniquely identifies products\n",
    "        in_out_id: a string denoting the column of 'data' containing the dummy for being an inside or outside option. If 'outside_option = True' then this may be set to e.g. the empty string ''.\n",
    "        cont_var: a list of the continuous variables among the covariates\n",
    "        disc_var: a list of the discrete variables among the covariates\n",
    "        outside_option: a boolean indicating whether the model is estimated with or without an outside option. Default is set to 'True' i.e. with an outside option.\n",
    "\n",
    "    Returns\n",
    "        Psi: a dictionary of length T of numpy arrays ((G+1)*J[t], J[t]) the J[t] by J[t] identity stacked on top of the Psi_g matrices for each market t and each gropuing g\n",
    "        Psi_dim: a dictionary of length T of (G+1,J[t],J[t]) numpy arrays with the top most array being the J[t] by J[t] identity matrix and the following G matrices being the \\psi^g matrices \n",
    "    '''\n",
    "\n",
    "    T = data[markets_id].nunique()\n",
    "    J = np.array([data[data[markets_id] == t][products_id].nunique() for t in np.arange(T)])\n",
    "    \n",
    "    # We include nest on outside vs. inside options. The amount of categories varies if the outside option is included in the analysis.\n",
    "    dat = data.sort_values(by = [markets_id, products_id]) # We sort the data in ascending, first according to market and then according to the product id\n",
    "    \n",
    "    Psi = {}\n",
    "    Psi_dim = {}\n",
    "\n",
    "    if OO:\n",
    "        in_out_index = [n for n in np.arange(len(disc_var)) if disc_var[n] == in_out_id][0]\n",
    "        non_in_out_indices = np.array([n for n in np.arange(len(disc_var)) if disc_var[n] != in_out_id])\n",
    "\n",
    "    # Assign nests for products in each market t\n",
    "    for t in np.arange(T):\n",
    "        data_t = dat[dat[markets_id] == t] # Subset data on market t\n",
    "\n",
    "        # Estimate discrete kernels\n",
    "        D_disc = len(disc_var)\n",
    "        K_disc = np.empty((D_disc, J[t], J[t]))\n",
    "        C = np.array(data_t[disc_var].nunique())\n",
    "\n",
    "        for d in np.arange(D_disc):\n",
    "            Indicator = pd.get_dummies(data_t[disc_var[d]]).values.reshape((J[t], C[d]))\n",
    "            K_disc[d,:,:] = Indicator@(Indicator.T) # Get the indicator kernel function for the discrete variables\n",
    "\n",
    "        Psidisc_t = np.einsum('djk,dk->djk', K_disc, 1./(K_disc.sum(axis=1)))\n",
    "            \n",
    "        # Estimate continuous kernels\n",
    "        D_cont = len(cont_var)\n",
    "        IQR = scstat.iqr(data_t[cont_var].values, axis = 0) # Compute interquartile range of each continuous variable\n",
    "        sd = np.std(data_t[cont_var].values, axis = 0) # Compute empirical standard deviation of each continuous variable\n",
    "        h = 0.9*np.fmin(sd, IQR/1.34)/(J[t]**(1/5)) # Use Silverman's rule of thumb for bandwidth estimation for each continuous variable\n",
    "        w = data_t[cont_var].values.transpose()\n",
    "        diff = w[:,:,None]*np.ones((D_cont, J[t], J[t])) - w[:,None,:] # calculates the differences w_j - w_k for all continuous g = 1, ... , G , and for all alternatives j,k.\n",
    "        \n",
    "        # Compute continuous kernel functions\n",
    "        if outside_option:\n",
    "            K_cont = np.exp(-(diff**2)/(2*(h[:,None,None]**2)))[:,1:,1:] # Compute continuous kernel function for inside options\n",
    "            Psicontinner_t = np.einsum('djk,dk->djk', K_cont, 1./K_cont.sum(axis=1))\n",
    "            Psicont_t = np.zeros((D_cont, J[t], J[t]))\n",
    "            Psicont_t[:,0,0] = 1 # The outside option is only similar to itself\n",
    "            Psicont_t[:,1:,1:] = Psicontinner_t # The inside option are only similar to each other\n",
    "        else:\n",
    "            K_cont = np.exp(-(diff**2)/(2*(h[:,None,None]**2))) # -=-\n",
    "            Psicont_t = np.einsum('djk,dk->djk', K_cont, 1./K_cont.sum(axis=1))\n",
    "\n",
    "        # Stack Psi\n",
    "        D = len([*cont_var, *disc_var]) + 1\n",
    "\n",
    "        if outside_option:\n",
    "            Psi_dim[t] = np.concatenate((np.eye(J[t]).reshape((1,J[t],J[t])), Psidisc_t[in_out_index,:,:].reshape((1,J[t],J[t])), Psicont_t, Psidisc_t[non_in_out_indices,:,:]), axis = 0)\n",
    "            Psi[t] = Psi_dim[t].reshape((D*J[t], J[t]))\n",
    "        else:\n",
    "            Psi_dim[t] = np.concatenate((np.eye(J[t]).reshape((1,J[t],J[t])), Psicont_t, Psidisc_t), axis = 0)\n",
    "            Psi[t] = Psi_dim[t].reshape((D*J[t], J[t]))\n",
    "\n",
    "    return Psi, Psi_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi_matrix(psi):\n",
    "    '''\n",
    "    This function computes the \\varphi matrix used in e.g. calculating \\delta. \n",
    "\n",
    "    Args:\n",
    "        psi: a dictionary of length T of numpy arrays ((G+1)*J[t], J[t]) the J[t] by J[t] identity stacked on top of the Psi_g matrices for each market t and each gropuing g as outputted by 'Create_nests'-function\n",
    "\n",
    "    Returns.\n",
    "        phi: a dictionary of length T of numpy arrays (J[t],G) of the \\varphi^g matrices\n",
    "    '''\n",
    "    T = len(psi)\n",
    "    J = np.array([psi[t].shape[1] for t in np.arange(T)])\n",
    "    G = np.int32(psi[0].shape[0] / J[0] - 1)\n",
    "\n",
    "    phi = {}\n",
    "\n",
    "    for t in np.arange(T):\n",
    "        phi_t = np.empty((J[t], G))\n",
    "        psi_t = psi[t]\n",
    "\n",
    "        # Compute phi_g = (psi^g \\circ log(psi^g))^T %o% \\iota \n",
    "        for g in np.arange(1,G+1):\n",
    "            psi_g = psi_t[g*J[t]:(g+1)*J[t],:]\n",
    "            phi_t[:,g-1] = (psi_g*np.log(psi_g, out = np.zeros_like(psi_g), where = (psi_g > 0))).sum(axis=0)\n",
    "        \n",
    "        phi[t] = phi_t\n",
    "\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity_specification(data, markets_id, products_id, in_out_id, cont_var, disc_var, outside_option = True):\n",
    "    '''\n",
    "    This function returns the Similarity Model specification as given by the covariates and the nesting structure\n",
    "\n",
    "    Args:\n",
    "        data: a pandas DataFrame\n",
    "        markets_id: a string denoting the column of 'data' containing an enumeration t=0,1,...,T-1 of markets\n",
    "        products_id: a string denoting the column of 'data' containing product codes which uniquely identifies products\n",
    "        in_out_id: a string denoting the column of 'data' containing the dummy for being an inside or outside option. If 'outside_option = True' then this may be set to e.g. the empty string ''.\n",
    "        cont_var: a list of the continuous variables among the covariates\n",
    "        disc_var: a list of the discrete variables among the covariates\n",
    "        outside_option: a boolean indicating whether the model is estimated with or without an outside option. Default is set to 'True' i.e. with an outside option.\n",
    "\n",
    "    Returns.\n",
    "        Model: a dictionary of length 3, containing the stacked Psi, the 3-dimensional Psi, and the Phi matrix as outputted by 'Create_nests' and 'phi_matrix', respectively.\n",
    "    '''\n",
    "\n",
    "    Psi, Psi_3d = Create_nests(data, markets_id, products_id, in_out_id, cont_var, disc_var, outside_option)\n",
    "    Phi = phi_matrix(Psi)\n",
    "    Model = {'psi' : Psi, 'psi_3d' : Psi_3d, 'phi' : Phi}\n",
    "\n",
    "    return Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = Similarity_specification(dat, 'market', 'co', 'in_out', nest_contvars, nest_discvars, outside_option = OO)\n",
    "Psi = Model['psi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_Gamma(Lambda, model):\n",
    "    '''\n",
    "    This function computes the Gamma matrix\n",
    "\n",
    "    Args:\n",
    "        Lambda: a (G,) numpy array of grouping parameters \\lambda_g\n",
    "        model: a dictionary of the Similarity Model specification as outputted by 'Similarity_specification'\n",
    "\n",
    "    Returns.\n",
    "        Gamma: a dictionary of length T containing the ((G+1)*J[t],J[t]) numpy arrays of the \\Gamma matrices for each market t.\n",
    "    '''\n",
    "\n",
    "    Psi = model['psi']\n",
    "    T = len(Psi)\n",
    "    J = np.array([Psi[t].shape[1] for t in np.arange(T)])\n",
    "    \n",
    "    Gamma = {}\n",
    "    lambda0 = np.array([1 - sum(Lambda)])\n",
    "    Lambda_full = np.concatenate((lambda0, Lambda)) # create vector (1- sum(lambda), lambda_1, ..., lambda_G)\n",
    "    D = len(Lambda_full)\n",
    "    \n",
    "    for t in np.arange(T):\n",
    "        Lambda_long =(Lambda_full[:,None]*np.ones((D,J[t]))).reshape((D*J[t],))\n",
    "        Gamma[t] = Lambda_long[:,None]*Psi[t]\n",
    "\n",
    "    return Gamma"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
